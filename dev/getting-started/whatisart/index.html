<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Background · AdaptiveResonance.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../democards/gridtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="AdaptiveResonance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">AdaptiveResonance.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li class="is-active"><a class="tocitem" href>Background</a><ul class="internal"><li><a class="tocitem" href="#What-is-Adaptive-Resonance-Theory?"><span>What is Adaptive Resonance Theory?</span></a></li><li><a class="tocitem" href="#ART-Basics"><span>ART Basics</span></a></li><li><a class="tocitem" href="#History-and-Development"><span>History and Development</span></a></li></ul></li><li><a class="tocitem" href="../basic-example/">Basic Example</a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../man/guide/">Guide</a></li><li><a class="tocitem" href="../../examples/">Examples</a></li><li><a class="tocitem" href="../../man/modules/">Modules</a></li><li><a class="tocitem" href="../../man/contributing/">Contributing</a></li><li><a class="tocitem" href="../../man/full-index/">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Getting Started</a></li><li class="is-active"><a href>Background</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Background</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AP6YC/AdaptiveResonance.jl/blob/master/docs/src/getting-started/whatisart.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h1><p>This page provides a theoretical overview of Adaptive Resonance Theory and what this project aims to accomplish.</p><h2 id="What-is-Adaptive-Resonance-Theory?"><a class="docs-heading-anchor" href="#What-is-Adaptive-Resonance-Theory?">What is Adaptive Resonance Theory?</a><a id="What-is-Adaptive-Resonance-Theory?-1"></a><a class="docs-heading-anchor-permalink" href="#What-is-Adaptive-Resonance-Theory?" title="Permalink"></a></h2><p>Adaptive Resonance Theory (commonly abbreviated to ART) is both a <strong>neurological theory</strong> and a <strong>family of neurogenitive neural network models for machine learning</strong>.</p><p>ART began as a neurocognitive theory of how fields of cells can continuously learn stable representations, and it evolved into the basis for a myriad of practical machine learning algorithms. Pioneered by Stephen Grossberg and Gail Carpenter, the field has had contributions across many years and from many disciplines, resulting in a plethora of engineering applications and theoretical advancements that have enabled ART-based algorithms to compete with many other modern learning and clustering algorithms.</p><p>Because of the high degree of interplay between the neurocognitive theory and the engineering models born of it, the term ART is frequently used to refer to both in the modern day (for better or for worse).</p><p>Stephen Grossberg&#39;s has recently released a book summarizing the work of him, his wife Gail Carpenter, and his colleagues on Adaptive Resonance Theory in his book <a href="https://www.amazon.com/Conscious-Mind-Resonant-Brain-Makes/dp/0190070552">Conscious Brain, Resonant Mind</a>.</p><h2 id="ART-Basics"><a class="docs-heading-anchor" href="#ART-Basics">ART Basics</a><a id="ART-Basics-1"></a><a class="docs-heading-anchor-permalink" href="#ART-Basics" title="Permalink"></a></h2><p><img src="../../assets/figures/art.png" alt="art"/></p><h3 id="ART-Dynamics"><a class="docs-heading-anchor" href="#ART-Dynamics">ART Dynamics</a><a id="ART-Dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#ART-Dynamics" title="Permalink"></a></h3><p>Nearly every ART model shares a basic set of dynamics:</p><ol><li>ART models typically have two layers/fields denoted F1 and F2.</li><li>The F1 field is the feature representation field.  Most often, it is simply the input feature sample itself (after some necessary preprocessing).</li><li>The F2 field is the category representation field.  With some exceptions, each node in the F2 field generally represents its own category.  This is most easily understood as a weight vector representing a prototype for a class or centroid of a cluster.</li><li>An activation function is used to find the order of categories &quot;most activated&quot; for a given sample in F1.</li><li>In order of highest activation, a match function is used to compute the agreement between the sample and the categories.</li><li>If the match function for a category evaluates to a value above a threshold known as the vigilance parameter (<span>$\rho$</span>), the weights of that category may be updated according to a learning rule.</li><li>If there is complete mismatch across all categories, then a new categories is created according to some instantiation rule.</li></ol><h3 id="ART-Considerations"><a class="docs-heading-anchor" href="#ART-Considerations">ART Considerations</a><a id="ART-Considerations-1"></a><a class="docs-heading-anchor-permalink" href="#ART-Considerations" title="Permalink"></a></h3><p>In addition to the dynamics typical of an ART model, you must know:</p><ol><li>ART models are inherently designed for unsupervised learning (i.e., learning in the absense of supervisory labels for samples).  This is also known as clustering.</li><li>ART models are capable of supervised learning and reinforcement learning through some redesign and/or combination of ART models.  For example, ARTMAP models are combinations of two ART models in a special way, one learning feature-to-category mappings and another learning category-to-label mappingss.  ART modules are used for reinforcement learning by representing the mappings between state, value, and action spaces with ART dynamics.</li><li>Almost all ART models face the problem of the appropriate selection of the vigilance parameter, which may depend in its optimality according to the problem.</li><li>Being a class of neurogenitive neural network models, ART models gain the ability for theoretically infinite capacity along with the problem of &quot;category proliferation,&quot; which is the undesirable increase in the number of categories as the model continues to learn, leading to increasing computational time.  In contrast, while the evaluation time of a deep neural network is always <em>exactly the same</em>, there exist upper bounds in their representational capacity.</li><li>Nearly every ART model requires feature normalization (i.e., feature elements lying within <span>$[0,1]$</span>) and a process known as complement coding where the feature vector is appended to its vector complement <span>$[1-\bar{x}]$</span>. This is because real-numbered vectors can be arbitrarily close to one another, hindering learning performance, which requires a degree of contrast enhancement between samples to ensure their separation.</li></ol><p>To learn about their implementations, nearly every practical ART model is listed in a recent <a href="https://arxiv.org/abs/1905.11437">ART survey paper by Leonardo Enzo Brito da Silva</a>.</p><h2 id="History-and-Development"><a class="docs-heading-anchor" href="#History-and-Development">History and Development</a><a id="History-and-Development-1"></a><a class="docs-heading-anchor-permalink" href="#History-and-Development" title="Permalink"></a></h2><p>At a high level, ART began with a neural network model known as the Grossberg Network named after Stephen Grossberg. This network treats the firing of neurons in frequency domain as basic shunting models, which are recurrently connected to increase their own activity while suppressing the activities of others nearby (i.e., on-center, off-surround). Using this shunting model, Grossberg shows that autonomous, associative learning can occur with what are known as instar networks.</p><p>By representing categories as a field of instar networks, new categories could be optimally learned by the instantiation of new neurons. However, it was shown that the learning stability of Grossberg Networks degrades as the number of represented categories increases. Discoveries in the neurocognitive theory and breakthroughs in their implementation led to the introduction of a recurrent connections between the two fields of the network to stabilize the learning. These breakthroughs were based upon the discovery that autonomous learning depends on the interplay and agreement between <em>perception</em> and <em>expectation</em>, frequently referred to as bottom-up and top-down processes. Furthermore, it is <em>resonance</em> between these states in the frequency domain that gives rise to conscious experiences and that permit adaptive weights to change, leading to the phenomenon of learning. The theory has many explanatory consequences in psychology, such as why attention is required for learning, but its consequences in the engineering models are that it stabilizes learning in cooperative-competitive dynamics, such as interconnected fields of neurons, which are most often chaotic.</p><p>Chapters 18 and 19 of the book by <a href="https://hagan.okstate.edu/NNDesign.pdf">Neural Network Design by Hagan, Demuth, Beale, and De Jesus</a> provide a good theoretical basis for learning how these network models were eventually implemented into the first binary-vector implementation of ART1.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../basic-example/">Basic Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Friday 29 April 2022 21:48">Friday 29 April 2022</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
