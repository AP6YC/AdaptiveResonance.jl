var documenterSearchIndex = {"docs":
[{"location":"getting-started/basic-example/#Basic-Example","page":"Basic Example","title":"Basic Example","text":"","category":"section"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"This page demonstrates a full basic example of an AdaptiveResonance.jl workflow. In the example below, we create a dataset generated from two multivariate Gaussian distributions in two dimensions, showing how an ART module can be used in unsupervised or simple supervised modes alongside an ARTMAP module that is explicitly supervised-only.","category":"page"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"For more examples that you can run yourself in Julia notebooks, see the Examples page.","category":"page"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"# Copyright © 2021 Alexander L. Hayes\n# MIT License\n\nusing AdaptiveResonance\nusing Distributions, Random\nusing MLDataUtils\nusing Plots\n\n\"\"\"\nDemonstrates Unsupervised DDVFA, Supervised DDVFA, and (Supervised) SFAM on a toy problem\nwith two multivariate Gaussians.\n\"\"\"\n\n# Setup two multivariate Gaussians and sampling 1000 points from each.\n\nrng = MersenneTwister(1234)\ndist1 = MvNormal([0.0, 6.0], [1.0 0.0; 0.0 1.0])\ndist2 = MvNormal([4.5, 6.0], [2.0 -1.5; -1.5 2.0])\n\nN_POINTS = 1000\n\nX = hcat(rand(rng, dist1, N_POINTS), rand(rng, dist2, N_POINTS))\ny = vcat(ones(Int64, N_POINTS), zeros(Int64, N_POINTS))\n\np1 = scatter(X[1,:], X[2,:], group=y, title=\"Original Data\")\n\n(X_train, y_train), (X_test, y_test) = stratifiedobs((X, y))\n\n# Standardize data types\nX_train = convert(Matrix{Float64}, X_train)\nX_test = convert(Matrix{Float64}, X_test)\ny_train = convert(Vector{Int}, y_train)\ny_test = convert(Vector{Int}, y_test)\n\n# Unsupervised DDVFA\nart = DDVFA()\ntrain!(art, X_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np2 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Unsupervised DDVFA\")\n\n# Supervised DDVFA\nart = DDVFA()\ntrain!(art, X_train, y=y_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np3 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Supervised DDVFA\", xlabel=\"Performance: \" * string(round(performance(y_hat_test, y_test); digits=3)))\n\n# Supervised SFAM\nart = SFAM()\ntrain!(art, X_train, y_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np4 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Supervised SFAM\", xlabel=\"Performance: \" * string(round(performance(y_hat_test, y_test); digits=3)))\n\n# Performance Measure + display the plots\nplot(p1, p2, p3, p4, layout=(1, 4), legend = false, xtickfontsize=6, xguidefontsize=8, titlefont=font(8))","category":"page"},{"location":"man/contributing/#Contributing","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This page serves as the contribution guide for the AdaptiveResonance.jl package. From top to bottom, the ways of contributing are:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"GitHub Issues: how to raise an issue with the project.\nJulia Development: how to download and interact with the package.\nGitFlow: how to directly contribute code to the package in an organized way on GitHub.\nDevelopment Details: how the internals of the package are currently setup if you would like to directly contribute code.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Please also see the Attribution to learn about the authors and sources of support for the project.","category":"page"},{"location":"man/contributing/#Issues","page":"Contributing","title":"Issues","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The main point of contact is the GitHub issues page for the project. This is the easiest way to contribute to the project, as any issue you find or request you have will be addressed there by the authors of the package. Depending on the issue, the authors will collaborate with you, and after making changes they will link a pull request which addresses your concern or implements your proposed changes.","category":"page"},{"location":"man/contributing/#Julia-Development","page":"Contributing","title":"Julia Development","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"As a Julia package, development follows the usual procedure:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Clone the project from GitHub\nSwitch to or create the branch that you wish work on (see GitFlow).\nStart Julia at your development folder.\nInstantiate the package (i.e., download and install the package dependencies).","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"For example, you can get the package and startup Julia with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"git clone git@github.com:AP6YC/AdaptiveResonance.jl.git\njulia --project=.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"note: Note\nIn Julia, you must activate your project in the current REPL to point to the location/scope of installed packages. The above immediately activates the project when starting up Julia, but you may also separately startup the julia and activate the package with the interactive package manager via the ] syntax:julia\njulia> ]\n(@v.10) pkg> activate .\n(AdaptiveResonance) pkg>","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"You may run the package's unit tests after the above setup in Julia with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"julia> using Pkg\njulia> Pkg.instantiate()\njulia> Pkg.test()","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"or interactively though the Julia package manager with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"julia> ]\n(AdaptiveResonance) pkg> instantiate\n(AdaptiveResonance) pkg> test","category":"page"},{"location":"man/contributing/#GitFlow","page":"Contributing","title":"GitFlow","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The AdaptiveResonance.jl package follows the GitFlow git working model. The original post by Vincent Driessen outlines this methodology quite well, while Atlassian has a good tutorial as well. In summary:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Create a feature branch off of the develop branch with the name feature/<my-feature-name>.\nCommit your changes and push to this feature branch.\nWhen you are satisfied with your changes, initiate a GitHub pull request (PR) to merge the feature branch with develop.\nIf the unit tests pass, the feature branch will first be merged with develop and then be deleted.\nReleases will be periodically initiated from the develop branch and versioned onto the master branch.\nImmediate bug fixes circumvent this process through a hotfix branch off of master.","category":"page"},{"location":"man/contributing/#Development-Details","page":"Contributing","title":"Development Details","text":"","category":"section"},{"location":"man/contributing/#Documentation","page":"Contributing","title":"Documentation","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"These docs are currently hosted as a static site on the GitHub pages platform. They are setup to be built and served in a separate branch called gh-pages from the master/development branches of the project.","category":"page"},{"location":"man/contributing/#Package-Structure","page":"Contributing","title":"Package Structure","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The AdaptiveResonance.jl package has the following file structure:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"AdaptiveResonance\n├── .github/workflows       // GitHub: workflows for testing and documentation.\n├── docs                    // Docs: documentation for the module.\n│   └───src                 //      Documentation source files.\n├── examples                // Source: example usage scripts.\n├── src                     // Source: majority of source code.\n│   ├───ART                 //      ART-based unsupervised modules.\n│   │   ├───distributed     //      Distributed ART modules.\n│   │   └───single          //      Undistributed ART modules.\n│   └───ARTMAP              //      ARTMAP-based supervised modules.\n├── test                    // Test: Unit, integration, and environment tests.\n│   ├── adaptiveresonance   //      Tests common to the entire package.\n│   ├── art                 //      Tests for just ART modules.\n│   ├── artmap              //      Tests for just ARTMAP modules.\n│   └───data                //      CI test data.\n├── .appveyor               // Appveyor: Windows-specific coverage.\n├── .gitattributes          // Git: LFS settings, languages, etc.\n├── .gitignore              // Git: .gitignore for the whole project.\n├── CODE_OF_CONDUCT.md      // Doc: the code of conduct for contributors.\n├── CONTRIBUTING.md         // Doc: contributing guide (points to this page).\n├── LICENSE                 // Doc: the license to the project.\n├── Project.toml            // Julia: the Pkg.jl dependencies of the project.\n└── README.md               // Doc: this document.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"ART and ARTMAP algorithms are put into their own files within the src/ART/ and src/ARTMAP/ directories, respectively. Both of these directories have an \"index\" file where each module is \"included\" (i.e., src/ART/ART.jl), which is in turn \"included\" in the package module file src/AdaptiveResonance.jl.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Abstract types and common structures/methods are included at the top of the package module file. All public methods and structs (i.e., for the end user) are \"exported\" at the end of this file.","category":"page"},{"location":"man/contributing/#ART-Module-Workflow","page":"Contributing","title":"ART Module Workflow","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"To write an ART module for this project, it will require the following:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"A train! and classify method (within the module).\nAn keyword-options struct using the Parameters.jl macro @with_kw with assertions to keep the parameters within correct ranges.\nThree constructors:\nAn empty constructor (i.e. DDVFA()).\nA keyword argument constructor (passing the kwargs to the options struct defined above).\nA constructor with the options struct passed itself.\nUse of common type aliases in method definitions.\nAn internal DataConfig for setting up the data configuration, especially with data_setup! (src/common.jl).\nAn update_iter evaluation for each iteration (src/common.jl).\nInclusion to the correct ART index file (i.e., src/ART/ART.jl).\nExports of the names for the options and types in the top-level module definition (src/AdaptiveResonance.jl).","category":"page"},{"location":"man/contributing/#DataConfig","page":"Contributing","title":"DataConfig","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The original implementation of ART1 uses binary vectors, which have guaranteed separation between distinct vectors. Real-valued ART modules, however, face the problem of permitting vectors to be arbitrarily close to one another. Therefore, nearly every real-valued ART module uses [0, 1] normalization and complement-coding. This is reflected in the DataConfig struct in the common file src/common.jl.","category":"page"},{"location":"man/contributing/#Type-Aliases","page":"Contributing","title":"Type Aliases","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"For convenience in when defining types and function signatures, this package uses the NumericalTypeAliases.jl package and the aliases therein. The documentation for the abstract and concrete types provided by NumericalTypeAliases.jl can be found here.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"In this package, data samples are always Real-valued (with the notable exception of ART1), while class labels are integered. Furthermore, independent class labels are always Int because of the Julia native support for a given system's signed native integer type.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This project does not currently test for the support of arbitrary precision arithmetic because learning algorithms in general do not have a significant need for precision.","category":"page"},{"location":"man/contributing/#Attribution","page":"Contributing","title":"Attribution","text":"","category":"section"},{"location":"man/contributing/#Authors","page":"Contributing","title":"Authors","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This package is developed and maintained by Sasha Petrenko with sponsorship by the Applied Computational Intelligence Laboratory (ACIL). The users @aaronpeikert, @hayesall, and @markNZed have graciously contributed their time with reviews and feedback that has greatly improved the project.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"If you simply have suggestions for improvement, Sasha Petrenko (<sap625@mst.edu>) is the current developer and maintainer of the AdaptiveResonance.jl package, so please feel free to reach out with thoughts and questions.","category":"page"},{"location":"man/contributing/#Support","page":"Contributing","title":"Support","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This project is supported by grants from the Night Vision Electronic Sensors Directorate, the DARPA Lifelong Learning Machines (L2M) program, Teledyne Technologies, and the National Science Foundation. The material, findings, and conclusions here do not necessarily reflect the views of these entities.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-22-2-0209. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.","category":"page"},{"location":"man/guide/#Package-Guide","page":"Guide","title":"Package Guide","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance.jl package is built upon ART modules that contain all of the state information during training and inference. The ART modules are driven by options, which are themselves mutable keyword argument structs from the Parameters.jl package.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To work with AdaptiveResonance.jl, you should know:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"How to install the package\nART module basics\nHow to use ART module options\nART vs. ARTMAP\nART stats logging","category":"page"},{"location":"man/guide/#installation","page":"Guide","title":"Installation","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance package can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"julia> ]\n(@v.10) pkg> add AdaptiveResonance","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Alternatively, it can be added to your environment in a script with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"using Pkg\nPkg.add(\"AdaptiveResonance\")","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you wish to have the latest changes between releases, you can directly add the GitHub repo at an arbitrary branch (such as develop) as a dependency with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"julia> ]\n(@v.10) pkg> add https://github.com/AP6YC/AdaptiveResonance.jl#develop","category":"page"},{"location":"man/guide/#art_modules","page":"Guide","title":"ART Modules","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To work with ART modules, you should know:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Their basic methods\nIncremental vs. batch modes\nSupervised vs. unsupervised learning modes\nMismatch vs. Best-Matching-Unit","category":"page"},{"location":"man/guide/#methods","page":"Guide","title":"Methods","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Every ART module is equipped with several constructors, a training function train!, and a classification/inference function classify. ART models are mutable structs, and they can be instantiated with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"art = DDVFA()","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For more ways to customize instantiation, see the ART options section.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To train and test these models, you use the train! and classify functions upon the models. Because training changes the internal parameters of the ART models and classification does not, train! uses an exclamation point while classify does not, following Julia standard usage.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, we may load data of some sort and train/test like so:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Load the data from some source with a train/test split\ntrain_x, train_y, test_x, test_y = load_some_data()\n\n# Instantiate an arbitrary ART module\nart = DDVFA()\n\n# Train the module on the training data, getting the prescribed cluster labels\ny_hat_train = train!(art, train_x)\n\n# Conduct inference\ny_hat_test = classify(art, test_x)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nBecause Julia arrays are column-major in memory, the AdaptiveResonance.jl package follows the Julia convention of assuming 2-D data arrays are in the shape of (n_features, n_samples).","category":"page"},{"location":"man/guide/#incremental_vs_batch","page":"Guide","title":"Incremental vs. Batch","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This training and testing may be done in either incremental or batch modes:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create a destination container for the incremental examples\nn_train = length(train_y)\nn_test = length(test_y)\ny_hat_train_incremental = zeros(Integer, n_train)\ny_hat_test_incremental = zeros(Integer, n_test)\n\n# Loop over all training samples\nfor i = 1:n_train\n    y_hat_train_incremental[i] = train!(art, train_x[:, i])\nend\n\n# loop over all testing samples\nfor i = 1:n_test\n    y_hat_test_incremental[i] = classify(art, test_x[:, i])\nend","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This is done through checking the dimensionality of the inputs. For example, if a matrix (i.e., 2-D array) is passed to the train! function, then the data is assumed to be (n_features, n_samples), and the module is trained on all samples. However, if the data is a vector (i.e., 1-D array), then the vector is interpreted as a single sample.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"When supervised (see supervised vs. unsupervised), the dimensions of the labels must correspond to the dimensions of the data. For example, a 2-D matrix of the data must accompany a 1-D vector of labels, while a 1-D vector of a single data sample must accompany a single integer label.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Batch and incremental modes can be used interchangably after module instantiation.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nThe first time that an ART module is trained, it infers the data parameters (e.g., feature dimensions, feature ranges, etc.) to setup the internal data configuration. This happens automatically in batch mode, but it cannot happen if the module is only trained incrementally. If you know the dimensions and minimum/maximum values of the features and want to train incrementally, you can use the function data_setup! after module instantiation, which can be used a number of ways. If you have the batch data available, you can set up with# Manually setup the data config with the data itself\ndata_setup!(art, data.train_x)If you do not have the batch data available, you can directly create a DataConfig with the minimums and maximums (inferring the number of features from the lengths of these vectors):# Get the mins and maxes vectors with some method\nmins, maxes = get_some_data_mins_maxes()\n\n# Directly update the data config\nart.config = DataConfig(mins, maxes)If all of the features share the same minimums and maximums, then you can use them as long as you specify the number of features:# Get the global minimum, maximum, and feature dimension somehow\nmin, max, dim = get_some_data_characteristics()\n\n# Directly update the data config with these global values\nart.config = DataConfig(min, max, dim)","category":"page"},{"location":"man/guide/#supervised_vs_unsupervised","page":"Guide","title":"Supervised vs. Unsupervised","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"ARTMAP modules require a supervised label argument because their formulations typically map internal cluster categories to labels:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create an arbitrary ARTMAP module\nartmap = DAM()\n\n# Conduct supervised learning\ny_hat_train = train!(artmap, train_x, train_y)\n\n# Conduct inference\ny_hat_test = classify(artmap, test_x)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"In the case of ARTMAP, the returned training labels y_hat_train will always match the training labels train_y by definition. In addition to the classification accuracy (ranging from 0 to 1), you can test that the training labels match with the function performance:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Verify that the training labels match\nperf_train = performance(y_hat_train, train_y)\n\n# Get the classification accuracy\nperf_test = performance(y_hat_test, test_y)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"However, many ART modules, though unsupervised by definition, can also be trained in a supervised way by naively mapping categories to labels (more in ART vs. ARTMAP).","category":"page"},{"location":"man/guide/#mismatch-bmu","page":"Guide","title":"Mismatch vs. Best-Matching-Unit","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"During inference, ART algorithms report the category that satisfies the match/vigilance criterion (see Background). By default, in the case that no category satisfies this criterion the module reports a mismatch as -1. In modules that support it, a keyword argument get_bmu (default is false) can be used in the classify method to get the \"best-matching unit\", which is the category that maximizes the activation. This can be interpreted as the \"next-best guess\" of the model in the case that the sample is sufficiently different from anything that the model has seen. For example,","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Conduct inference, getting the best-matching unit in case of complete mismatch\ny_hat_bmu = classify(my_art, test_x, get_bmu=true)","category":"page"},{"location":"man/guide/#art_options","page":"Guide","title":"ART Options","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This section contains:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"An overview of ART options\nA summary of all available options\nAdvanced activation, match, and update usage","category":"page"},{"location":"man/guide/#art_options_overview","page":"Guide","title":"Options Overview","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance package is designed for maximum flexibility for scientific research, even though this may come at the cost of learning instability if misused. Because of the diversity of ART modules, the package is structured around instantiating separate modules and using them for training and inference. Due to this diversity, each module has its own options struct with keyword arguments. These options have default values driven by standards in their respective literatures, so the ART modules may be used immediately without any customization. Furthermore, these options are mutable, so they may be modified before module instantiation, before training, or even after training.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, you can get going with the default options by creating an ART module with the default constructor:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA()","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you want to change the parameters before construction, you can create an options struct, modify it, then instantiate your ART module with it:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art_opts = opts_DDVFA()\nmy_art_opts.gamma = 3\nmy_art = DDVFA(my_art_opts)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The options are objects from the Parameters.jl project, so they can be instantiated even with keyword arguments:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art_opts = opts_DDVFA(gamma = 3)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"You can also pass these keyword arguments directly to the ART model when constructing it with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA(gamma = 3)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"You can even modify the parameters on the fly after the ART module has been instantiated by directly modifying the options within the module:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA()\nmy_art.opts.gamma = 3","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Because of the @assert feature of the Parameters.jl package, each parameter is forced to lie within certain bounds by definition in the literature during options instantiation. However, it is possible to change these parameter values beyond their predefined bounds after instantiation.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nYou must be careful when changing option values during or after training, as it may result in some undefined behavior. Modify the ART module options after instantiation at your own risk and discretion.","category":"page"},{"location":"man/guide/#art_options_summary","page":"Guide","title":"ART Options Summary","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Though most parameters differ between each ART and ARTMAP module, they all share some quality-of-life options and parameters shared by all ART algorithms:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"display::Bool: a flag to display or suppress progress bars and logging messages during training and testing.\nmax_epochs::Int: the maximum number of epochs to train over the data, regardless if other stopping conditions have not been met yet.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Otherwise, most ART and ARTMAP modules share the following nomenclature for algorithmic parameters:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"rho::Float: ART vigilance parameter [0, 1].\nalpha::Float: Choice parameter > 0.\nbeta::Float: Learning parameter (0, 1].\nepsilon::Float: Match tracking parameter (0, 1).\nmatch::Symbol: A symbolic name of the match function used (i.e., :basic_match). Valid names are listed in MATCH_FUNCTIONS.\nactivation::Symbol: A symbolic name of the activation function used (i.e., :basic_activation). Valid names are listed in ACTIVATION_FUNCTIONS.\nupdate::Symbol: A symbolic name of the weight update function used (i.e., :basic_update). Valid names are listed in UPDATE_FUNCTIONS.","category":"page"},{"location":"man/guide/#art_activation_match_update_functions","page":"Guide","title":"ART Activation, Match, and Update Functions","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Though their implementations may vary, all ART and ARTMAP modules require the computation of a match function, and activation function, and a method of updating weights when learning. Both ART and ARTMAP modules can now swap out their activation, match, and update functions thanks to Julia's metaprogramming capabilities. This is done by setting the match, activation, or update options of the ART options struct with a symbol of the function to use, such as with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_opts = opts_FuzzyART(match=:choice_by_difference, activation=:basic_activation, update=:basic_update)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"A list of all available activation, match, and update functions is provided in the ACTIVATION_FUNCTIONS, [MATCH_FUNCTIONS], and UPDATE_FUNCTIONS constants, respectively.","category":"page"},{"location":"man/guide/#art_vs_artmap","page":"Guide","title":"ART vs. ARTMAP","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"ART modules are generally unsupervised in formulation, so they do not explicitly require supervisory labels to their training examples. However, many of these modules can be formulated in the simplified ARTMAP style whereby the ART B module has a vigilance parameter of 1, directly mapping the categories of the ART A module to any provided supervisory labels.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This is done in the training stage through the optional keyword argument y=...:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create an arbitrary ART module\nart = DDVFA()\n\n# Naively prescribe supervised labels to cluster categories\ny_hat_train = train!(art, train_x, y=train_y)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This can also be done incrementally with the same function:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Get the number of training samples and create a results container\nn_train = length(train_y)\ny_hat_train_incremental = zeros(Int, n_train)\n\n# Train incrementally over all training samples\nfor i = 1:n_train\n    y_hat_train_incremental[i] = train!(art, train_x[:, i], y=train_y[i])\nend","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Without provided labels, the ART modules behave as expected, incrementally creating categories when necessary during the training phase.","category":"page"},{"location":"man/guide/#art_stats","page":"Guide","title":"ART Stats Logging","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you are curious about what the activation and match values were after either incremental training or classifiation, all ART modules implement basic statistics dictionaries in their stats field with the following entries:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"T: the activation value of the most recent winning node (i.e., the best-matching unit).\nM: the match value of the most recent winning node.\nbmu: the integer index of the best-matching unit.\nmismatch: whether a mismatch occurred during the most recent training/classification iteration.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"These fields are useful if you wish to know the degree to which a sample is recognized by your ART module and agrees with its understanding of the data.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, you may train a model on some random data (rather inneffectually, but simply for illustration purposes):","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create a FuzzyART module with default options\nmy_art = FuzzyART()\n# Use three feature dimensions\ndim = 3\n# Create ten random samples\nn_samples = 10\n# Create random features and integer labels\nfeatures = rand(dim, n_samples)\nlabels = rand(1:3, n_samples)\n# Train the module in simple supervised mode\ntrain!(my_art, features, y=labels)\n# See what the activation and match values were for the last sample\nT_bmu = my_art.stats[\"T\"]\nM_bmu = my_art.stats[\"M\"]\n# We can also see which node was the best-matching unit and whether mismatch occured\nbmu_index = my_art.stats[\"bmu\"]\nmismatch_flag = my_art.stats[\"mismatch\"]","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/art/ddvfa_supervised.jl\"","category":"page"},{"location":"examples/art/ddvfa_supervised/#ddvfa_supervised","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"","category":"section"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"DDVFA is an unsupervised clustering algorithm by definition, but it can be adaptived for supervised learning by mapping the module's internal categories to the true labels. ART modules such as DDVFA can also be used in simple supervised mode where provided labels are used in place of internal incremental labels for the clusters, providing a method of assessing the clustering performance when labels are available.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(([5.9 6.9 6.0 4.8 5.4 6.3 5.8 6.4 6.0 5.5 5.1 6.3 6.3 5.5 7.7 7.0 4.9 4.6 4.4 7.2 5.2 5.4 4.5 5.7 5.1 6.7 6.1 6.7 7.7 5.9 6.7 6.5 5.4 6.5 6.1 5.6 6.1 5.7 5.1 5.5 6.1 4.6 6.4 7.7 5.5 6.9 7.9 6.8 6.4 4.9 5.9 6.0 5.7 6.8 6.3 7.2 4.8 4.7 5.6 6.4 4.4 4.9 6.4 6.7 6.1 5.0 5.8 5.7 5.2 6.3 4.6 5.5 5.0 5.7 6.9 5.8 5.4 5.7 5.7 6.1 7.7 4.9 5.1 5.0 6.7 7.6 5.5 6.5 4.4 5.7 5.0 6.4 5.1 4.9 5.0 6.7 5.0 5.0 6.5 6.6 4.6 7.1 7.4 5.4 5.0; 3.0 3.1 3.4 3.1 3.4 3.3 4.0 2.8 2.2 2.3 2.5 2.3 2.5 4.2 3.0 3.2 2.4 3.1 3.2 3.0 3.4 3.9 2.3 4.4 3.5 3.1 3.0 3.1 2.8 3.2 3.3 2.8 3.4 3.2 2.8 3.0 2.9 2.8 3.8 3.5 2.8 3.4 3.2 3.8 2.5 3.2 3.8 2.8 2.8 3.1 3.0 3.0 2.6 3.0 3.4 3.6 3.4 3.2 2.5 3.1 3.0 3.0 2.7 3.1 2.6 3.4 2.7 3.0 2.7 3.3 3.2 2.4 2.0 2.5 3.1 2.7 3.0 2.8 3.8 3.0 2.6 2.5 3.8 3.5 3.3 3.0 2.4 3.0 2.9 2.9 3.0 3.2 3.3 3.1 3.4 3.0 3.5 3.3 3.0 2.9 3.6 3.0 2.8 3.7 3.6; 4.2 4.9 4.5 1.6 1.5 4.7 1.2 5.6 5.0 4.0 3.0 4.4 5.0 1.4 6.1 4.7 3.3 1.5 1.3 5.8 1.4 1.7 1.3 1.5 1.4 4.7 4.9 5.6 6.7 4.8 5.7 4.6 1.7 5.1 4.7 4.5 4.7 4.5 1.9 1.3 4.0 1.4 4.5 6.7 4.0 5.7 6.4 4.8 5.6 1.5 5.1 4.8 3.5 5.5 5.6 6.1 1.6 1.3 3.9 5.5 1.3 1.4 5.3 4.4 5.6 1.5 3.9 4.2 3.9 6.0 1.4 3.8 3.5 5.0 5.4 5.1 4.5 4.1 1.7 4.6 6.9 4.5 1.5 1.6 5.7 6.6 3.7 5.5 1.4 4.2 1.6 5.3 1.7 1.5 1.6 5.0 1.3 1.4 5.8 4.6 1.0 5.9 6.1 1.5 1.4; 1.5 1.5 1.6 0.2 0.4 1.6 0.2 2.2 1.5 1.3 1.1 1.3 1.9 0.2 2.3 1.4 1.0 0.2 0.2 1.6 0.2 0.4 0.3 0.4 0.3 1.5 1.8 2.4 2.0 1.8 2.5 1.5 0.2 2.0 1.2 1.5 1.4 1.3 0.4 0.2 1.3 0.3 1.5 2.2 1.3 2.3 2.0 1.4 2.1 0.1 1.8 1.8 1.0 2.1 2.4 2.5 0.2 0.2 1.1 1.8 0.2 0.2 1.9 1.4 1.4 0.2 1.2 1.2 1.4 2.5 0.2 1.1 1.0 2.0 2.1 1.9 1.5 1.3 0.3 1.4 2.3 1.7 0.3 0.6 2.1 2.1 1.0 1.8 0.2 1.3 0.2 2.3 0.5 0.1 0.4 1.7 0.3 0.2 2.2 1.3 0.2 2.1 1.9 0.2 0.2], [2, 2, 2, 1, 1, 2, 1, 3, 3, 2, 2, 2, 3, 1, 3, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 3, 3, 3, 2, 3, 2, 1, 3, 2, 2, 2, 2, 1, 1, 2, 1, 2, 3, 2, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 3, 1, 1, 2, 3, 1, 1, 3, 2, 3, 1, 2, 2, 2, 3, 1, 2, 2, 3, 3, 3, 2, 2, 1, 2, 3, 3, 1, 1, 3, 3, 2, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 3, 2, 1, 3, 3, 1, 1]), ([6.9 5.1 6.7 6.5 6.2 5.6 5.1 6.0 5.8 4.8 5.2 5.6 5.4 6.7 6.8 6.0 6.3 5.6 7.3 5.6 4.7 5.8 5.0 5.1 7.2 6.3 4.3 6.4 5.0 6.3 6.2 6.2 5.2 5.5 6.3 4.8 5.8 6.6 5.3 5.1 5.8 6.2 6.0 4.9 4.8; 3.1 3.7 3.0 3.0 3.4 2.9 3.4 2.9 2.8 3.4 3.5 2.7 3.9 2.5 3.2 2.7 2.5 2.8 2.9 3.0 3.2 2.7 2.3 3.5 3.2 2.8 3.0 2.9 3.2 2.7 2.9 2.2 4.1 2.6 2.9 3.0 2.6 3.0 3.7 3.8 2.7 2.8 2.2 3.1 3.0; 5.1 1.5 5.2 5.2 5.4 3.6 1.5 4.5 5.1 1.9 1.5 4.2 1.3 5.8 5.9 5.1 4.9 4.9 6.3 4.1 1.6 4.1 3.3 1.4 6.0 5.1 1.1 4.3 1.2 4.9 4.3 4.5 1.5 4.4 5.6 1.4 4.0 4.4 1.5 1.6 5.1 4.8 4.0 1.5 1.4; 2.3 0.4 2.3 2.0 2.3 1.3 0.2 1.5 2.4 0.2 0.2 1.3 0.4 1.8 2.3 1.6 1.5 2.0 1.8 1.3 0.2 1.0 1.0 0.2 1.8 1.5 0.1 1.3 0.2 1.8 1.3 1.5 0.1 1.2 1.8 0.3 1.2 1.4 0.2 0.2 1.9 1.8 1.0 0.1 0.1], [3, 1, 3, 3, 3, 2, 1, 2, 3, 1, 1, 2, 1, 3, 3, 2, 2, 3, 3, 2, 1, 2, 2, 1, 3, 3, 1, 2, 1, 3, 2, 2, 1, 2, 3, 1, 2, 2, 1, 1, 3, 3, 2, 1, 1]))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Now, we can create our DDVFA module. We'll do so with the default contstructor, though the module itself has many options that you can alter during instantiation.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"art = DDVFA()","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.7\n  rho_ub: Float64 0.85\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.85\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We can train the model in batch mode upon the data in a simple supervised mode. We do so by passing the integer vector of labels to the training method with the simple keyword y. Just as in unsupervised training, we can extract the module's prescribed labels from the training method, which should match up to the training labels as we will see later.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Train in simple supervised mode by passing the labels as a keyword argument.\ny_hat_train = train!(art, X_train, y=y_train)\nprintln(\"Training labels: \",  size(y_hat_train), \" \", typeof(y_hat_train))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We can classify the testing data to see how we generalize. At the same time, we can see the effect of getting the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Classify both ways\ny_hat = AdaptiveResonance.classify(art, X_test)\ny_hat_bmu = AdaptiveResonance.classify(art, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"Testing labels: \",  size(y_hat), \" \", typeof(y_hat))\nprintln(\"Testing labels with bmu: \",  size(y_hat_bmu), \" \", typeof(y_hat_bmu))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Testing labels: (45,) Vector{Int64}\nTesting labels with bmu: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Finally, we can calculate the performances (number correct over total) of the model upon all three regimes:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training data\nTesting data\nTesting data with get_bmu=true","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train = performance(y_hat_train, y_train)\nperf_test = performance(y_hat, y_test)\nperf_test_bmu = performance(y_hat_bmu, y_test)\n\n# Format each performance number for comparison\n@printf \"Training performance: %.4f\\n\" perf_train\n@printf \"Testing performance: %.4f\\n\" perf_test\n@printf \"Best-matching unit testing performance: %.4f\\n\" perf_test_bmu","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training performance: 1.0000\nTesting performance: 0.9111\nBest-matching unit testing performance: 0.9111\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"man/modules/#modules-page","page":"Modules","title":"Modules","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This project implements a number of ART-based models with options that modulate their behavior (see the options section of the Guide)","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This page lists both the implemented models and some of their variants","category":"page"},{"location":"man/modules/#Implemented-Models","page":"Modules","title":"Implemented Models","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This project has implementations of the following ART (unsupervised) and ARTMAP (supervised) modules:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"CurrentModule=AdaptiveResonance","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"ART\nFuzzyART: Fuzzy ART\nDVFA: Dual Vigilance Fuzzy ART\nDDVFA: Distributed Dual Vigilance Fuzzy ART\nARTMAP\nSFAM: Simplified Fuzzy ARTMAP\nFAM: Fuzzy ARTMAP","category":"page"},{"location":"man/modules/#modules-variants","page":"Modules","title":"Variants","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Each module contains many options that modulate its behavior. Some of these options are used to modulate the internals of the module, such as switching the match and activation functions, to achieve different modules that are found in the literature.","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"These variants are:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"ART\nGammaNormalizedFuzzyART: Gamma-Normalized FuzzyART\nARTMAP\nDAM: Default ARTMAP","category":"page"},{"location":"man/modules/#Gamma-Normalized-FuzzyART","page":"Modules","title":"Gamma-Normalized FuzzyART","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"A Gamma-Normalized FuzzyART is implemented as a FuzzyART module where the gamma normalization option is set on gamma_normalization=true and the kernel width parameter is set to gamma = 10 (gamma_ref is 1.0 by default). It can be created with the convenience constructor:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_gnfa = GammaNormalizedFuzzyART()","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Under the hood, this simply does","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_gnfa = FuzzyART(gamma_normalization=true)","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"which also sets the match and activation function options to match=:gamma_match and activation=:gamma_activation, respectively.","category":"page"},{"location":"man/modules/#Default-ARTMAP","page":"Modules","title":"Default ARTMAP","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"A Default ARTMAP is implemented as a Simplified FuzzyARTMAP module where the activation function is set to Default ARTMAP's choice-by difference function via activation=:choice_by_difference. It can be created with the convenience constructor:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_dam = DAM()","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Under the hood, this simply does","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_dam = SFAM(activation=:choice_by_difference)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/art/ddvfa_unsupervised.jl\"","category":"page"},{"location":"examples/art/ddvfa_unsupervised/#ddvfa_unsupervised","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"","category":"section"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"DDVFA is an unsupervised clustering algorithm by definition, so it can be used to cluster a set of samples all at once in batch mode.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for loading some data.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Extract the features into a local variable\nfeatures = iris.features","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"4×150 Matrix{Float64}:\n 5.1  4.9  4.7  4.6  5.0  5.4  4.6  5.0  4.4  4.9  5.4  4.8  4.8  4.3  5.8  5.7  5.4  5.1  5.7  5.1  5.4  5.1  4.6  5.1  4.8  5.0  5.0  5.2  5.2  4.7  4.8  5.4  5.2  5.5  4.9  5.0  5.5  4.9  4.4  5.1  5.0  4.5  4.4  5.0  5.1  4.8  5.1  4.6  5.3  5.0  7.0  6.4  6.9  5.5  6.5  5.7  6.3  4.9  6.6  5.2  5.0  5.9  6.0  6.1  5.6  6.7  5.6  5.8  6.2  5.6  5.9  6.1  6.3  6.1  6.4  6.6  6.8  6.7  6.0  5.7  5.5  5.5  5.8  6.0  5.4  6.0  6.7  6.3  5.6  5.5  5.5  6.1  5.8  5.0  5.6  5.7  5.7  6.2  5.1  5.7  6.3  5.8  7.1  6.3  6.5  7.6  4.9  7.3  6.7  7.2  6.5  6.4  6.8  5.7  5.8  6.4  6.5  7.7  7.7  6.0  6.9  5.6  7.7  6.3  6.7  7.2  6.2  6.1  6.4  7.2  7.4  7.9  6.4  6.3  6.1  7.7  6.3  6.4  6.0  6.9  6.7  6.9  5.8  6.8  6.7  6.7  6.3  6.5  6.2  5.9\n 3.5  3.0  3.2  3.1  3.6  3.9  3.4  3.4  2.9  3.1  3.7  3.4  3.0  3.0  4.0  4.4  3.9  3.5  3.8  3.8  3.4  3.7  3.6  3.3  3.4  3.0  3.4  3.5  3.4  3.2  3.1  3.4  4.1  4.2  3.1  3.2  3.5  3.1  3.0  3.4  3.5  2.3  3.2  3.5  3.8  3.0  3.8  3.2  3.7  3.3  3.2  3.2  3.1  2.3  2.8  2.8  3.3  2.4  2.9  2.7  2.0  3.0  2.2  2.9  2.9  3.1  3.0  2.7  2.2  2.5  3.2  2.8  2.5  2.8  2.9  3.0  2.8  3.0  2.9  2.6  2.4  2.4  2.7  2.7  3.0  3.4  3.1  2.3  3.0  2.5  2.6  3.0  2.6  2.3  2.7  3.0  2.9  2.9  2.5  2.8  3.3  2.7  3.0  2.9  3.0  3.0  2.5  2.9  2.5  3.6  3.2  2.7  3.0  2.5  2.8  3.2  3.0  3.8  2.6  2.2  3.2  2.8  2.8  2.7  3.3  3.2  2.8  3.0  2.8  3.0  2.8  3.8  2.8  2.8  2.6  3.0  3.4  3.1  3.0  3.1  3.1  3.1  2.7  3.2  3.3  3.0  2.5  3.0  3.4  3.0\n 1.4  1.4  1.3  1.5  1.4  1.7  1.4  1.5  1.4  1.5  1.5  1.6  1.4  1.1  1.2  1.5  1.3  1.4  1.7  1.5  1.7  1.5  1.0  1.7  1.9  1.6  1.6  1.5  1.4  1.6  1.6  1.5  1.5  1.4  1.5  1.2  1.3  1.5  1.3  1.5  1.3  1.3  1.3  1.6  1.9  1.4  1.6  1.4  1.5  1.4  4.7  4.5  4.9  4.0  4.6  4.5  4.7  3.3  4.6  3.9  3.5  4.2  4.0  4.7  3.6  4.4  4.5  4.1  4.5  3.9  4.8  4.0  4.9  4.7  4.3  4.4  4.8  5.0  4.5  3.5  3.8  3.7  3.9  5.1  4.5  4.5  4.7  4.4  4.1  4.0  4.4  4.6  4.0  3.3  4.2  4.2  4.2  4.3  3.0  4.1  6.0  5.1  5.9  5.6  5.8  6.6  4.5  6.3  5.8  6.1  5.1  5.3  5.5  5.0  5.1  5.3  5.5  6.7  6.9  5.0  5.7  4.9  6.7  4.9  5.7  6.0  4.8  4.9  5.6  5.8  6.1  6.4  5.6  5.1  5.6  6.1  5.6  5.5  4.8  5.4  5.6  5.1  5.1  5.9  5.7  5.2  5.0  5.2  5.4  5.1\n 0.2  0.2  0.2  0.2  0.2  0.4  0.3  0.2  0.2  0.1  0.2  0.2  0.1  0.1  0.2  0.4  0.4  0.3  0.3  0.3  0.2  0.4  0.2  0.5  0.2  0.2  0.4  0.2  0.2  0.2  0.2  0.4  0.1  0.2  0.1  0.2  0.2  0.1  0.2  0.2  0.3  0.3  0.2  0.6  0.4  0.3  0.2  0.2  0.2  0.2  1.4  1.5  1.5  1.3  1.5  1.3  1.6  1.0  1.3  1.4  1.0  1.5  1.0  1.4  1.3  1.4  1.5  1.0  1.5  1.1  1.8  1.3  1.5  1.2  1.3  1.4  1.4  1.7  1.5  1.0  1.1  1.0  1.2  1.6  1.5  1.6  1.5  1.3  1.3  1.3  1.2  1.4  1.2  1.0  1.3  1.2  1.3  1.3  1.1  1.3  2.5  1.9  2.1  1.8  2.2  2.1  1.7  1.8  1.8  2.5  2.0  1.9  2.1  2.0  2.4  2.3  1.8  2.2  2.3  1.5  2.3  2.0  2.0  1.8  2.1  1.8  1.8  1.8  2.1  1.6  1.9  2.0  2.2  1.5  1.4  2.3  2.4  1.8  1.8  2.1  2.4  2.3  1.9  2.3  2.5  2.3  1.9  2.0  2.3  1.8","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Next, we will instantiate a DDVFA module. We could create an options struct for reuse with opts=opts_DDVFA(...), but for now we will use the direct keyword arguments approach.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"art = DDVFA(rho_lb=0.6, rho_ub=0.75)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"To train the module on the training data, we use train!. The train method returns the prescribed cluster labels, which are just what the algorithm believes are unique/separate cluster. This is because we are doing unsupervised learning rather than supervised learning with known labels.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"y_hat_train = train!(art, features)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"150-element Vector{Int64}:\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 2\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 4\n 3\n 4\n 4\n 3\n 4\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 3\n 4\n 3\n 5\n 3\n 5\n 3\n 5\n 5\n 3\n 5\n 5\n 5\n 3\n 3\n 5\n 3\n 3\n 3\n 5\n 5\n 5\n 3\n 5\n 3\n 5\n 3\n 5\n 5\n 3\n 3\n 5\n 5\n 5\n 5\n 5\n 3\n 3\n 5\n 5\n 3\n 3\n 5\n 5\n 5\n 3\n 5\n 5\n 5\n 3\n 3\n 5\n 3","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Though we could inspect the unique entries in the list above, we can see the number of categories directly from the art module.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"art.n_categories","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"5","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Because DDVFA actually has FuzzyART modules for F2 nodes, each category has its own category prototypes. We can see the total number of weights in the DDVFA module by summing n_categories across all F2 nodes.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"total_vec = [art.F2[i].n_categories for i = 1:art.n_categories]\ntotal_cat = sum(total_vec)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"21","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/index.md\"","category":"page"},{"location":"examples/#examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"This section contains some examples using the AdaptiveResonance.jl package with topics ranging from how to the internals of package work to practical examples on different datasets.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"These examples are separated into the following sections:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"AdaptiveResonance: examples exploring the various components of the package, such as how the options structs work and how to train incremental vs batch modes.\nART: examples using ART modules in unsupervised and simple supervised modes.\nARTMAP: examples using ARTMAP modules for supervised learning.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"examples/#AdaptiveResonance","page":"Examples","title":"AdaptiveResonance","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"These examples demonstrate different aspects of usage that are common to all modules in the package, such as incremental vs. batch learning and how to use module options.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how the data configuration object works for data preprocessing in ART modules that require it.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"ART DataConfig Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how to use incremental training methods vs. batch training for all ART modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Incremental vs. Batch Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how to use options and modify the options for all ART and ARTMAP modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"ART Options Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/#ART","page":"Examples","title":"ART","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"All ART modules learn in an unsupervised (i.e. clustering) mode by default, but they all can accept labels in the simplified ARTMAP fashion (see the Package Guide).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use DDVFA for simple supervised learning by clustering Iris samples and mapping the modules internal categories to the true labels.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Supervised DDVFA Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use DDVFA for unsupervised learning by clustering Iris samples.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Unsupervised DDVFA Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/#ARTMAP","page":"Examples","title":"ARTMAP","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"ARTMAP modules are supervised by definition, so they require supervised labels in the training stage. These examples demonstrate different use-cases with ARTMAP modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use a Simplified FuzzyARTMAP (SFAM) module to conduct supervised learning on the Iris dataset.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Supervised Simplified FuzzyARTMAP (SFAM) Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/options.jl\"","category":"page"},{"location":"examples/adaptive_resonance/options/#options","page":"ART Options Example","title":"ART Options Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/options/#Overview","page":"ART Options Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"The AdaptiveResonance.jl package has several ways of handling options for ART modules. These methods are meant to give maximum flexibility to the user for sharing and interpreting options, which themselves vary between each module.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"note: Note\nFor more info on options in ART modules, see the guide in the docs on ART options.","category":"page"},{"location":"examples/adaptive_resonance/options/#ART-Options","page":"ART Options Example","title":"ART Options","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"To get a feel for the ART options system, we will inspect different options and their instantiation methods.","category":"page"},{"location":"examples/adaptive_resonance/options/#Inspection","page":"ART Options Example","title":"Inspection","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"First, we load AdaptiveResonance:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"using AdaptiveResonance","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Every ART module has a default constructor, which can be instantiated in the usual way:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a FuzzyART module with default options\nmy_fuzzyart = FuzzyART()\ntypeof(my_fuzzyart)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Within every ART module is a Parameters.jl struct named opts containing the options for the module","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Check the FuzzyART options\nmy_fuzzyart.opts","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Note that the options here have the type opts_FuzzyART. This nomenclature is used throughout the module to indicate an options type associated with an ART module. For example, the options for a DDVFA module are opts_DDVFA:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a DDVFA module and check the type of the options\nmy_ddvfa = DDVFA()\ntypeof(my_ddvfa.opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_DDVFA","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In fact, we can create an instance of these options with a default constructor:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a separate options struct\nmy_fuzzyart_opts = opts_FuzzyART()","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In addition to the default constructor, we can construct ART modules by instantiating these options and passing them to the module during construction:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Instantiate an ART module by passing our options\nmy_fuzzyart = FuzzyART(my_fuzzyart_opts)\nmy_other_fuzzyart = FuzzyART(my_fuzzyart_opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/#Specifying-Options","page":"ART Options Example","title":"Specifying Options","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now to the good stuff: because of the behavior of the Parameters.jl type, each option has a default value that we can modify during instantiation with keyword arguments:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Change some of the default FuzzyART options\nmy_fuzzyart_opts = opts_FuzzyART(\n    rho=0.6,\n    gamma_normalization=true\n)\nmy_fuzzyart = FuzzyART(my_fuzzyart_opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"As some syntactic sugar, we can pass these keyword arguments directly to the module during instantiation if we have no need to share option structs:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Pass these keyword arguments to the module directly\nmy_fuzzyart = FuzzyART(\n    rho=0.6,\n    gamma_normalization=true\n)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Before training, we can also instantiate the model and alter the options afterward:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"my_fuzzyart = FuzzyART()\nmy_fuzzyart.opts.rho=0.6","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"0.6","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"note: Note\nAll ART modules are designed to use this options struct internally when the parameters are needed. It is possible to change these parameters in the middle of training and evaluation, but some algorithmic instability may occur.","category":"page"},{"location":"examples/adaptive_resonance/options/#Comparison","page":"ART Options Example","title":"Comparison","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"To see the effect that changing these parameters has on the modules, we can train and test them side-by-side.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"using MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing\nusing MultivariateStats # Principal component analysis (PCA)\nusing Plots             # Plotting frontend\ngr()                    # Use the default GR backend explicitly","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Plots.GRBackend()","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(([6.3 5.6 4.4 5.4 5.7 5.1 6.3 5.7 7.2 6.0 6.8 5.7 4.8 5.8 5.5 6.9 4.4 4.9 5.2 5.1 6.1 6.7 4.9 7.0 5.7 7.7 5.1 6.0 6.4 6.0 5.1 5.3 6.5 5.6 6.0 5.8 6.6 5.9 6.7 5.7 6.5 5.0 6.3 4.9 6.7 4.8 6.5 6.7 5.0 6.4 7.7 4.6 4.7 5.2 5.9 5.0 5.5 6.3 5.0 6.2 5.0 6.3 6.2 5.5 5.6 5.6 5.8 6.1 5.0 6.0 4.5 6.4 6.9 7.6 4.9 4.6 5.1 4.8 6.3 4.6 6.2 6.1 5.4 4.4 6.9 7.7 5.1 6.3 6.2 7.4 5.0 7.7 6.3 5.1 5.1 7.2 4.3 5.2 7.1 7.2 5.4 6.5 5.8 6.7 6.1; 3.3 2.5 2.9 3.9 4.4 3.8 2.7 2.8 3.2 2.2 2.8 2.8 3.4 2.8 2.5 3.1 3.2 3.1 3.5 3.5 2.9 3.1 3.1 3.2 3.8 2.6 3.5 2.2 2.8 2.7 3.7 3.7 3.0 3.0 3.0 2.7 3.0 3.2 3.0 2.6 3.0 2.0 2.9 3.1 3.0 3.0 2.8 3.3 3.4 2.8 3.8 3.4 3.2 4.1 3.0 3.0 2.3 2.5 3.3 2.8 3.5 2.8 3.4 2.6 2.8 2.9 2.7 3.0 3.6 2.9 2.3 3.1 3.2 3.0 2.5 3.1 2.5 3.4 2.3 3.6 2.9 2.8 3.4 3.0 3.1 2.8 3.3 3.4 2.2 2.8 2.3 3.0 2.5 3.8 3.4 3.6 3.0 3.4 3.0 3.0 3.0 3.2 2.6 3.3 3.0; 4.7 3.9 1.4 1.3 1.5 1.9 4.9 4.5 6.0 5.0 4.8 4.1 1.9 5.1 4.0 5.1 1.3 1.5 1.5 1.4 4.7 4.7 1.5 4.7 1.7 6.9 1.4 4.0 5.6 5.1 1.5 1.5 5.5 4.1 4.8 5.1 4.4 4.8 5.2 3.5 5.8 3.5 5.6 1.5 5.0 1.4 4.6 5.7 1.6 5.6 6.7 1.4 1.3 1.5 4.2 1.6 4.0 5.0 1.4 4.8 1.3 5.1 5.4 4.4 4.9 3.6 3.9 4.9 1.4 4.5 1.3 5.5 5.7 6.6 4.5 1.5 3.0 1.6 4.4 1.0 4.3 4.0 1.5 1.3 4.9 6.7 1.7 5.6 4.5 6.1 3.3 6.1 4.9 1.6 1.5 6.1 1.1 1.4 5.9 5.8 4.5 5.1 4.0 5.7 4.6; 1.6 1.1 0.2 0.4 0.4 0.4 1.8 1.3 1.8 1.5 1.4 1.3 0.2 2.4 1.3 2.3 0.2 0.1 0.2 0.3 1.4 1.5 0.1 1.4 0.3 2.3 0.2 1.0 2.2 1.6 0.4 0.2 1.8 1.3 1.8 1.9 1.4 1.8 2.3 1.0 2.2 1.0 1.8 0.1 1.7 0.1 1.5 2.1 0.4 2.1 2.2 0.3 0.2 0.1 1.5 0.2 1.3 1.9 0.2 1.8 0.3 1.5 2.3 1.2 2.0 1.3 1.2 1.8 0.2 1.5 0.3 1.8 2.3 2.1 1.7 0.2 1.1 0.2 1.3 0.2 1.3 1.3 0.4 0.2 1.5 2.0 0.5 2.4 1.5 1.9 1.0 2.3 1.5 0.2 0.2 2.5 0.1 0.2 2.1 1.6 1.5 2.0 1.2 2.5 1.4], [2, 2, 1, 1, 1, 1, 3, 2, 3, 3, 2, 2, 1, 3, 2, 3, 1, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 2, 3, 2, 1, 1, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 3, 3, 1, 1, 1, 2, 1, 2, 3, 1, 3, 1, 3, 3, 2, 3, 2, 2, 3, 1, 2, 1, 3, 3, 3, 3, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 3, 1, 3, 2, 3, 2, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2, 3, 2, 3, 2]), ([4.8 5.0 5.8 6.8 5.5 6.0 5.2 5.1 6.1 6.4 5.4 5.5 5.7 5.8 6.3 6.7 5.5 6.7 5.8 4.9 4.8 5.4 5.7 4.6 5.4 4.7 7.3 6.7 6.9 5.6 6.4 5.6 7.9 6.4 5.7 5.0 6.1 6.8 6.5 5.9 6.4 5.5 5.0 6.6 4.9; 3.1 3.5 2.7 3.0 2.4 3.4 2.7 3.8 2.8 2.9 3.9 4.2 3.0 4.0 3.3 3.1 3.5 3.1 2.7 2.4 3.0 3.4 2.9 3.2 3.7 3.2 2.9 2.5 3.1 2.7 3.2 3.0 3.8 3.2 2.5 3.2 2.6 3.2 3.0 3.0 2.7 2.4 3.4 2.9 3.0; 1.6 1.6 5.1 5.5 3.8 4.5 3.9 1.5 4.7 4.3 1.7 1.4 4.2 1.2 6.0 4.4 1.3 5.6 4.1 3.3 1.4 1.7 4.2 1.4 1.5 1.6 6.3 5.8 5.4 4.2 5.3 4.5 6.4 4.5 5.0 1.2 5.6 5.9 5.2 5.1 5.3 3.7 1.5 4.6 1.4; 0.2 0.6 1.9 2.1 1.1 1.6 1.4 0.3 1.2 1.3 0.4 0.2 1.2 0.2 2.5 1.4 0.2 2.4 1.0 1.0 0.3 0.2 1.3 0.2 0.2 0.2 1.8 1.8 2.1 1.3 2.3 1.5 2.0 1.5 2.0 0.2 1.4 2.3 2.0 1.8 1.9 1.0 0.2 1.3 0.2], [1, 1, 3, 3, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 3, 2, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 3, 2, 3, 2, 3, 2, 3, 1, 3, 3, 3, 3, 3, 2, 1, 2, 1]))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now we can create several FuzzyART modules with different options.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create two FuzzyARTs with different vigilance values and suppressing logging messages\nrho_1 = 0.5\nrho_2 = 0.7\nmy_fuzzyart_1 = FuzzyART(rho=rho_1, display=false)\nmy_fuzzyart_2 = FuzzyART(rho=rho_2, display=false)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.7\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Here, we will train these FuzzyART modules in simple supervised mode by passing the supervised labels as a keyword argument:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Train in simple supervised mode by passing the labels as a keyword argument.\ny_hat_train_1 = train!(my_fuzzyart_1, X_train, y=y_train)\ny_hat_train_2 = train!(my_fuzzyart_2, X_train, y=y_train)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"105-element Vector{Int64}:\n 2\n 2\n 1\n 1\n 1\n 1\n 3\n 2\n 3\n 3\n 2\n 2\n 1\n 3\n 2\n 3\n 1\n 1\n 1\n 1\n 2\n 2\n 1\n 2\n 1\n 3\n 1\n 2\n 3\n 2\n 1\n 1\n 3\n 2\n 3\n 3\n 2\n 2\n 3\n 2\n 3\n 2\n 3\n 1\n 2\n 1\n 2\n 3\n 1\n 3\n 3\n 1\n 1\n 1\n 2\n 1\n 2\n 3\n 1\n 3\n 1\n 3\n 3\n 2\n 3\n 2\n 2\n 3\n 1\n 2\n 1\n 3\n 3\n 3\n 3\n 1\n 2\n 1\n 2\n 1\n 2\n 2\n 1\n 1\n 2\n 3\n 1\n 3\n 2\n 3\n 2\n 3\n 2\n 1\n 1\n 3\n 1\n 1\n 3\n 3\n 2\n 3\n 2\n 3\n 2","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We then classify the test data with both modules:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"y_hat_1 = AdaptiveResonance.classify(my_fuzzyart_1, X_test, get_bmu=true)\ny_hat_2 = AdaptiveResonance.classify(my_fuzzyart_2, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"FuzzyART 1 labels: \",  size(y_hat_1), \" \", typeof(y_hat_1))\nprintln(\"FuzzyART 2 labels: \",  size(y_hat_2), \" \", typeof(y_hat_2))\n\n# Calculate the performance on the test data\nperf_test_1 = performance(y_hat_1, y_test)\nperf_test_2 = performance(y_hat_2, y_test)\n\n# Format each performance number for comparison\n@printf \"Testing performance rho=%.1f: %.4f\\n\" rho_1 perf_test_1\n@printf \"Testing performance rho=%.1f: %.4f\\n\" rho_2 perf_test_2","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART 1 labels: (45,) Vector{Int64}\nFuzzyART 2 labels: (45,) Vector{Int64}\nTesting performance rho=0.5: 0.9778\nTesting performance rho=0.7: 1.0000\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In addition to having different performances, we can see that there is a subsequent trade-off in the number of categories used:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Print the number of categories for each vigilance parameter\n@printf \"Number of categories rho=%.1f: %i\\n\" rho_1 my_fuzzyart_1.n_categories\n@printf \"Number of categories rho=%.1f: %i\\n\" rho_2 my_fuzzyart_2.n_categories","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Number of categories rho=0.5: 8\nNumber of categories rho=0.7: 16\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"The variation between vigilance parameter, number of categories created during learning, and testing performance/generalization is a central theme in ART-based algorithms.","category":"page"},{"location":"examples/adaptive_resonance/options/#Visualization","page":"ART Options Example","title":"Visualization","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now, to visualize how the two models differ in how they partition the data, we can use principal component analysis (PCA) to compress to two plotting dimensions. PCA is a method to represent a dataset in a different number of dimensions while preserving the relative separation between datapoints. Though most datasets are not able to be effectively transformed down to two dimensions, this technique is useful to get a general sense of how well separated the classes are and how well your algorithm classifies them.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Train a PCA model to visually separate the features in two dimensions.\nM = fit(PCA, features; maxoutdim=2)\n\n# Apply the PCA model to the testing set\nX_test_pca = MultivariateStats.transform(M, X_test)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"2×45 Matrix{Float64}:\n  2.58846   2.40551   -1.41407   -2.16538   0.0703429  -0.807205   0.0101901  2.58735   -0.920503  -0.714008  2.2799    2.59716  -0.331127  2.64354  -2.53173    -0.927573  2.62523  -2.3143    -0.234541   0.751467   2.71567   2.31053   -0.375238   2.84032   2.50653    2.63285   -2.93201   -2.31967   -2.10765   -0.355533  -1.90474   -0.659593  -3.23234  -0.932411  -1.34459   2.867      -1.77964   -2.56332   -1.76405    -1.38967   -1.80234    0.191884  2.62648   -1.0433     2.71539\n -0.197393  0.195917  -0.574925   0.21528  -0.702538    0.195054  -0.720575   0.520474  -0.18239    0.150379  0.747783  1.10002  -0.21118   1.18619  -0.0118422   0.468236  0.6068    0.182609  -0.331922  -1.00111   -0.242681  0.397868  -0.291622  -0.220576  0.651935  -0.190076   0.352377  -0.245548   0.371482  -0.503218   0.118819  -0.351976   1.37052   0.319198  -0.776415  0.0771931  -0.501465   0.275975   0.0785192  -0.282887  -0.216155  -0.677491  0.170405   0.228957  -0.169557","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We can now plot the PCA'ed test set and label them according to the two FuzzyART's We will do so by creating a function for the subplots first as they will share the same format, and we dare not duplicate code. Then, we will plot those subplots side-by-side.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a function for our subplots\nfunction fuzzyart_scatter(data, labels, rho)\n    p = scatter(\n        data[1, :],             # PCA dimension 1\n        data[2, :],             # PCA dimension 2\n        group=labels,           # labels belonging to each point\n        markersize=8,           # size of scatter points\n        xlims = [-4, 4],        # manually set the x-limits\n        title=(@sprintf \"FuzzyART \\$\\\\rho\\$ = %.1f\" rho),  # formatted title\n    )\n    return p\nend\n\n# Create the two scatterplot objects\np1 = fuzzyart_scatter(X_test_pca, y_hat_1, rho_1)\np2 = fuzzyart_scatter(X_test_pca, y_hat_2, rho_2)\n\n# Plot the two scatterplots together\nplot(\n    p1, p2,                 # scatterplot objects\n    layout = (1, 2),        # plot side-by-side\n    ##layout = [a, b],        # plot side-by-side\n    legend = false,         # no legend\n    xtickfontsize = 12,     # x-tick size\n    ytickfontsize = 12,     # y-tick size\n    xlabel = \"\\$PCA_1\\$\",   # x-label\n    ylabel = \"\\$PCA_2\\$\",   # y-label\n    dpi = 300,              # Set the dots-per-inch\n)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip060\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip060)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip061\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip060)\" d=\"M310.676 1405.9 L1152.76 1405.9 L1152.76 123.472 L310.676 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip062\">\n    <rect x=\"310\" y=\"123\" width=\"843\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"521.196,1405.9 521.196,123.472 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"731.716,1405.9 731.716,123.472 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"942.236,1405.9 942.236,123.472 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1152.76,1405.9 1152.76,123.472 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 1152.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"521.196,1405.9 521.196,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"731.716,1405.9 731.716,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"942.236,1405.9 942.236,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1152.76,1405.9 1152.76,1387 \"/>\n<path clip-path=\"url(#clip060)\" d=\"M264.027 1464.66 L308.541 1464.66 L308.541 1470.56 L264.027 1470.56 L264.027 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M342.95 1444.17 L325.242 1471.84 L342.95 1471.84 L342.95 1444.17 M341.11 1438.06 L349.929 1438.06 L349.929 1471.84 L357.325 1471.84 L357.325 1477.68 L349.929 1477.68 L349.929 1489.9 L342.95 1489.9 L342.95 1477.68 L319.547 1477.68 L319.547 1470.91 L341.11 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M476.109 1464.66 L520.623 1464.66 L520.623 1470.56 L476.109 1470.56 L476.109 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M541.803 1484 L566.283 1484 L566.283 1489.9 L533.366 1489.9 L533.366 1484 Q537.359 1479.87 544.234 1472.92 Q551.144 1465.94 552.915 1463.93 Q556.283 1460.14 557.602 1457.54 Q558.956 1454.9 558.956 1452.37 Q558.956 1448.23 556.04 1445.63 Q553.158 1443.03 548.505 1443.03 Q545.206 1443.03 541.526 1444.17 Q537.88 1445.32 533.713 1447.64 L533.713 1440.56 Q537.949 1438.86 541.63 1437.99 Q545.31 1437.12 548.366 1437.12 Q556.421 1437.12 561.213 1441.15 Q566.005 1445.18 566.005 1451.91 Q566.005 1455.11 564.789 1457.99 Q563.609 1460.84 560.449 1464.73 Q559.581 1465.73 554.928 1470.56 Q550.276 1475.35 541.803 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M731.716 1442.68 Q726.299 1442.68 723.556 1448.03 Q720.848 1453.34 720.848 1464.03 Q720.848 1474.69 723.556 1480.04 Q726.299 1485.35 731.716 1485.35 Q737.167 1485.35 739.876 1480.04 Q742.619 1474.69 742.619 1464.03 Q742.619 1453.34 739.876 1448.03 Q737.167 1442.68 731.716 1442.68 M731.716 1437.12 Q740.431 1437.12 745.014 1444.03 Q749.633 1450.91 749.633 1464.03 Q749.633 1477.12 745.014 1484.03 Q740.431 1490.91 731.716 1490.91 Q723.001 1490.91 718.383 1484.03 Q713.799 1477.12 713.799 1464.03 Q713.799 1450.91 718.383 1444.03 Q723.001 1437.12 731.716 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M934.215 1484 L958.694 1484 L958.694 1489.9 L925.778 1489.9 L925.778 1484 Q929.771 1479.87 936.646 1472.92 Q943.555 1465.94 945.326 1463.93 Q948.694 1460.14 950.014 1457.54 Q951.368 1454.9 951.368 1452.37 Q951.368 1448.23 948.451 1445.63 Q945.569 1443.03 940.916 1443.03 Q937.618 1443.03 933.937 1444.17 Q930.292 1445.32 926.125 1447.64 L926.125 1440.56 Q930.361 1438.86 934.042 1437.99 Q937.722 1437.12 940.778 1437.12 Q948.833 1437.12 953.625 1441.15 Q958.416 1445.18 958.416 1451.91 Q958.416 1455.11 957.201 1457.99 Q956.021 1460.84 952.861 1464.73 Q951.993 1465.73 947.34 1470.56 Q942.687 1475.35 934.215 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1157.27 1444.17 L1139.56 1471.84 L1157.27 1471.84 L1157.27 1444.17 M1155.43 1438.06 L1164.25 1438.06 L1164.25 1471.84 L1171.64 1471.84 L1171.64 1477.68 L1164.25 1477.68 L1164.25 1489.9 L1157.27 1489.9 L1157.27 1477.68 L1133.87 1477.68 L1133.87 1470.91 L1155.43 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M693.145 1527.31 Q693.145 1530.92 690.472 1534.24 Q687.831 1537.55 683.515 1539.58 Q679.232 1541.58 674.626 1541.58 L663.419 1541.58 L659.329 1558.07 Q659.296 1558.17 659.2 1558.58 Q659.103 1558.97 659.103 1559.2 Q659.103 1560 660.102 1560.19 Q661.132 1560.39 663.419 1560.39 Q664.9 1560.39 665.126 1560.65 Q665.254 1560.81 665.254 1561.1 Q665.254 1561.55 665.126 1561.87 Q664.997 1562.16 664.739 1562.26 Q664.514 1562.35 664.353 1562.38 Q664.192 1562.42 663.934 1562.42 Q663.258 1562.42 661.808 1562.35 Q660.391 1562.29 659.651 1562.29 L655.432 1562.22 L647.058 1562.42 Q646.06 1562.42 646.06 1561.61 Q646.06 1561 646.317 1560.74 Q646.575 1560.45 646.865 1560.42 Q647.155 1560.39 647.896 1560.39 Q649.506 1560.39 650.472 1560.29 Q651.438 1560.19 652.05 1560.07 Q652.694 1559.9 653.016 1559.45 Q653.371 1559 653.532 1558.62 Q653.693 1558.2 653.918 1557.26 L662.742 1521.84 Q663 1520.77 663 1520.61 Q663 1520.07 662.678 1519.87 Q662.388 1519.65 661.551 1519.55 Q659.941 1519.42 658.717 1519.42 Q657.912 1519.42 657.589 1519.39 Q657.3 1519.36 657.042 1519.2 Q656.817 1519 656.817 1518.62 Q656.817 1518 657.074 1517.75 Q657.364 1517.46 657.686 1517.42 Q658.008 1517.36 658.781 1517.36 L680.166 1517.36 Q686.317 1517.36 689.731 1520.29 Q693.145 1523.22 693.145 1527.31 M687.026 1525.73 Q687.026 1519.42 678.04 1519.42 L671.728 1519.42 Q669.634 1519.42 669.119 1519.81 Q668.604 1520.16 668.153 1521.93 L663.676 1539.87 L672.984 1539.87 Q679.232 1539.87 683.129 1536.36 Q684.9 1534.75 685.963 1531.4 Q687.026 1528.05 687.026 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M743.514 1516.59 L739.359 1533.4 Q739.069 1534.46 738.876 1534.59 Q738.715 1534.72 738.2 1534.72 Q737.201 1534.72 737.201 1534.04 Q737.201 1533.98 737.298 1533.14 Q737.395 1532.27 737.395 1530.69 Q737.395 1524.86 734.561 1521.42 Q731.759 1517.97 726.767 1517.97 Q722.451 1517.97 718.103 1520.16 Q713.788 1522.35 710.696 1525.93 Q708.377 1528.63 706.67 1532.05 Q704.996 1535.46 704.19 1538.58 Q703.417 1541.71 703.063 1544.06 Q702.709 1546.41 702.709 1548.12 Q702.709 1550.6 703.224 1552.69 Q703.772 1554.78 704.738 1556.27 Q705.704 1557.71 706.928 1558.84 Q708.184 1559.94 709.633 1560.58 Q711.115 1561.22 712.596 1561.55 Q714.078 1561.84 715.623 1561.84 Q721.839 1561.84 727.765 1557.01 Q732.467 1553.04 734.432 1546.57 Q734.593 1545.93 735.269 1545.93 Q736.074 1545.93 736.074 1546.57 Q736.074 1546.7 735.913 1547.34 Q735.752 1547.96 735.269 1549.21 Q734.786 1550.44 734.045 1551.82 Q733.304 1553.21 731.92 1554.94 Q730.535 1556.68 728.828 1558.2 Q725.929 1560.71 722.258 1562.29 Q718.586 1563.87 714.561 1563.87 Q709.537 1563.87 705.479 1561.64 Q701.421 1559.42 699.037 1555.27 Q696.686 1551.11 696.686 1545.8 Q696.686 1540.19 699.263 1534.69 Q701.839 1529.18 705.93 1525.09 Q710.02 1521 715.43 1518.46 Q720.841 1515.91 726.251 1515.91 Q728.313 1515.91 730.148 1516.46 Q731.984 1517.01 733.079 1517.68 Q734.206 1518.36 735.205 1519.36 Q736.203 1520.32 736.525 1520.77 Q736.879 1521.23 737.201 1521.77 L741.807 1516.72 Q742.612 1515.91 742.805 1515.91 Q743.192 1515.91 743.353 1516.14 Q743.514 1516.36 743.514 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M788.635 1561.1 Q788.635 1561.71 788.377 1562.03 Q788.152 1562.32 787.927 1562.38 Q787.733 1562.42 787.443 1562.42 Q786.606 1562.42 783.708 1562.32 Q780.809 1562.22 779.972 1562.22 Q778.619 1562.22 775.849 1562.32 Q773.08 1562.42 771.727 1562.42 Q770.825 1562.42 770.825 1561.68 Q770.825 1561.19 770.922 1560.93 Q771.018 1560.65 771.276 1560.55 Q771.566 1560.42 771.727 1560.42 Q771.92 1560.39 772.403 1560.39 Q773.047 1560.39 773.724 1560.32 Q774.4 1560.23 775.237 1560.03 Q776.075 1559.84 776.59 1559.36 Q777.138 1558.87 777.138 1558.2 Q777.138 1557.91 776.912 1555.52 Q776.687 1553.14 776.397 1550.37 Q776.107 1547.57 776.075 1547.18 L759.521 1547.18 Q758.007 1549.79 756.944 1551.6 Q755.882 1553.4 755.495 1554.01 Q755.109 1554.62 754.883 1555.01 Q754.658 1555.4 754.529 1555.62 Q753.595 1557.33 753.595 1558.07 Q753.595 1560.13 756.687 1560.39 Q757.75 1560.39 757.75 1561.16 Q757.75 1561.74 757.492 1562.06 Q757.234 1562.35 757.009 1562.38 Q756.816 1562.42 756.494 1562.42 Q755.431 1562.42 753.209 1562.32 Q750.986 1562.22 749.891 1562.22 Q748.957 1562.22 747.025 1562.32 Q745.093 1562.42 744.223 1562.42 Q743.837 1562.42 743.611 1562.19 Q743.386 1561.97 743.386 1561.68 Q743.386 1561.22 743.45 1560.97 Q743.547 1560.71 743.805 1560.58 Q744.062 1560.45 744.191 1560.45 Q744.32 1560.42 744.771 1560.39 Q747.218 1560.23 749.118 1559.07 Q751.051 1557.88 752.887 1554.82 L775.817 1516.3 Q776.043 1515.91 776.204 1515.72 Q776.365 1515.52 776.687 1515.36 Q777.041 1515.2 777.556 1515.2 Q778.361 1515.2 778.522 1515.46 Q778.683 1515.69 778.78 1516.78 L782.806 1558 Q782.902 1558.87 782.967 1559.23 Q783.063 1559.55 783.482 1559.9 Q783.933 1560.23 784.738 1560.32 Q785.576 1560.39 787.121 1560.39 Q787.701 1560.39 787.927 1560.42 Q788.152 1560.42 788.377 1560.58 Q788.635 1560.74 788.635 1561.1 M775.882 1545.12 L773.788 1523.38 L760.777 1545.12 L775.882 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M795.238 1554.34 L795.238 1552.9 Q800.784 1552.9 803.647 1549.94 Q804.436 1549.94 804.572 1550.12 Q804.707 1550.3 804.707 1551.14 L804.707 1577.04 Q804.707 1578.42 805.383 1578.84 Q806.059 1579.27 809.013 1579.27 L810.478 1579.27 L810.478 1580.69 Q808.855 1580.56 802.993 1580.56 Q797.132 1580.56 795.531 1580.69 L795.531 1579.27 L796.997 1579.27 Q799.905 1579.27 800.604 1578.87 Q801.303 1578.44 801.303 1577.04 L801.303 1553.12 Q798.89 1554.34 795.238 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1369.04 1152.76,1369.04 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1113.98 1152.76,1113.98 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,858.911 1152.76,858.911 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,603.847 1152.76,603.847 \"/>\n<polyline clip-path=\"url(#clip062)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,348.782 1152.76,348.782 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1369.04 329.574,1369.04 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1113.98 329.574,1113.98 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,858.911 329.574,858.911 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,603.847 329.574,603.847 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,348.782 329.574,348.782 \"/>\n<path clip-path=\"url(#clip060)\" d=\"M114.26 1369.72 L158.774 1369.72 L158.774 1375.62 L114.26 1375.62 L114.26 1369.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M175.128 1389.06 L186.586 1389.06 L186.586 1349.51 L174.121 1352.01 L174.121 1345.62 L186.517 1343.12 L193.531 1343.12 L193.531 1389.06 L204.989 1389.06 L204.989 1394.96 L175.128 1394.96 L175.128 1389.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M219.155 1386.14 L226.482 1386.14 L226.482 1394.96 L219.155 1394.96 L219.155 1386.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M256.759 1347.74 Q251.343 1347.74 248.6 1353.08 Q245.891 1358.4 245.891 1369.09 Q245.891 1379.75 248.6 1385.1 Q251.343 1390.41 256.759 1390.41 Q262.211 1390.41 264.919 1385.1 Q267.662 1379.75 267.662 1369.09 Q267.662 1358.4 264.919 1353.08 Q262.211 1347.74 256.759 1347.74 M256.759 1342.18 Q265.475 1342.18 270.058 1349.09 Q274.676 1355.97 274.676 1369.09 Q274.676 1382.18 270.058 1389.09 Q265.475 1395.97 256.759 1395.97 Q248.044 1395.97 243.426 1389.09 Q238.843 1382.18 238.843 1369.09 Q238.843 1355.97 243.426 1349.09 Q248.044 1342.18 256.759 1342.18 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M115.753 1114.65 L160.267 1114.65 L160.267 1120.56 L115.753 1120.56 L115.753 1114.65 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M190.406 1092.67 Q184.989 1092.67 182.246 1098.02 Q179.538 1103.33 179.538 1114.03 Q179.538 1124.69 182.246 1130.03 Q184.989 1135.35 190.406 1135.35 Q195.857 1135.35 198.565 1130.03 Q201.308 1124.69 201.308 1114.03 Q201.308 1103.33 198.565 1098.02 Q195.857 1092.67 190.406 1092.67 M190.406 1087.12 Q199.121 1087.12 203.704 1094.03 Q208.322 1100.9 208.322 1114.03 Q208.322 1127.12 203.704 1134.03 Q199.121 1140.9 190.406 1140.9 Q181.69 1140.9 177.072 1134.03 Q172.489 1127.12 172.489 1114.03 Q172.489 1100.9 177.072 1094.03 Q181.69 1087.12 190.406 1087.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M220.648 1131.08 L227.975 1131.08 L227.975 1139.9 L220.648 1139.9 L220.648 1131.08 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M243.322 1088.06 L270.857 1088.06 L270.857 1093.96 L249.746 1093.96 L249.746 1106.67 Q251.273 1106.15 252.801 1105.9 Q254.329 1105.62 255.857 1105.62 Q264.537 1105.62 269.607 1110.38 Q274.676 1115.14 274.676 1123.26 Q274.676 1131.63 269.468 1136.28 Q264.259 1140.9 254.78 1140.9 Q251.516 1140.9 248.114 1140.35 Q244.746 1139.79 241.134 1138.68 L241.134 1131.63 Q244.259 1133.33 247.593 1134.17 Q250.926 1135 254.641 1135 Q260.648 1135 264.155 1131.84 Q267.662 1128.68 267.662 1123.26 Q267.662 1117.85 264.155 1114.69 Q260.648 1111.53 254.641 1111.53 Q251.829 1111.53 249.016 1112.15 Q246.239 1112.78 243.322 1114.1 L243.322 1088.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M188.913 837.609 Q183.496 837.609 180.753 842.956 Q178.045 848.269 178.045 858.963 Q178.045 869.623 180.753 874.97 Q183.496 880.282 188.913 880.282 Q194.364 880.282 197.072 874.97 Q199.815 869.623 199.815 858.963 Q199.815 848.269 197.072 842.956 Q194.364 837.609 188.913 837.609 M188.913 832.053 Q197.628 832.053 202.211 838.963 Q206.829 845.838 206.829 858.963 Q206.829 872.053 202.211 878.963 Q197.628 885.838 188.913 885.838 Q180.197 885.838 175.579 878.963 Q170.996 872.053 170.996 858.963 Q170.996 845.838 175.579 838.963 Q180.197 832.053 188.913 832.053 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M219.155 876.012 L226.482 876.012 L226.482 884.831 L219.155 884.831 L219.155 876.012 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M256.759 837.609 Q251.343 837.609 248.6 842.956 Q245.891 848.269 245.891 858.963 Q245.891 869.623 248.6 874.97 Q251.343 880.282 256.759 880.282 Q262.211 880.282 264.919 874.97 Q267.662 869.623 267.662 858.963 Q267.662 848.269 264.919 842.956 Q262.211 837.609 256.759 837.609 M256.759 832.053 Q265.475 832.053 270.058 838.963 Q274.676 845.838 274.676 858.963 Q274.676 872.053 270.058 878.963 Q265.475 885.838 256.759 885.838 Q248.044 885.838 243.426 878.963 Q238.843 872.053 238.843 858.963 Q238.843 845.838 243.426 838.963 Q248.044 832.053 256.759 832.053 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M190.406 582.545 Q184.989 582.545 182.246 587.892 Q179.538 593.204 179.538 603.899 Q179.538 614.558 182.246 619.906 Q184.989 625.218 190.406 625.218 Q195.857 625.218 198.565 619.906 Q201.308 614.558 201.308 603.899 Q201.308 593.204 198.565 587.892 Q195.857 582.545 190.406 582.545 M190.406 576.989 Q199.121 576.989 203.704 583.899 Q208.322 590.774 208.322 603.899 Q208.322 616.989 203.704 623.899 Q199.121 630.774 190.406 630.774 Q181.69 630.774 177.072 623.899 Q172.489 616.989 172.489 603.899 Q172.489 590.774 177.072 583.899 Q181.69 576.989 190.406 576.989 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M220.648 620.947 L227.975 620.947 L227.975 629.767 L220.648 629.767 L220.648 620.947 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M243.322 577.927 L270.857 577.927 L270.857 583.829 L249.746 583.829 L249.746 596.538 Q251.273 596.017 252.801 595.774 Q254.329 595.496 255.857 595.496 Q264.537 595.496 269.607 600.253 Q274.676 605.01 274.676 613.135 Q274.676 621.503 269.468 626.156 Q264.259 630.774 254.78 630.774 Q251.516 630.774 248.114 630.218 Q244.746 629.662 241.134 628.551 L241.134 621.503 Q244.259 623.204 247.593 624.037 Q250.926 624.871 254.641 624.871 Q260.648 624.871 264.155 621.711 Q267.662 618.551 267.662 613.135 Q267.662 607.718 264.155 604.558 Q260.648 601.399 254.641 601.399 Q251.829 601.399 249.016 602.024 Q246.239 602.649 243.322 603.968 L243.322 577.927 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M175.128 368.799 L186.586 368.799 L186.586 329.251 L174.121 331.751 L174.121 325.362 L186.517 322.862 L193.531 322.862 L193.531 368.799 L204.989 368.799 L204.989 374.702 L175.128 374.702 L175.128 368.799 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M219.155 365.883 L226.482 365.883 L226.482 374.702 L219.155 374.702 L219.155 365.883 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M256.759 327.48 Q251.343 327.48 248.6 332.827 Q245.891 338.14 245.891 348.834 Q245.891 359.494 248.6 364.841 Q251.343 370.154 256.759 370.154 Q262.211 370.154 264.919 364.841 Q267.662 359.494 267.662 348.834 Q267.662 338.14 264.919 332.827 Q262.211 327.48 256.759 327.48 M256.759 321.925 Q265.475 321.925 270.058 328.834 Q274.676 335.709 274.676 348.834 Q274.676 361.925 270.058 368.834 Q265.475 375.709 256.759 375.709 Q248.044 375.709 243.426 368.834 Q238.843 361.925 238.843 348.834 Q238.843 335.709 243.426 328.834 Q248.044 321.925 256.759 321.925 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M28.8883 804.838 Q32.4954 804.838 35.8126 807.511 Q39.1298 810.152 41.1587 814.467 Q43.1555 818.751 43.1555 823.356 L43.1555 834.564 L59.6449 838.654 Q59.7415 838.686 60.1602 838.783 Q60.5467 838.879 60.7721 838.879 Q61.5772 838.879 61.7705 837.881 Q61.9637 836.85 61.9637 834.564 Q61.9637 833.082 62.2214 832.857 Q62.3824 832.728 62.6722 832.728 Q63.1231 832.728 63.4452 832.857 Q63.735 832.986 63.8317 833.243 Q63.9283 833.469 63.9605 833.63 Q63.9927 833.791 63.9927 834.048 Q63.9927 834.725 63.9283 836.174 Q63.8639 837.591 63.8639 838.332 L63.7995 842.551 L63.9927 850.924 Q63.9927 851.923 63.1875 851.923 Q62.5756 851.923 62.318 851.665 Q62.0281 851.407 61.9959 851.117 Q61.9637 850.828 61.9637 850.087 Q61.9637 848.477 61.8671 847.51 Q61.7705 846.544 61.6417 845.932 Q61.4806 845.288 61.0297 844.966 Q60.5789 844.612 60.1924 844.451 Q59.7737 844.29 58.8398 844.064 L23.4133 835.24 Q22.3505 834.982 22.1895 834.982 Q21.642 834.982 21.4487 835.304 Q21.2233 835.594 21.1267 836.432 Q20.9979 838.042 20.9979 839.266 Q20.9979 840.071 20.9657 840.393 Q20.9335 840.683 20.7724 840.94 Q20.5792 841.166 20.1927 841.166 Q19.5808 841.166 19.3232 840.908 Q19.0333 840.618 19.0011 840.296 Q18.9367 839.974 18.9367 839.201 L18.9367 817.817 Q18.9367 811.665 21.8674 808.251 Q24.7982 804.838 28.8883 804.838 M27.3102 810.957 Q20.9979 810.957 20.9979 819.942 L20.9979 826.255 Q20.9979 828.348 21.3843 828.863 Q21.7386 829.378 23.5099 829.829 L41.4486 834.306 L41.4486 824.998 Q41.4486 818.751 37.9381 814.854 Q36.3279 813.082 32.9784 812.02 Q29.629 810.957 27.3102 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M18.1637 754.469 L34.9752 758.623 Q36.038 758.913 36.1668 759.106 Q36.2956 759.267 36.2956 759.783 Q36.2956 760.781 35.6193 760.781 Q35.5549 760.781 34.7176 760.684 Q33.848 760.588 32.2699 760.588 Q26.4407 760.588 22.9946 763.422 Q19.5486 766.224 19.5486 771.216 Q19.5486 775.531 21.7386 779.879 Q23.9286 784.195 27.5034 787.286 Q30.2087 789.605 33.6226 791.312 Q37.0364 792.987 40.1604 793.792 Q43.2843 794.565 45.6353 794.919 Q47.9864 795.273 49.6933 795.273 Q52.1731 795.273 54.2665 794.758 Q56.3599 794.211 57.8414 793.244 Q59.2906 792.278 60.4178 791.055 Q61.5128 789.798 62.157 788.349 Q62.8011 786.868 63.1231 785.386 Q63.413 783.905 63.413 782.359 Q63.413 776.143 58.5821 770.217 Q54.6208 765.515 48.1474 763.551 Q47.5033 763.39 47.5033 762.713 Q47.5033 761.908 48.1474 761.908 Q48.2762 761.908 48.9203 762.069 Q49.5323 762.23 50.7883 762.713 Q52.0121 763.196 53.397 763.937 Q54.7818 764.678 56.5209 766.063 Q58.26 767.448 59.7737 769.155 Q62.2858 772.053 63.8639 775.725 Q65.442 779.396 65.442 783.422 Q65.442 788.446 63.2197 792.504 Q60.9975 796.562 56.843 798.945 Q52.6884 801.296 47.3745 801.296 Q41.7706 801.296 36.2634 798.719 Q30.7562 796.143 26.6661 792.053 Q22.576 787.963 20.0317 782.552 Q17.4874 777.142 17.4874 771.731 Q17.4874 769.67 18.0349 767.834 Q18.5824 765.998 19.2587 764.903 Q19.9351 763.776 20.9335 762.778 Q21.8996 761.779 22.3505 761.457 Q22.8014 761.103 23.3489 760.781 L18.2926 756.176 Q17.4874 755.37 17.4874 755.177 Q17.4874 754.791 17.7129 754.63 Q17.9383 754.469 18.1637 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M62.6722 709.347 Q63.2842 709.347 63.6062 709.605 Q63.8961 709.83 63.9605 710.056 Q63.9927 710.249 63.9927 710.539 Q63.9927 711.376 63.8961 714.275 Q63.7995 717.173 63.7995 718.011 Q63.7995 719.363 63.8961 722.133 Q63.9927 724.903 63.9927 726.255 Q63.9927 727.157 63.252 727.157 Q62.7689 727.157 62.5112 727.061 Q62.2214 726.964 62.1247 726.706 Q61.9959 726.416 61.9959 726.255 Q61.9637 726.062 61.9637 725.579 Q61.9637 724.935 61.8993 724.259 Q61.8027 723.582 61.6095 722.745 Q61.4162 721.908 60.9331 721.392 Q60.45 720.845 59.7737 720.845 Q59.4839 720.845 57.1006 721.07 Q54.7174 721.296 51.9477 721.586 Q49.1458 721.875 48.7593 721.908 L48.7593 738.461 Q51.368 739.975 53.1715 741.038 Q54.975 742.101 55.587 742.487 Q56.1989 742.874 56.5853 743.099 Q56.9718 743.325 57.1973 743.453 Q58.9042 744.387 59.6449 744.387 Q61.7061 744.387 61.9637 741.296 Q61.9637 740.233 62.7367 740.233 Q63.3164 740.233 63.6384 740.49 Q63.9283 740.748 63.9605 740.973 Q63.9927 741.167 63.9927 741.489 Q63.9927 742.552 63.8961 744.774 Q63.7995 746.996 63.7995 748.091 Q63.7995 749.025 63.8961 750.957 Q63.9927 752.89 63.9927 753.759 Q63.9927 754.146 63.7672 754.371 Q63.5418 754.597 63.252 754.597 Q62.8011 754.597 62.5434 754.532 Q62.2858 754.436 62.157 754.178 Q62.0281 753.92 62.0281 753.791 Q61.9959 753.663 61.9637 753.212 Q61.8027 750.764 60.6433 748.864 Q59.4517 746.932 56.3921 745.096 L17.8739 722.165 Q17.4874 721.94 17.2942 721.779 Q17.101 721.618 16.9399 721.296 Q16.7789 720.941 16.7789 720.426 Q16.7789 719.621 17.0365 719.46 Q17.262 719.299 18.357 719.202 L59.5805 715.177 Q60.45 715.08 60.8043 715.016 Q61.1264 714.919 61.4806 714.5 Q61.8027 714.049 61.8993 713.244 Q61.9637 712.407 61.9637 710.861 Q61.9637 710.281 61.9959 710.056 Q61.9959 709.83 62.157 709.605 Q62.318 709.347 62.6722 709.347 M46.6981 722.101 L24.9592 724.194 L46.6981 737.205 L46.6981 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M82.2693 702.744 Q81.4351 702.744 81.1871 702.676 Q80.9391 702.586 80.5559 702.226 L70.6816 693.366 Q65.2259 688.519 60.4691 688.519 Q57.3806 688.519 55.1712 690.142 Q52.9619 691.743 52.9619 694.696 Q52.9619 696.725 54.2018 698.438 Q55.4418 700.151 57.6511 700.941 Q57.606 700.805 57.606 700.332 Q57.606 699.182 58.3274 698.551 Q59.0488 697.897 60.0182 697.897 Q61.2581 697.897 61.8668 698.709 Q62.453 699.498 62.453 700.287 Q62.453 700.602 62.3854 701.031 Q62.3177 701.437 61.6865 702.09 Q61.0327 702.744 59.883 702.744 Q56.6592 702.744 54.0891 700.309 Q51.5191 697.852 51.5191 694.11 Q51.5191 689.871 54.044 687.098 Q56.5464 684.303 60.4691 684.303 Q61.8443 684.303 63.1068 684.731 Q64.3467 685.137 65.3161 685.701 Q66.2855 686.242 67.841 687.73 Q69.3966 689.218 70.5012 690.412 Q71.6059 691.607 73.9505 694.29 L78.7073 699.182 L78.7073 690.863 Q78.7073 686.805 78.3466 686.49 Q77.6928 686.039 74.2436 685.475 L74.2436 684.303 L82.2693 685.611 L82.2693 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M382.158 3.35044 L416.915 3.35044 L416.915 10.237 L390.341 10.237 L390.341 28.061 L414.322 28.061 L414.322 34.9475 L390.341 34.9475 L390.341 63.8304 L382.158 63.8304 L382.158 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M424.247 45.9254 L424.247 18.4603 L431.7 18.4603 L431.7 45.6419 Q431.7 52.0828 434.212 55.3235 Q436.724 58.5238 441.747 58.5238 Q447.783 58.5238 451.266 54.6754 Q454.791 50.827 454.791 44.1836 L454.791 18.4603 L462.244 18.4603 L462.244 63.8304 L454.791 63.8304 L454.791 56.8629 Q452.077 60.9948 448.471 63.0203 Q444.906 65.0052 440.167 65.0052 Q432.349 65.0052 428.298 60.1441 Q424.247 55.283 424.247 45.9254 M443.002 17.3666 L443.002 17.3666 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M474.356 18.4603 L509.761 18.4603 L509.761 25.2658 L481.729 57.8756 L509.761 57.8756 L509.761 63.8304 L473.344 63.8304 L473.344 57.0249 L501.376 24.4151 L474.356 24.4151 L474.356 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M517.904 18.4603 L553.309 18.4603 L553.309 25.2658 L525.276 57.8756 L553.309 57.8756 L553.309 63.8304 L516.891 63.8304 L516.891 57.0249 L544.923 24.4151 L517.904 24.4151 L517.904 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M583.569 68.0434 Q580.409 76.1452 577.411 78.6162 Q574.414 81.0873 569.391 81.0873 L563.436 81.0873 L563.436 74.8489 L567.811 74.8489 Q570.89 74.8489 572.591 73.3906 Q574.292 71.9322 576.358 66.504 L577.695 63.1013 L559.344 18.4603 L567.244 18.4603 L581.422 53.9462 L595.6 18.4603 L603.499 18.4603 L583.569 68.0434 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M634.327 11.4117 L623.227 41.51 L645.467 41.51 L634.327 11.4117 M629.709 3.35044 L638.985 3.35044 L662.035 63.8304 L653.528 63.8304 L648.019 48.3155 L620.756 48.3155 L615.247 63.8304 L606.619 63.8304 L629.709 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M699.546 35.4741 Q702.179 36.3653 704.65 39.282 Q707.162 42.1986 709.674 47.3027 L717.978 63.8304 L709.187 63.8304 L701.45 48.3155 Q698.453 42.2391 695.617 40.2542 Q692.822 38.2692 687.961 38.2692 L679.049 38.2692 L679.049 63.8304 L670.866 63.8304 L670.866 3.35044 L689.338 3.35044 Q699.708 3.35044 704.812 7.68491 Q709.917 12.0194 709.917 20.7693 Q709.917 26.4811 707.243 30.2484 Q704.61 34.0158 699.546 35.4741 M679.049 10.0749 L679.049 31.5447 L689.338 31.5447 Q695.252 31.5447 698.25 28.8306 Q701.288 26.076 701.288 20.7693 Q701.288 15.4626 698.25 12.789 Q695.252 10.0749 689.338 10.0749 L679.049 10.0749 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M714.089 3.35044 L765.252 3.35044 L765.252 10.237 L743.782 10.237 L743.782 63.8304 L735.559 63.8304 L735.559 10.237 L714.089 10.237 L714.089 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M831.017 40.4256 Q831.017 46.492 827.902 52.1895 Q824.828 57.887 819.991 61.3301 Q815.195 64.7732 810.358 64.7732 Q804.907 64.7732 802.078 59.1167 Q796.955 79.6523 796.668 80.1852 Q795.479 81.9477 793.758 81.9477 Q792.692 81.9477 792.036 81.2919 Q791.38 80.677 791.38 79.6933 Q791.421 79.3654 791.667 78.3406 L799.865 45.3443 Q801.751 37.6793 807.448 32.2277 Q813.187 26.7351 819.335 26.7351 Q824.213 26.7351 827.615 30.3832 Q831.017 34.0312 831.017 40.4256 M824.991 36.8185 Q824.991 32.7196 823.352 30.6701 Q821.712 28.5797 819.171 28.5797 Q816.835 28.5797 814.006 30.4652 Q811.219 32.3507 808.76 36.5316 Q807.448 38.9499 806.505 41.9422 Q805.563 44.9344 803.718 52.3125 Q803.062 55.2637 803.062 55.4276 Q803.062 55.7555 803.226 56.4934 Q803.431 57.2312 803.923 58.3789 Q804.456 59.4856 805.194 60.4693 Q805.931 61.4531 807.284 62.1909 Q808.637 62.8877 810.276 62.8877 Q812.818 62.8877 815.523 60.8382 Q818.269 58.7478 820.278 54.9358 Q821.958 51.8616 823.475 46.0821 Q824.991 40.2616 824.991 36.8185 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M869.493 26.157 L921.425 26.157 L921.425 32.9625 L869.493 32.9625 L869.493 26.157 M869.493 42.6847 L921.425 42.6847 L921.425 49.5713 L869.493 49.5713 L869.493 42.6847 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M982.959 8.73814 Q976.639 8.73814 973.439 14.9765 Q970.279 21.1744 970.279 33.6512 Q970.279 46.0875 973.439 52.3259 Q976.639 58.5238 982.959 58.5238 Q989.318 58.5238 992.478 52.3259 Q995.678 46.0875 995.678 33.6512 Q995.678 21.1744 992.478 14.9765 Q989.318 8.73814 982.959 8.73814 M982.959 2.25669 Q993.126 2.25669 998.473 10.318 Q1003.86 18.3388 1003.86 33.6512 Q1003.86 48.9231 998.473 56.9844 Q993.126 65.0052 982.959 65.0052 Q972.791 65.0052 967.403 56.9844 Q962.056 48.9231 962.056 33.6512 Q962.056 18.3388 967.403 10.318 Q972.791 2.25669 982.959 2.25669 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1018.24 53.5411 L1026.79 53.5411 L1026.79 63.8304 L1018.24 63.8304 L1018.24 53.5411 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1044.69 3.35044 L1076.82 3.35044 L1076.82 10.237 L1052.19 10.237 L1052.19 25.0633 Q1053.97 24.4556 1055.75 24.1721 Q1057.54 23.848 1059.32 23.848 Q1069.45 23.848 1075.36 29.3978 Q1081.27 34.9475 1081.27 44.4266 Q1081.27 54.1893 1075.2 59.6175 Q1069.12 65.0052 1058.06 65.0052 Q1054.25 65.0052 1050.28 64.3571 Q1046.36 63.7089 1042.14 62.4126 L1042.14 54.1893 Q1045.79 56.1742 1049.68 57.1464 Q1053.57 58.1187 1057.9 58.1187 Q1064.91 58.1187 1069 54.4323 Q1073.09 50.746 1073.09 44.4266 Q1073.09 38.1072 1069 34.4209 Q1064.91 30.7346 1057.9 30.7346 Q1054.62 30.7346 1051.34 31.4637 Q1048.1 32.1929 1044.69 33.7322 L1044.69 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip062)\" cx=\"1004.18\" cy=\"959.607\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"984.92\" cy=\"758.968\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1004.06\" cy=\"593.402\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"971.698\" cy=\"477.446\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1005.09\" cy=\"297.758\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1009.98\" cy=\"253.799\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1008.05\" cy=\"549.365\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1017.57\" cy=\"982.71\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"974.922\" cy=\"655.947\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1030.69\" cy=\"971.433\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"995.553\" cy=\"526.34\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1008.85\" cy=\"955.874\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1033.5\" cy=\"819.533\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1008.18\" cy=\"771.982\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"1017.54\" cy=\"945.407\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"739.12\" cy=\"1217.3\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"646.749\" cy=\"759.408\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"732.789\" cy=\"1226.5\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"634.824\" cy=\"951.954\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"656.559\" cy=\"782.198\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"696.862\" cy=\"966.64\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"634.08\" cy=\"620.05\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"707.028\" cy=\"1028.23\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"810.815\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"692.218\" cy=\"1007.68\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"694.293\" cy=\"1115.62\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"662.287\" cy=\"1038.46\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"633.57\" cy=\"696.079\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"544.391\" cy=\"1114.72\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"751.914\" cy=\"1204.52\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"621.898\" cy=\"742.113\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"582.871\" cy=\"1152.2\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"503.788\" cy=\"749.09\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"465.226\" cy=\"864.952\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"488.112\" cy=\"765.757\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"423.093\" cy=\"679.153\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"487.547\" cy=\"984.172\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"509.864\" cy=\"669.407\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"531.223\" cy=\"798.298\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"391.48\" cy=\"159.767\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"590.184\" cy=\"1254.98\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"461.901\" cy=\"718.128\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"546.032\" cy=\"818.856\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"585.44\" cy=\"1003.22\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip062)\" cx=\"542.002\" cy=\"969.178\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<path clip-path=\"url(#clip060)\" d=\"M1510.68 1405.9 L2352.76 1405.9 L2352.76 123.472 L1510.68 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip063\">\n    <rect x=\"1510\" y=\"123\" width=\"843\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1405.9 1510.68,123.472 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1721.2,1405.9 1721.2,123.472 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1931.72,1405.9 1931.72,123.472 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2142.24,1405.9 2142.24,123.472 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2352.76,1405.9 2352.76,123.472 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 2352.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 1510.68,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1721.2,1405.9 1721.2,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1931.72,1405.9 1931.72,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2142.24,1405.9 2142.24,1387 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2352.76,1405.9 2352.76,1387 \"/>\n<path clip-path=\"url(#clip060)\" d=\"M1464.03 1464.66 L1508.54 1464.66 L1508.54 1470.56 L1464.03 1470.56 L1464.03 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1542.95 1444.17 L1525.24 1471.84 L1542.95 1471.84 L1542.95 1444.17 M1541.11 1438.06 L1549.93 1438.06 L1549.93 1471.84 L1557.33 1471.84 L1557.33 1477.68 L1549.93 1477.68 L1549.93 1489.9 L1542.95 1489.9 L1542.95 1477.68 L1519.55 1477.68 L1519.55 1470.91 L1541.11 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1676.11 1464.66 L1720.62 1464.66 L1720.62 1470.56 L1676.11 1470.56 L1676.11 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1741.8 1484 L1766.28 1484 L1766.28 1489.9 L1733.37 1489.9 L1733.37 1484 Q1737.36 1479.87 1744.23 1472.92 Q1751.14 1465.94 1752.91 1463.93 Q1756.28 1460.14 1757.6 1457.54 Q1758.96 1454.9 1758.96 1452.37 Q1758.96 1448.23 1756.04 1445.63 Q1753.16 1443.03 1748.5 1443.03 Q1745.21 1443.03 1741.53 1444.17 Q1737.88 1445.32 1733.71 1447.64 L1733.71 1440.56 Q1737.95 1438.86 1741.63 1437.99 Q1745.31 1437.12 1748.37 1437.12 Q1756.42 1437.12 1761.21 1441.15 Q1766 1445.18 1766 1451.91 Q1766 1455.11 1764.79 1457.99 Q1763.61 1460.84 1760.45 1464.73 Q1759.58 1465.73 1754.93 1470.56 Q1750.28 1475.35 1741.8 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1931.72 1442.68 Q1926.3 1442.68 1923.56 1448.03 Q1920.85 1453.34 1920.85 1464.03 Q1920.85 1474.69 1923.56 1480.04 Q1926.3 1485.35 1931.72 1485.35 Q1937.17 1485.35 1939.88 1480.04 Q1942.62 1474.69 1942.62 1464.03 Q1942.62 1453.34 1939.88 1448.03 Q1937.17 1442.68 1931.72 1442.68 M1931.72 1437.12 Q1940.43 1437.12 1945.01 1444.03 Q1949.63 1450.91 1949.63 1464.03 Q1949.63 1477.12 1945.01 1484.03 Q1940.43 1490.91 1931.72 1490.91 Q1923 1490.91 1918.38 1484.03 Q1913.8 1477.12 1913.8 1464.03 Q1913.8 1450.91 1918.38 1444.03 Q1923 1437.12 1931.72 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2134.22 1484 L2158.69 1484 L2158.69 1489.9 L2125.78 1489.9 L2125.78 1484 Q2129.77 1479.87 2136.65 1472.92 Q2143.56 1465.94 2145.33 1463.93 Q2148.69 1460.14 2150.01 1457.54 Q2151.37 1454.9 2151.37 1452.37 Q2151.37 1448.23 2148.45 1445.63 Q2145.57 1443.03 2140.92 1443.03 Q2137.62 1443.03 2133.94 1444.17 Q2130.29 1445.32 2126.12 1447.64 L2126.12 1440.56 Q2130.36 1438.86 2134.04 1437.99 Q2137.72 1437.12 2140.78 1437.12 Q2148.83 1437.12 2153.62 1441.15 Q2158.42 1445.18 2158.42 1451.91 Q2158.42 1455.11 2157.2 1457.99 Q2156.02 1460.84 2152.86 1464.73 Q2151.99 1465.73 2147.34 1470.56 Q2142.69 1475.35 2134.22 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2357.27 1444.17 L2339.56 1471.84 L2357.27 1471.84 L2357.27 1444.17 M2355.43 1438.06 L2364.25 1438.06 L2364.25 1471.84 L2371.64 1471.84 L2371.64 1477.68 L2364.25 1477.68 L2364.25 1489.9 L2357.27 1489.9 L2357.27 1477.68 L2333.87 1477.68 L2333.87 1470.91 L2355.43 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1893.14 1527.31 Q1893.14 1530.92 1890.47 1534.24 Q1887.83 1537.55 1883.52 1539.58 Q1879.23 1541.58 1874.63 1541.58 L1863.42 1541.58 L1859.33 1558.07 Q1859.3 1558.17 1859.2 1558.58 Q1859.1 1558.97 1859.1 1559.2 Q1859.1 1560 1860.1 1560.19 Q1861.13 1560.39 1863.42 1560.39 Q1864.9 1560.39 1865.13 1560.65 Q1865.25 1560.81 1865.25 1561.1 Q1865.25 1561.55 1865.13 1561.87 Q1865 1562.16 1864.74 1562.26 Q1864.51 1562.35 1864.35 1562.38 Q1864.19 1562.42 1863.93 1562.42 Q1863.26 1562.42 1861.81 1562.35 Q1860.39 1562.29 1859.65 1562.29 L1855.43 1562.22 L1847.06 1562.42 Q1846.06 1562.42 1846.06 1561.61 Q1846.06 1561 1846.32 1560.74 Q1846.58 1560.45 1846.86 1560.42 Q1847.15 1560.39 1847.9 1560.39 Q1849.51 1560.39 1850.47 1560.29 Q1851.44 1560.19 1852.05 1560.07 Q1852.69 1559.9 1853.02 1559.45 Q1853.37 1559 1853.53 1558.62 Q1853.69 1558.2 1853.92 1557.26 L1862.74 1521.84 Q1863 1520.77 1863 1520.61 Q1863 1520.07 1862.68 1519.87 Q1862.39 1519.65 1861.55 1519.55 Q1859.94 1519.42 1858.72 1519.42 Q1857.91 1519.42 1857.59 1519.39 Q1857.3 1519.36 1857.04 1519.2 Q1856.82 1519 1856.82 1518.62 Q1856.82 1518 1857.07 1517.75 Q1857.36 1517.46 1857.69 1517.42 Q1858.01 1517.36 1858.78 1517.36 L1880.17 1517.36 Q1886.32 1517.36 1889.73 1520.29 Q1893.14 1523.22 1893.14 1527.31 M1887.03 1525.73 Q1887.03 1519.42 1878.04 1519.42 L1871.73 1519.42 Q1869.63 1519.42 1869.12 1519.81 Q1868.6 1520.16 1868.15 1521.93 L1863.68 1539.87 L1872.98 1539.87 Q1879.23 1539.87 1883.13 1536.36 Q1884.9 1534.75 1885.96 1531.4 Q1887.03 1528.05 1887.03 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1943.51 1516.59 L1939.36 1533.4 Q1939.07 1534.46 1938.88 1534.59 Q1938.72 1534.72 1938.2 1534.72 Q1937.2 1534.72 1937.2 1534.04 Q1937.2 1533.98 1937.3 1533.14 Q1937.39 1532.27 1937.39 1530.69 Q1937.39 1524.86 1934.56 1521.42 Q1931.76 1517.97 1926.77 1517.97 Q1922.45 1517.97 1918.1 1520.16 Q1913.79 1522.35 1910.7 1525.93 Q1908.38 1528.63 1906.67 1532.05 Q1905 1535.46 1904.19 1538.58 Q1903.42 1541.71 1903.06 1544.06 Q1902.71 1546.41 1902.71 1548.12 Q1902.71 1550.6 1903.22 1552.69 Q1903.77 1554.78 1904.74 1556.27 Q1905.7 1557.71 1906.93 1558.84 Q1908.18 1559.94 1909.63 1560.58 Q1911.11 1561.22 1912.6 1561.55 Q1914.08 1561.84 1915.62 1561.84 Q1921.84 1561.84 1927.77 1557.01 Q1932.47 1553.04 1934.43 1546.57 Q1934.59 1545.93 1935.27 1545.93 Q1936.07 1545.93 1936.07 1546.57 Q1936.07 1546.7 1935.91 1547.34 Q1935.75 1547.96 1935.27 1549.21 Q1934.79 1550.44 1934.05 1551.82 Q1933.3 1553.21 1931.92 1554.94 Q1930.53 1556.68 1928.83 1558.2 Q1925.93 1560.71 1922.26 1562.29 Q1918.59 1563.87 1914.56 1563.87 Q1909.54 1563.87 1905.48 1561.64 Q1901.42 1559.42 1899.04 1555.27 Q1896.69 1551.11 1896.69 1545.8 Q1896.69 1540.19 1899.26 1534.69 Q1901.84 1529.18 1905.93 1525.09 Q1910.02 1521 1915.43 1518.46 Q1920.84 1515.91 1926.25 1515.91 Q1928.31 1515.91 1930.15 1516.46 Q1931.98 1517.01 1933.08 1517.68 Q1934.21 1518.36 1935.2 1519.36 Q1936.2 1520.32 1936.53 1520.77 Q1936.88 1521.23 1937.2 1521.77 L1941.81 1516.72 Q1942.61 1515.91 1942.81 1515.91 Q1943.19 1515.91 1943.35 1516.14 Q1943.51 1516.36 1943.51 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1988.64 1561.1 Q1988.64 1561.71 1988.38 1562.03 Q1988.15 1562.32 1987.93 1562.38 Q1987.73 1562.42 1987.44 1562.42 Q1986.61 1562.42 1983.71 1562.32 Q1980.81 1562.22 1979.97 1562.22 Q1978.62 1562.22 1975.85 1562.32 Q1973.08 1562.42 1971.73 1562.42 Q1970.83 1562.42 1970.83 1561.68 Q1970.83 1561.19 1970.92 1560.93 Q1971.02 1560.65 1971.28 1560.55 Q1971.57 1560.42 1971.73 1560.42 Q1971.92 1560.39 1972.4 1560.39 Q1973.05 1560.39 1973.72 1560.32 Q1974.4 1560.23 1975.24 1560.03 Q1976.07 1559.84 1976.59 1559.36 Q1977.14 1558.87 1977.14 1558.2 Q1977.14 1557.91 1976.91 1555.52 Q1976.69 1553.14 1976.4 1550.37 Q1976.11 1547.57 1976.07 1547.18 L1959.52 1547.18 Q1958.01 1549.79 1956.94 1551.6 Q1955.88 1553.4 1955.5 1554.01 Q1955.11 1554.62 1954.88 1555.01 Q1954.66 1555.4 1954.53 1555.62 Q1953.6 1557.33 1953.6 1558.07 Q1953.6 1560.13 1956.69 1560.39 Q1957.75 1560.39 1957.75 1561.16 Q1957.75 1561.74 1957.49 1562.06 Q1957.23 1562.35 1957.01 1562.38 Q1956.82 1562.42 1956.49 1562.42 Q1955.43 1562.42 1953.21 1562.32 Q1950.99 1562.22 1949.89 1562.22 Q1948.96 1562.22 1947.03 1562.32 Q1945.09 1562.42 1944.22 1562.42 Q1943.84 1562.42 1943.61 1562.19 Q1943.39 1561.97 1943.39 1561.68 Q1943.39 1561.22 1943.45 1560.97 Q1943.55 1560.71 1943.8 1560.58 Q1944.06 1560.45 1944.19 1560.45 Q1944.32 1560.42 1944.77 1560.39 Q1947.22 1560.23 1949.12 1559.07 Q1951.05 1557.88 1952.89 1554.82 L1975.82 1516.3 Q1976.04 1515.91 1976.2 1515.72 Q1976.36 1515.52 1976.69 1515.36 Q1977.04 1515.2 1977.56 1515.2 Q1978.36 1515.2 1978.52 1515.46 Q1978.68 1515.69 1978.78 1516.78 L1982.81 1558 Q1982.9 1558.87 1982.97 1559.23 Q1983.06 1559.55 1983.48 1559.9 Q1983.93 1560.23 1984.74 1560.32 Q1985.58 1560.39 1987.12 1560.39 Q1987.7 1560.39 1987.93 1560.42 Q1988.15 1560.42 1988.38 1560.58 Q1988.64 1560.74 1988.64 1561.1 M1975.88 1545.12 L1973.79 1523.38 L1960.78 1545.12 L1975.88 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1995.24 1554.34 L1995.24 1552.9 Q2000.78 1552.9 2003.65 1549.94 Q2004.44 1549.94 2004.57 1550.12 Q2004.71 1550.3 2004.71 1551.14 L2004.71 1577.04 Q2004.71 1578.42 2005.38 1578.84 Q2006.06 1579.27 2009.01 1579.27 L2010.48 1579.27 L2010.48 1580.69 Q2008.85 1580.56 2002.99 1580.56 Q1997.13 1580.56 1995.53 1580.69 L1995.53 1579.27 L1997 1579.27 Q1999.9 1579.27 2000.6 1578.87 Q2001.3 1578.44 2001.3 1577.04 L2001.3 1553.12 Q1998.89 1554.34 1995.24 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1369.04 2352.76,1369.04 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1113.98 2352.76,1113.98 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,858.911 2352.76,858.911 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,603.847 2352.76,603.847 \"/>\n<polyline clip-path=\"url(#clip063)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,348.782 2352.76,348.782 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 1510.68,123.472 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1369.04 1529.57,1369.04 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1113.98 1529.57,1113.98 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,858.911 1529.57,858.911 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,603.847 1529.57,603.847 \"/>\n<polyline clip-path=\"url(#clip060)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,348.782 1529.57,348.782 \"/>\n<path clip-path=\"url(#clip060)\" d=\"M1314.26 1369.72 L1358.77 1369.72 L1358.77 1375.62 L1314.26 1375.62 L1314.26 1369.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1375.13 1389.06 L1386.59 1389.06 L1386.59 1349.51 L1374.12 1352.01 L1374.12 1345.62 L1386.52 1343.12 L1393.53 1343.12 L1393.53 1389.06 L1404.99 1389.06 L1404.99 1394.96 L1375.13 1394.96 L1375.13 1389.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1419.16 1386.14 L1426.48 1386.14 L1426.48 1394.96 L1419.16 1394.96 L1419.16 1386.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1456.76 1347.74 Q1451.34 1347.74 1448.6 1353.08 Q1445.89 1358.4 1445.89 1369.09 Q1445.89 1379.75 1448.6 1385.1 Q1451.34 1390.41 1456.76 1390.41 Q1462.21 1390.41 1464.92 1385.1 Q1467.66 1379.75 1467.66 1369.09 Q1467.66 1358.4 1464.92 1353.08 Q1462.21 1347.74 1456.76 1347.74 M1456.76 1342.18 Q1465.47 1342.18 1470.06 1349.09 Q1474.68 1355.97 1474.68 1369.09 Q1474.68 1382.18 1470.06 1389.09 Q1465.47 1395.97 1456.76 1395.97 Q1448.04 1395.97 1443.43 1389.09 Q1438.84 1382.18 1438.84 1369.09 Q1438.84 1355.97 1443.43 1349.09 Q1448.04 1342.18 1456.76 1342.18 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1315.75 1114.65 L1360.27 1114.65 L1360.27 1120.56 L1315.75 1120.56 L1315.75 1114.65 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1390.41 1092.67 Q1384.99 1092.67 1382.25 1098.02 Q1379.54 1103.33 1379.54 1114.03 Q1379.54 1124.69 1382.25 1130.03 Q1384.99 1135.35 1390.41 1135.35 Q1395.86 1135.35 1398.57 1130.03 Q1401.31 1124.69 1401.31 1114.03 Q1401.31 1103.33 1398.57 1098.02 Q1395.86 1092.67 1390.41 1092.67 M1390.41 1087.12 Q1399.12 1087.12 1403.7 1094.03 Q1408.32 1100.9 1408.32 1114.03 Q1408.32 1127.12 1403.7 1134.03 Q1399.12 1140.9 1390.41 1140.9 Q1381.69 1140.9 1377.07 1134.03 Q1372.49 1127.12 1372.49 1114.03 Q1372.49 1100.9 1377.07 1094.03 Q1381.69 1087.12 1390.41 1087.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1420.65 1131.08 L1427.97 1131.08 L1427.97 1139.9 L1420.65 1139.9 L1420.65 1131.08 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1443.32 1088.06 L1470.86 1088.06 L1470.86 1093.96 L1449.75 1093.96 L1449.75 1106.67 Q1451.27 1106.15 1452.8 1105.9 Q1454.33 1105.62 1455.86 1105.62 Q1464.54 1105.62 1469.61 1110.38 Q1474.68 1115.14 1474.68 1123.26 Q1474.68 1131.63 1469.47 1136.28 Q1464.26 1140.9 1454.78 1140.9 Q1451.52 1140.9 1448.11 1140.35 Q1444.75 1139.79 1441.13 1138.68 L1441.13 1131.63 Q1444.26 1133.33 1447.59 1134.17 Q1450.93 1135 1454.64 1135 Q1460.65 1135 1464.16 1131.84 Q1467.66 1128.68 1467.66 1123.26 Q1467.66 1117.85 1464.16 1114.69 Q1460.65 1111.53 1454.64 1111.53 Q1451.83 1111.53 1449.02 1112.15 Q1446.24 1112.78 1443.32 1114.1 L1443.32 1088.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1388.91 837.609 Q1383.5 837.609 1380.75 842.956 Q1378.04 848.269 1378.04 858.963 Q1378.04 869.623 1380.75 874.97 Q1383.5 880.282 1388.91 880.282 Q1394.36 880.282 1397.07 874.97 Q1399.82 869.623 1399.82 858.963 Q1399.82 848.269 1397.07 842.956 Q1394.36 837.609 1388.91 837.609 M1388.91 832.053 Q1397.63 832.053 1402.21 838.963 Q1406.83 845.838 1406.83 858.963 Q1406.83 872.053 1402.21 878.963 Q1397.63 885.838 1388.91 885.838 Q1380.2 885.838 1375.58 878.963 Q1371 872.053 1371 858.963 Q1371 845.838 1375.58 838.963 Q1380.2 832.053 1388.91 832.053 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1419.16 876.012 L1426.48 876.012 L1426.48 884.831 L1419.16 884.831 L1419.16 876.012 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1456.76 837.609 Q1451.34 837.609 1448.6 842.956 Q1445.89 848.269 1445.89 858.963 Q1445.89 869.623 1448.6 874.97 Q1451.34 880.282 1456.76 880.282 Q1462.21 880.282 1464.92 874.97 Q1467.66 869.623 1467.66 858.963 Q1467.66 848.269 1464.92 842.956 Q1462.21 837.609 1456.76 837.609 M1456.76 832.053 Q1465.47 832.053 1470.06 838.963 Q1474.68 845.838 1474.68 858.963 Q1474.68 872.053 1470.06 878.963 Q1465.47 885.838 1456.76 885.838 Q1448.04 885.838 1443.43 878.963 Q1438.84 872.053 1438.84 858.963 Q1438.84 845.838 1443.43 838.963 Q1448.04 832.053 1456.76 832.053 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1390.41 582.545 Q1384.99 582.545 1382.25 587.892 Q1379.54 593.204 1379.54 603.899 Q1379.54 614.558 1382.25 619.906 Q1384.99 625.218 1390.41 625.218 Q1395.86 625.218 1398.57 619.906 Q1401.31 614.558 1401.31 603.899 Q1401.31 593.204 1398.57 587.892 Q1395.86 582.545 1390.41 582.545 M1390.41 576.989 Q1399.12 576.989 1403.7 583.899 Q1408.32 590.774 1408.32 603.899 Q1408.32 616.989 1403.7 623.899 Q1399.12 630.774 1390.41 630.774 Q1381.69 630.774 1377.07 623.899 Q1372.49 616.989 1372.49 603.899 Q1372.49 590.774 1377.07 583.899 Q1381.69 576.989 1390.41 576.989 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1420.65 620.947 L1427.97 620.947 L1427.97 629.767 L1420.65 629.767 L1420.65 620.947 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1443.32 577.927 L1470.86 577.927 L1470.86 583.829 L1449.75 583.829 L1449.75 596.538 Q1451.27 596.017 1452.8 595.774 Q1454.33 595.496 1455.86 595.496 Q1464.54 595.496 1469.61 600.253 Q1474.68 605.01 1474.68 613.135 Q1474.68 621.503 1469.47 626.156 Q1464.26 630.774 1454.78 630.774 Q1451.52 630.774 1448.11 630.218 Q1444.75 629.662 1441.13 628.551 L1441.13 621.503 Q1444.26 623.204 1447.59 624.037 Q1450.93 624.871 1454.64 624.871 Q1460.65 624.871 1464.16 621.711 Q1467.66 618.551 1467.66 613.135 Q1467.66 607.718 1464.16 604.558 Q1460.65 601.399 1454.64 601.399 Q1451.83 601.399 1449.02 602.024 Q1446.24 602.649 1443.32 603.968 L1443.32 577.927 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1375.13 368.799 L1386.59 368.799 L1386.59 329.251 L1374.12 331.751 L1374.12 325.362 L1386.52 322.862 L1393.53 322.862 L1393.53 368.799 L1404.99 368.799 L1404.99 374.702 L1375.13 374.702 L1375.13 368.799 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1419.16 365.883 L1426.48 365.883 L1426.48 374.702 L1419.16 374.702 L1419.16 365.883 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1456.76 327.48 Q1451.34 327.48 1448.6 332.827 Q1445.89 338.14 1445.89 348.834 Q1445.89 359.494 1448.6 364.841 Q1451.34 370.154 1456.76 370.154 Q1462.21 370.154 1464.92 364.841 Q1467.66 359.494 1467.66 348.834 Q1467.66 338.14 1464.92 332.827 Q1462.21 327.48 1456.76 327.48 M1456.76 321.925 Q1465.47 321.925 1470.06 328.834 Q1474.68 335.709 1474.68 348.834 Q1474.68 361.925 1470.06 368.834 Q1465.47 375.709 1456.76 375.709 Q1448.04 375.709 1443.43 368.834 Q1438.84 361.925 1438.84 348.834 Q1438.84 335.709 1443.43 328.834 Q1448.04 321.925 1456.76 321.925 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1228.89 804.838 Q1232.5 804.838 1235.81 807.511 Q1239.13 810.152 1241.16 814.467 Q1243.16 818.751 1243.16 823.356 L1243.16 834.564 L1259.64 838.654 Q1259.74 838.686 1260.16 838.783 Q1260.55 838.879 1260.77 838.879 Q1261.58 838.879 1261.77 837.881 Q1261.96 836.85 1261.96 834.564 Q1261.96 833.082 1262.22 832.857 Q1262.38 832.728 1262.67 832.728 Q1263.12 832.728 1263.45 832.857 Q1263.74 832.986 1263.83 833.243 Q1263.93 833.469 1263.96 833.63 Q1263.99 833.791 1263.99 834.048 Q1263.99 834.725 1263.93 836.174 Q1263.86 837.591 1263.86 838.332 L1263.8 842.551 L1263.99 850.924 Q1263.99 851.923 1263.19 851.923 Q1262.58 851.923 1262.32 851.665 Q1262.03 851.407 1262 851.117 Q1261.96 850.828 1261.96 850.087 Q1261.96 848.477 1261.87 847.51 Q1261.77 846.544 1261.64 845.932 Q1261.48 845.288 1261.03 844.966 Q1260.58 844.612 1260.19 844.451 Q1259.77 844.29 1258.84 844.064 L1223.41 835.24 Q1222.35 834.982 1222.19 834.982 Q1221.64 834.982 1221.45 835.304 Q1221.22 835.594 1221.13 836.432 Q1221 838.042 1221 839.266 Q1221 840.071 1220.97 840.393 Q1220.93 840.683 1220.77 840.94 Q1220.58 841.166 1220.19 841.166 Q1219.58 841.166 1219.32 840.908 Q1219.03 840.618 1219 840.296 Q1218.94 839.974 1218.94 839.201 L1218.94 817.817 Q1218.94 811.665 1221.87 808.251 Q1224.8 804.838 1228.89 804.838 M1227.31 810.957 Q1221 810.957 1221 819.942 L1221 826.255 Q1221 828.348 1221.38 828.863 Q1221.74 829.378 1223.51 829.829 L1241.45 834.306 L1241.45 824.998 Q1241.45 818.751 1237.94 814.854 Q1236.33 813.082 1232.98 812.02 Q1229.63 810.957 1227.31 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1218.16 754.469 L1234.98 758.623 Q1236.04 758.913 1236.17 759.106 Q1236.3 759.267 1236.3 759.783 Q1236.3 760.781 1235.62 760.781 Q1235.55 760.781 1234.72 760.684 Q1233.85 760.588 1232.27 760.588 Q1226.44 760.588 1222.99 763.422 Q1219.55 766.224 1219.55 771.216 Q1219.55 775.531 1221.74 779.879 Q1223.93 784.195 1227.5 787.286 Q1230.21 789.605 1233.62 791.312 Q1237.04 792.987 1240.16 793.792 Q1243.28 794.565 1245.64 794.919 Q1247.99 795.273 1249.69 795.273 Q1252.17 795.273 1254.27 794.758 Q1256.36 794.211 1257.84 793.244 Q1259.29 792.278 1260.42 791.055 Q1261.51 789.798 1262.16 788.349 Q1262.8 786.868 1263.12 785.386 Q1263.41 783.905 1263.41 782.359 Q1263.41 776.143 1258.58 770.217 Q1254.62 765.515 1248.15 763.551 Q1247.5 763.39 1247.5 762.713 Q1247.5 761.908 1248.15 761.908 Q1248.28 761.908 1248.92 762.069 Q1249.53 762.23 1250.79 762.713 Q1252.01 763.196 1253.4 763.937 Q1254.78 764.678 1256.52 766.063 Q1258.26 767.448 1259.77 769.155 Q1262.29 772.053 1263.86 775.725 Q1265.44 779.396 1265.44 783.422 Q1265.44 788.446 1263.22 792.504 Q1261 796.562 1256.84 798.945 Q1252.69 801.296 1247.37 801.296 Q1241.77 801.296 1236.26 798.719 Q1230.76 796.143 1226.67 792.053 Q1222.58 787.963 1220.03 782.552 Q1217.49 777.142 1217.49 771.731 Q1217.49 769.67 1218.03 767.834 Q1218.58 765.998 1219.26 764.903 Q1219.94 763.776 1220.93 762.778 Q1221.9 761.779 1222.35 761.457 Q1222.8 761.103 1223.35 760.781 L1218.29 756.176 Q1217.49 755.37 1217.49 755.177 Q1217.49 754.791 1217.71 754.63 Q1217.94 754.469 1218.16 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1262.67 709.347 Q1263.28 709.347 1263.61 709.605 Q1263.9 709.83 1263.96 710.056 Q1263.99 710.249 1263.99 710.539 Q1263.99 711.376 1263.9 714.275 Q1263.8 717.173 1263.8 718.011 Q1263.8 719.363 1263.9 722.133 Q1263.99 724.903 1263.99 726.255 Q1263.99 727.157 1263.25 727.157 Q1262.77 727.157 1262.51 727.061 Q1262.22 726.964 1262.12 726.706 Q1262 726.416 1262 726.255 Q1261.96 726.062 1261.96 725.579 Q1261.96 724.935 1261.9 724.259 Q1261.8 723.582 1261.61 722.745 Q1261.42 721.908 1260.93 721.392 Q1260.45 720.845 1259.77 720.845 Q1259.48 720.845 1257.1 721.07 Q1254.72 721.296 1251.95 721.586 Q1249.15 721.875 1248.76 721.908 L1248.76 738.461 Q1251.37 739.975 1253.17 741.038 Q1254.98 742.101 1255.59 742.487 Q1256.2 742.874 1256.59 743.099 Q1256.97 743.325 1257.2 743.453 Q1258.9 744.387 1259.64 744.387 Q1261.71 744.387 1261.96 741.296 Q1261.96 740.233 1262.74 740.233 Q1263.32 740.233 1263.64 740.49 Q1263.93 740.748 1263.96 740.973 Q1263.99 741.167 1263.99 741.489 Q1263.99 742.552 1263.9 744.774 Q1263.8 746.996 1263.8 748.091 Q1263.8 749.025 1263.9 750.957 Q1263.99 752.89 1263.99 753.759 Q1263.99 754.146 1263.77 754.371 Q1263.54 754.597 1263.25 754.597 Q1262.8 754.597 1262.54 754.532 Q1262.29 754.436 1262.16 754.178 Q1262.03 753.92 1262.03 753.791 Q1262 753.663 1261.96 753.212 Q1261.8 750.764 1260.64 748.864 Q1259.45 746.932 1256.39 745.096 L1217.87 722.165 Q1217.49 721.94 1217.29 721.779 Q1217.1 721.618 1216.94 721.296 Q1216.78 720.941 1216.78 720.426 Q1216.78 719.621 1217.04 719.46 Q1217.26 719.299 1218.36 719.202 L1259.58 715.177 Q1260.45 715.08 1260.8 715.016 Q1261.13 714.919 1261.48 714.5 Q1261.8 714.049 1261.9 713.244 Q1261.96 712.407 1261.96 710.861 Q1261.96 710.281 1262 710.056 Q1262 709.83 1262.16 709.605 Q1262.32 709.347 1262.67 709.347 M1246.7 722.101 L1224.96 724.194 L1246.7 737.205 L1246.7 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1282.27 702.744 Q1281.44 702.744 1281.19 702.676 Q1280.94 702.586 1280.56 702.226 L1270.68 693.366 Q1265.23 688.519 1260.47 688.519 Q1257.38 688.519 1255.17 690.142 Q1252.96 691.743 1252.96 694.696 Q1252.96 696.725 1254.2 698.438 Q1255.44 700.151 1257.65 700.941 Q1257.61 700.805 1257.61 700.332 Q1257.61 699.182 1258.33 698.551 Q1259.05 697.897 1260.02 697.897 Q1261.26 697.897 1261.87 698.709 Q1262.45 699.498 1262.45 700.287 Q1262.45 700.602 1262.39 701.031 Q1262.32 701.437 1261.69 702.09 Q1261.03 702.744 1259.88 702.744 Q1256.66 702.744 1254.09 700.309 Q1251.52 697.852 1251.52 694.11 Q1251.52 689.871 1254.04 687.098 Q1256.55 684.303 1260.47 684.303 Q1261.84 684.303 1263.11 684.731 Q1264.35 685.137 1265.32 685.701 Q1266.29 686.242 1267.84 687.73 Q1269.4 689.218 1270.5 690.412 Q1271.61 691.607 1273.95 694.29 L1278.71 699.182 L1278.71 690.863 Q1278.71 686.805 1278.35 686.49 Q1277.69 686.039 1274.24 685.475 L1274.24 684.303 L1282.27 685.611 L1282.27 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1582.08 3.35044 L1616.83 3.35044 L1616.83 10.237 L1590.26 10.237 L1590.26 28.061 L1614.24 28.061 L1614.24 34.9475 L1590.26 34.9475 L1590.26 63.8304 L1582.08 63.8304 L1582.08 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1624.17 45.9254 L1624.17 18.4603 L1631.62 18.4603 L1631.62 45.6419 Q1631.62 52.0828 1634.13 55.3235 Q1636.64 58.5238 1641.67 58.5238 Q1647.7 58.5238 1651.19 54.6754 Q1654.71 50.827 1654.71 44.1836 L1654.71 18.4603 L1662.16 18.4603 L1662.16 63.8304 L1654.71 63.8304 L1654.71 56.8629 Q1652 60.9948 1648.39 63.0203 Q1644.83 65.0052 1640.09 65.0052 Q1632.27 65.0052 1628.22 60.1441 Q1624.17 55.283 1624.17 45.9254 M1642.92 17.3666 L1642.92 17.3666 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1674.28 18.4603 L1709.68 18.4603 L1709.68 25.2658 L1681.65 57.8756 L1709.68 57.8756 L1709.68 63.8304 L1673.26 63.8304 L1673.26 57.0249 L1701.3 24.4151 L1674.28 24.4151 L1674.28 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1717.82 18.4603 L1753.23 18.4603 L1753.23 25.2658 L1725.2 57.8756 L1753.23 57.8756 L1753.23 63.8304 L1716.81 63.8304 L1716.81 57.0249 L1744.84 24.4151 L1717.82 24.4151 L1717.82 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1783.49 68.0434 Q1780.33 76.1452 1777.33 78.6162 Q1774.33 81.0873 1769.31 81.0873 L1763.35 81.0873 L1763.35 74.8489 L1767.73 74.8489 Q1770.81 74.8489 1772.51 73.3906 Q1774.21 71.9322 1776.28 66.504 L1777.61 63.1013 L1759.26 18.4603 L1767.16 18.4603 L1781.34 53.9462 L1795.52 18.4603 L1803.42 18.4603 L1783.49 68.0434 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1834.25 11.4117 L1823.15 41.51 L1845.39 41.51 L1834.25 11.4117 M1829.63 3.35044 L1838.9 3.35044 L1861.95 63.8304 L1853.45 63.8304 L1847.94 48.3155 L1820.68 48.3155 L1815.17 63.8304 L1806.54 63.8304 L1829.63 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1899.47 35.4741 Q1902.1 36.3653 1904.57 39.282 Q1907.08 42.1986 1909.59 47.3027 L1917.9 63.8304 L1909.11 63.8304 L1901.37 48.3155 Q1898.37 42.2391 1895.54 40.2542 Q1892.74 38.2692 1887.88 38.2692 L1878.97 38.2692 L1878.97 63.8304 L1870.78 63.8304 L1870.78 3.35044 L1889.26 3.35044 Q1899.63 3.35044 1904.73 7.68491 Q1909.84 12.0194 1909.84 20.7693 Q1909.84 26.4811 1907.16 30.2484 Q1904.53 34.0158 1899.47 35.4741 M1878.97 10.0749 L1878.97 31.5447 L1889.26 31.5447 Q1895.17 31.5447 1898.17 28.8306 Q1901.21 26.076 1901.21 20.7693 Q1901.21 15.4626 1898.17 12.789 Q1895.17 10.0749 1889.26 10.0749 L1878.97 10.0749 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M1914.01 3.35044 L1965.17 3.35044 L1965.17 10.237 L1943.7 10.237 L1943.7 63.8304 L1935.48 63.8304 L1935.48 10.237 L1914.01 10.237 L1914.01 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2030.94 40.4256 Q2030.94 46.492 2027.82 52.1895 Q2024.75 57.887 2019.91 61.3301 Q2015.11 64.7732 2010.28 64.7732 Q2004.83 64.7732 2002 59.1167 Q1996.87 79.6523 1996.59 80.1852 Q1995.4 81.9477 1993.68 81.9477 Q1992.61 81.9477 1991.96 81.2919 Q1991.3 80.677 1991.3 79.6933 Q1991.34 79.3654 1991.59 78.3406 L1999.78 45.3443 Q2001.67 37.6793 2007.37 32.2277 Q2013.11 26.7351 2019.25 26.7351 Q2024.13 26.7351 2027.53 30.3832 Q2030.94 34.0312 2030.94 40.4256 M2024.91 36.8185 Q2024.91 32.7196 2023.27 30.6701 Q2021.63 28.5797 2019.09 28.5797 Q2016.75 28.5797 2013.93 30.4652 Q2011.14 32.3507 2008.68 36.5316 Q2007.37 38.9499 2006.42 41.9422 Q2005.48 44.9344 2003.64 52.3125 Q2002.98 55.2637 2002.98 55.4276 Q2002.98 55.7555 2003.15 56.4934 Q2003.35 57.2312 2003.84 58.3789 Q2004.37 59.4856 2005.11 60.4693 Q2005.85 61.4531 2007.2 62.1909 Q2008.56 62.8877 2010.2 62.8877 Q2012.74 62.8877 2015.44 60.8382 Q2018.19 58.7478 2020.2 54.9358 Q2021.88 51.8616 2023.39 46.0821 Q2024.91 40.2616 2024.91 36.8185 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2069.41 26.157 L2121.34 26.157 L2121.34 32.9625 L2069.41 32.9625 L2069.41 26.157 M2069.41 42.6847 L2121.34 42.6847 L2121.34 49.5713 L2069.41 49.5713 L2069.41 42.6847 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2182.88 8.73814 Q2176.56 8.73814 2173.36 14.9765 Q2170.2 21.1744 2170.2 33.6512 Q2170.2 46.0875 2173.36 52.3259 Q2176.56 58.5238 2182.88 58.5238 Q2189.24 58.5238 2192.4 52.3259 Q2195.6 46.0875 2195.6 33.6512 Q2195.6 21.1744 2192.4 14.9765 Q2189.24 8.73814 2182.88 8.73814 M2182.88 2.25669 Q2193.05 2.25669 2198.39 10.318 Q2203.78 18.3388 2203.78 33.6512 Q2203.78 48.9231 2198.39 56.9844 Q2193.05 65.0052 2182.88 65.0052 Q2172.71 65.0052 2167.32 56.9844 Q2161.97 48.9231 2161.97 33.6512 Q2161.97 18.3388 2167.32 10.318 Q2172.71 2.25669 2182.88 2.25669 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2218.16 53.5411 L2226.71 53.5411 L2226.71 63.8304 L2218.16 63.8304 L2218.16 53.5411 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip060)\" d=\"M2242.47 3.35044 L2281.35 3.35044 L2281.35 6.83422 L2259.4 63.8304 L2250.85 63.8304 L2271.51 10.237 L2242.47 10.237 L2242.47 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip063)\" cx=\"2204.18\" cy=\"959.607\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2184.92\" cy=\"758.968\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2204.06\" cy=\"593.402\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2171.7\" cy=\"477.446\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2205.09\" cy=\"297.758\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2209.98\" cy=\"253.799\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2208.05\" cy=\"549.365\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2217.57\" cy=\"982.71\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2174.92\" cy=\"655.947\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2230.69\" cy=\"971.433\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2195.55\" cy=\"526.34\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2208.85\" cy=\"955.874\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2233.5\" cy=\"819.533\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2208.18\" cy=\"771.982\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2217.54\" cy=\"945.407\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1939.12\" cy=\"1217.3\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1846.75\" cy=\"759.408\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1932.79\" cy=\"1226.5\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1834.82\" cy=\"951.954\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1856.56\" cy=\"782.198\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1896.86\" cy=\"966.64\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1834.08\" cy=\"620.05\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1907.03\" cy=\"1028.23\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"2010.82\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1892.22\" cy=\"1007.68\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1894.29\" cy=\"1115.62\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1862.29\" cy=\"1038.46\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1833.57\" cy=\"696.079\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1951.91\" cy=\"1204.52\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1821.9\" cy=\"742.113\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1782.87\" cy=\"1152.2\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1703.79\" cy=\"749.09\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1665.23\" cy=\"864.952\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1688.11\" cy=\"765.757\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1623.09\" cy=\"679.153\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1687.55\" cy=\"984.172\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1709.86\" cy=\"669.407\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1731.22\" cy=\"798.298\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1591.48\" cy=\"159.767\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1790.18\" cy=\"1254.98\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1744.39\" cy=\"1114.72\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1661.9\" cy=\"718.128\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1746.03\" cy=\"818.856\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1785.44\" cy=\"1003.22\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip063)\" cx=\"1742\" cy=\"969.178\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n</svg>\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We can see that the two different vigilance values result in similar resutls on the whole, though they differ in how they classify certain samples that straddle the border between","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"\"assets/options-cover.png\"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/data_config.jl\"","category":"page"},{"location":"examples/adaptive_resonance/data_config/#data_config","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Overview","page":"ART DataConfig Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"In their derivations, ART modules have some special requirements when it comes to their input features. FuzzyART in particular, and subsequently its derivatives, has a requirement that the inputs be bounded and complement coded. This is due to some consequences such as weight decay that occur when using real-valued patterns rather than binary ones (and hence operations like fuzzy membership).","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Preprocessing of the features occurs as follows:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"The features are linearly normalized from 0 to 1 with respect to each feature with linear_normalization. This is done according to some known bounds that each feature has.\nThe features are then complement coded, meaning that the feature vector is appended to its 1-complement (i.e., x rightarrow leftx 1-xright) with complement_code.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"This preprocessing has the ultimate consequence that the input features must be bounded. This many not be a problem in some offline applications with a fixed dataset, but in others where the bounds are not known, techniques such as sigmoidal limiting are often used to place an artificial limit.","category":"page"},{"location":"examples/adaptive_resonance/data_config/#DataConfig","page":"ART DataConfig Example","title":"DataConfig","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Regardless, this process requires some a-priori knowledge about the minimums and maximums that each feature can have, which is stored as a preprocessing configuration. This preprocessing configuration is saved in every ART module as a DataConfig object called config, which we can see is uninitialized at first:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Load the library\nusing AdaptiveResonance\n\n# Create a new ART module and inspect its uninitialized data config `config`\nart = FuzzyART()\nart.config","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(false, Float64[], Float64[], 0, 0)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We see that the type of art.config is DataConfig. We can see what the internal elements of this struct are with fieldnames:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"fieldnames(AdaptiveResonance.DataConfig)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"(:setup, :mins, :maxs, :dim, :dim_comp)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We see that the dataconfig has a boolean setup flag, minimum and maximum feature vectors, dimensionality of the data, and the complement coded dimensionality (twice the size of the original dimension).","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Automatic-Configuration","page":"ART DataConfig Example","title":"Automatic Configuration","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"In batch training mode, the minimums and maximums are detected automatically; the minimum and maximum values for every feature are saved and used for the preprocessing step at every subsequent iteration.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Load data\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"note: Note\nThis automatic detection of feature characteristics only occurs if the config is not already setup. If it is setup beforehand, then that config is used instead.","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Manual-Configuration","page":"ART DataConfig Example","title":"Manual Configuration","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"As mentioned before, we may not always have the luxury of having a representative dataset in advance. Alternatively, we may know the bounds of the features but wish to run incrementally rather than in batch. In these cases, we can setup the config the various DataConfig constructors.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"For example, if the features are all bounded from -1 to 1, we have to also specify the original dimension of the data in DataConfig(min, max, dim):","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Reinitialize the FuzzyART module\nart = FuzzyART()\n# Tell the module that we have 20 features all ranging from -1 to 1\nart.config = DataConfig(-1, 1, 20)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(true, [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 20, 40)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"If the features differ in their ranges, we can specify with DataConfig(mins, maxs):","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Assume some minimum and maximum values for each feature\nmins = [-1,-2,-1.5]\nmaxs = [3, 2, 1]\nart.config = DataConfig(mins, maxs)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(true, [-1.0, -2.0, -1.5], [3.0, 2.0, 1.0], 3, 6)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Here, we don't need to specify the feature dimensionality because it is inferred from the length of the range values.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"note: Note\nAfter the first training run, the weights of the network are set to the size of the complement coded dimension. If you wish to change the dimension of the features, you will need to create a new network.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/artmap/sfam_iris.jl\"","category":"page"},{"location":"examples/artmap/sfam_iris/#sfam_iris","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"","category":"section"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"SFAM is a supervised algorithm by definition, so we use it to map a set of features to a set of supervisory labels. We will do so by training and testing on the ubiquitous Iris dataset and seeing how well the SFAM module generalizes the data.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Get the iris dataset as a DataFrame\niris = Iris()\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = Matrix(iris.features)', vec(Matrix{String}(iris.targets))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], [\"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\"])","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, labels)\nunique(labels)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(([6.2 5.7 6.9 4.9 5.7 6.8 4.8 6.5 5.7 6.9 6.5 6.7 6.0 7.2 4.5 5.7 4.8 6.9 6.3 4.9 7.7 6.4 6.4 4.9 5.3 6.0 6.8 6.3 5.2 5.0 5.0 5.6 5.6 5.1 6.3 5.4 5.9 5.5 6.2 6.5 5.8 5.7 5.1 6.3 4.6 5.1 6.7 5.8 6.4 5.4 6.4 4.9 6.3 5.8 5.1 4.7 5.2 5.7 5.0 5.0 4.4 6.1 6.7 7.0 6.5 6.7 6.3 5.4 6.0 4.8 7.4 6.5 5.4 5.5 5.5 6.4 6.6 6.1 5.5 7.3 6.1 7.2 5.6 5.1 5.8 6.7 6.4 5.0 4.6 6.2 4.6 7.7 5.7 6.4 5.8 6.3 5.9 5.0 5.2 5.1 4.9 4.9 5.5 5.0 5.6; 3.4 2.8 3.1 2.4 2.6 3.2 3.4 3.0 2.8 3.1 3.2 3.0 2.2 3.2 2.3 4.4 3.0 3.2 3.4 3.1 2.8 2.8 3.1 3.0 3.7 2.9 3.0 2.7 4.1 3.0 3.4 2.9 2.5 3.8 2.3 3.4 3.0 4.2 2.9 3.0 2.7 3.0 3.3 3.3 3.6 3.5 3.1 2.8 2.9 3.9 3.2 2.5 2.5 4.0 3.5 3.2 3.4 2.5 2.3 3.4 3.2 3.0 2.5 3.2 3.0 3.0 2.5 3.4 2.2 3.4 2.8 2.8 3.0 2.3 3.5 3.2 3.0 2.8 2.5 2.9 2.6 3.6 2.7 3.8 2.6 3.1 2.8 3.5 3.4 2.2 3.1 2.6 3.8 2.7 2.7 2.8 3.2 3.5 2.7 2.5 3.1 3.1 2.4 3.3 2.8; 5.4 4.5 5.4 3.3 3.5 5.9 1.6 5.8 4.1 5.1 5.1 5.0 4.0 6.0 1.3 1.5 1.4 5.7 5.6 1.5 6.7 5.6 5.5 1.4 1.5 4.5 5.5 4.9 1.5 1.6 1.5 3.6 3.9 1.9 4.4 1.5 5.1 1.4 4.3 5.2 5.1 4.2 1.7 4.7 1.0 1.4 4.4 5.1 4.3 1.7 4.5 4.5 5.0 1.2 1.4 1.6 1.4 5.0 3.3 1.6 1.3 4.6 5.8 4.7 5.5 5.2 4.9 1.7 5.0 1.9 6.1 4.6 4.5 4.0 1.3 5.3 4.4 4.0 4.0 6.3 5.6 6.1 4.2 1.5 4.0 4.7 5.6 1.3 1.4 4.5 1.5 6.9 1.7 5.3 4.1 5.1 4.8 1.6 3.9 3.0 1.5 1.5 3.7 1.4 4.9; 2.3 1.3 2.1 1.0 1.0 2.3 0.2 2.2 1.3 2.3 2.0 1.7 1.0 1.8 0.3 0.4 0.1 2.3 2.4 0.1 2.0 2.2 1.8 0.2 0.2 1.5 2.1 1.8 0.1 0.2 0.2 1.3 1.1 0.4 1.3 0.4 1.8 0.2 1.3 2.0 1.9 1.2 0.5 1.6 0.2 0.2 1.4 2.4 1.3 0.4 1.5 1.7 1.9 0.2 0.3 0.2 0.2 2.0 1.0 0.4 0.2 1.4 1.8 1.4 1.8 2.3 1.5 0.2 1.5 0.2 1.9 1.5 1.5 1.3 0.2 2.3 1.4 1.3 1.3 1.8 1.4 2.5 1.3 0.3 1.2 1.5 2.1 0.3 0.3 1.5 0.2 2.3 0.3 1.9 1.0 1.5 1.8 0.6 1.4 1.1 0.1 0.1 1.0 0.2 2.0], [3, 2, 3, 2, 2, 3, 1, 3, 2, 3, 3, 2, 2, 3, 1, 1, 1, 3, 3, 1, 3, 3, 3, 1, 1, 2, 3, 3, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 2, 3, 3, 2, 1, 2, 1, 1, 2, 3, 2, 1, 2, 3, 3, 1, 1, 1, 1, 3, 2, 1, 1, 2, 3, 2, 3, 3, 2, 1, 3, 1, 3, 2, 2, 2, 1, 3, 2, 2, 2, 3, 3, 3, 2, 1, 2, 2, 3, 1, 1, 2, 1, 3, 1, 3, 2, 3, 2, 1, 2, 2, 1, 1, 2, 1, 3]), ([4.6 5.0 5.8 6.0 5.0 4.8 6.1 6.3 5.5 6.2 4.7 5.5 6.7 5.9 6.9 4.4 6.0 5.6 5.8 7.7 7.9 7.6 5.4 5.1 6.7 5.1 7.2 5.4 6.8 6.6 6.1 7.1 5.7 6.1 5.0 6.7 5.2 6.0 4.4 4.3 7.7 4.8 6.3 5.1 5.6; 3.2 3.2 2.7 3.4 3.6 3.0 2.9 3.3 2.6 2.8 3.2 2.4 3.3 3.0 3.1 3.0 3.0 3.0 2.7 3.0 3.8 3.0 3.7 3.7 3.3 3.8 3.0 3.9 2.8 2.9 3.0 3.0 2.9 2.8 2.0 3.1 3.5 2.7 2.9 3.0 3.8 3.1 2.9 3.4 3.0; 1.4 1.2 3.9 4.5 1.4 1.4 4.7 6.0 4.4 4.8 1.3 3.8 5.7 4.2 4.9 1.3 4.8 4.1 5.1 6.1 6.4 6.6 1.5 1.5 5.7 1.6 5.8 1.3 4.8 4.6 4.9 5.9 4.2 4.7 3.5 5.6 1.5 5.1 1.4 1.1 6.7 1.6 5.6 1.5 4.5; 0.2 0.2 1.2 1.6 0.2 0.3 1.4 2.5 1.2 1.8 0.2 1.1 2.5 1.5 1.5 0.2 1.8 1.3 1.9 2.3 2.0 2.1 0.2 0.4 2.1 0.2 1.6 0.4 1.4 1.3 1.8 2.1 1.3 1.2 1.0 2.4 0.2 1.6 0.2 0.1 2.2 0.2 1.8 0.2 1.5], [1, 1, 2, 2, 1, 1, 2, 3, 2, 3, 1, 2, 3, 2, 2, 1, 3, 2, 3, 3, 3, 3, 1, 1, 3, 1, 3, 1, 2, 2, 3, 3, 2, 2, 2, 3, 1, 2, 1, 1, 3, 1, 3, 1, 2]))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Now, we can create our SFAM module. We'll do so with the default contstructor, though the module itself has many options that can be altered during instantiation.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Create the SFAM module\nart = SFAM()\n\n# Change the match tracking parameter after instantiation\nart.opts.epsilon = 1e-2","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"0.01","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We can train the model in batch mode upon the data and supervisory labels. We do so by directly passing the integer vector of labels to the training method. Just as in other modules, we can extract the SFAM's prescribed labels from the training method, which should match up to the training labels as we will see later.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Train in supervised mode by directly passing the labels.\ny_hat_train = train!(art, X_train, y_train)\nprintln(\"Training labels: \",  size(y_hat_train), \" \", typeof(y_hat_train))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We can classify the testing data to see how we generalize. At the same time, we can see the effect of getting the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Classify both ways\ny_hat = AdaptiveResonance.classify(art, X_test)\ny_hat_bmu = AdaptiveResonance.classify(art, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"Testing labels: \",  size(y_hat), \" \", typeof(y_hat))\nprintln(\"Testing labels with bmu: \",  size(y_hat_bmu), \" \", typeof(y_hat_bmu))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Testing labels: (45,) Vector{Int64}\nTesting labels with bmu: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Finally, we can calculate the performances (number correct over total) of the model upon all three regimes:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training data\nTesting data\nTesting data with get_bmu=true","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train = performance(y_hat_train, y_train)\nperf_test = performance(y_hat, y_test)\nperf_test_bmu = performance(y_hat_bmu, y_test)\n\n# Format each performance number for comparison\n@printf \"Training performance: %.4f\\n\" perf_train\n@printf \"Testing performance: %.4f\\n\" perf_test\n@printf \"Best-matching unit testing performance: %.4f\\n\" perf_test_bmu","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training performance: 1.0000\nTesting performance: 0.9556\nBest-matching unit testing performance: 0.9556\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"getting-started/whatisart/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"This page provides a theoretical overview of Adaptive Resonance Theory and what this project aims to accomplish.","category":"page"},{"location":"getting-started/whatisart/#What-is-Adaptive-Resonance-Theory?","page":"Background","title":"What is Adaptive Resonance Theory?","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Adaptive Resonance Theory (commonly abbreviated to ART) is both a neurological theory and a family of neurogenitive neural network models for machine learning.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART began as a neurocognitive theory of how fields of cells can continuously learn stable representations, and it evolved into the basis for a myriad of practical machine learning algorithms. Pioneered by Stephen Grossberg and Gail Carpenter, the field has had contributions across many years and from many disciplines, resulting in a plethora of engineering applications and theoretical advancements that have enabled ART-based algorithms to compete with many other modern learning and clustering algorithms.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Because of the high degree of interplay between the neurocognitive theory and the engineering models born of it, the term ART is frequently used to refer to both in the modern day (for better or for worse).","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Stephen Grossberg's has recently released a book summarizing the work of him, his wife and colleague Gail Carpenter, and his other colleagues on Adaptive Resonance Theory in his book Conscious Brain, Resonant Mind.","category":"page"},{"location":"getting-started/whatisart/#ART-Basics","page":"Background","title":"ART Basics","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"(Image: art)","category":"page"},{"location":"getting-started/whatisart/#ART-Dynamics","page":"Background","title":"ART Dynamics","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Nearly every ART model shares a basic set of dynamics:","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART models typically have two layers/fields denoted F1 and F2.\nThe F1 field is the feature representation field.  Most often, it is simply the input feature sample itself (after some necessary preprocessing).\nThe F2 field is the category representation field.  With some exceptions, each node in the F2 field generally represents its own category.  This is most easily understood as a weight vector representing a prototype for a class or centroid of a cluster.\nAn activation function is used to find the order of categories \"most activated\" for a given sample in F1.\nIn order of highest activation, a match function is used to compute the agreement between the sample and the categories.\nIf the match function for a category evaluates to a value above a threshold known as the vigilance parameter (rho), the weights of that category may be updated according to a learning rule.\nIf there is complete mismatch across all categories, then a new categories is created according to some instantiation rule.","category":"page"},{"location":"getting-started/whatisart/#ART-Considerations","page":"Background","title":"ART Considerations","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"In addition to the dynamics typical of an ART model, you must know:","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART models are inherently designed for unsupervised learning (i.e., learning in the absense of supervisory labels for samples).  This is also known as clustering.\nART models are capable of supervised learning and reinforcement learning through some redesign and/or combination of ART models.  For example, ARTMAP models are combinations of two ART models in a special way, one learning feature-to-category mappings and another learning category-to-label mappingss.  ART modules are used for reinforcement learning by representing the mappings between state, value, and action spaces with ART dynamics.\nAlmost all ART models face the problem of the appropriate selection of the vigilance parameter, which may depend in its optimality according to the problem.\nBeing a class of neurogenitive neural network models, ART models gain the ability for theoretically infinite capacity along with the problem of \"category proliferation,\" which is the undesirable increase in the number of categories as the model continues to learn, leading to increasing computational time.  In contrast, while the evaluation time of a fixed architecture deep neural network is always exactly the same, there exist upper bounds in their representational capacity.\nNearly every ART model requires feature normalization (i.e., feature elements lying within 01) and a process known as complement coding where the feature vector is appended to its vector complement 1-barx. This is because real-numbered vectors can be arbitrarily close to one another, hindering learning performance, which requires a degree of contrast enhancement between samples to ensure their separation.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"To learn about their implementations, nearly every practical ART model is listed in a recent ART survey paper by Leonardo Enzo Brito da Silva.","category":"page"},{"location":"getting-started/whatisart/#History-and-Development","page":"Background","title":"History and Development","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"At a high level, ART began with a neural network model known as the Grossberg Network named after Stephen Grossberg. This network treats the firing of neurons in frequency domain as basic shunting models, which are recurrently connected to increase their own activity while suppressing the activities of others nearby (i.e., on-center, off-surround). Using this shunting model, Grossberg shows that autonomous, associative learning can occur with what are known as instar networks.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"By representing categories as a field of instar networks, new categories could be optimally learned by the instantiation of new neurons. However, it was shown that the learning stability of Grossberg Networks degrades as the number of represented categories increases. Discoveries in the neurocognitive theory and breakthroughs in their implementation led to the introduction of a recurrent connections between the two fields of the network to stabilize the learning. These breakthroughs were based upon the discovery that autonomous learning depends on the interplay and agreement between perception and expectation, frequently referred to as bottom-up and top-down processes. Furthermore, it is resonance between these states in the frequency domain that gives rise to conscious experiences and that permit adaptive weights to change, leading to the phenomea of attention and learning. The theory has many explanatory consequences in psychology, such as why attention is required for learning, but its consequences in the engineering models are that it stabilizes learning in cooperative-competitive dynamics, such as interconnected fields of neurons, which are most often chaotic.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Chapters 18 and 19 of the book by Neural Network Design by Hagan, Demuth, Beale, and De Jesus provide a good theoretical basis for learning how these network models were eventually implemented into the first binary-vector implementation of ART1.","category":"page"},{"location":"man/dev-index/#dev-main-index","page":"Internals","title":"Developer Index","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"This page lists the types and functions that are internal to the AdaptiveResonance.jl package. Because they are not part of the public API, these names might change relatively frequently between versions and so should not be relied upon.","category":"page"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"All internal names are listed in the Index, and each of these entries link to the docstrings in the Docs section.","category":"page"},{"location":"man/dev-index/#Index","page":"Internals","title":"Index","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"This section contains a list of internal names that link to their corresponding Documentation.","category":"page"},{"location":"man/dev-index/#dev-index-methods","page":"Internals","title":"Methods","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:function]","category":"page"},{"location":"man/dev-index/#dev-index-types","page":"Internals","title":"Types","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:type]","category":"page"},{"location":"man/dev-index/#dev-index-types-2","page":"Internals","title":"Constants","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:constant]","category":"page"},{"location":"man/dev-index/#dev-index-docs","page":"Internals","title":"Docs","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Documentation for all internal names are listed below.","category":"page"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Modules = [AdaptiveResonance]\nPublic = false","category":"page"},{"location":"man/dev-index/#AdaptiveResonance.ACTIVATION_FUNCTIONS_DOCS","page":"Internals","title":"AdaptiveResonance.ACTIVATION_FUNCTIONS_DOCS","text":"ACTIVATIONFUNCTIONSDOCS\n\nDescription\n\nCommon docstring for listing available activation functions.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ARTIterator","page":"Internals","title":"AdaptiveResonance.ARTIterator","text":"ARTIterator\n\nDescription\n\nAcceptable iterators for ART module training and inference\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ART_DIM","page":"Internals","title":"AdaptiveResonance.ART_DIM","text":"ART_DIM\n\nDescription\n\nAdaptiveResonance.jl convention for which 2-D dimension contains the feature dimension.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ART_SAMPLES","page":"Internals","title":"AdaptiveResonance.ART_SAMPLES","text":"ART_SAMPLES\n\nDescription\n\nAdaptiveResonance.jl convention for which 2-D dimension contains the number of samples.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.MATCH_FUNCTIONS_DOCS","page":"Internals","title":"AdaptiveResonance.MATCH_FUNCTIONS_DOCS","text":"MATCHFUNCTIONSDOCS\n\nDescription\n\nCommon docstring for listing available match functions.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARGS_MATRIX_REPLACE","page":"Internals","title":"AdaptiveResonance._ARGS_MATRIX_REPLACE","text":"ARGSMATRIX_REPLACE\n\nDescription\n\nCommon docstring: shared arguments string for functions updating a column in a matrix.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_ART","page":"Internals","title":"AdaptiveResonance._ARG_ART","text":"ARGART\n\nDescription\n\nCommon docstring: shared argument docstring for ART module arguments.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_ART_X_W","page":"Internals","title":"AdaptiveResonance._ARG_ART_X_W","text":"ARGARTXW\n\nDescription\n\nCommon docstring: shared arguments string for methods using an ART module, sample 'x', and weight vector 'W'.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_INDEX","page":"Internals","title":"AdaptiveResonance._ARG_INDEX","text":"ARGINDEX\n\nDescription\n\nCommon docstring: shared argument docstring for the index of the weight column.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_W","page":"Internals","title":"AdaptiveResonance._ARG_W","text":"ARGW\n\nDescription\n\nCommon docstring: shared argument docstring for the weight vector.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_X","page":"Internals","title":"AdaptiveResonance._ARG_X","text":"ARGX\n\nDescription\n\nCommon docstring: shared argument docstring for the input sample of features.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._COMMON_DOC","page":"Internals","title":"AdaptiveResonance._COMMON_DOC","text":"COMMONDOC\n\nDescription\n\nDocstring prefix denoting that the constant is used as a common docstring element for other docstrings.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._OPTS_DOCSTRING","page":"Internals","title":"AdaptiveResonance._OPTS_DOCSTRING","text":"OPTSDOCSTRING\n\nDescription\n\nCommon docstring: shared options docstring, inserted at the end of opts_<...> structs.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ARTMatrix","page":"Internals","title":"AdaptiveResonance.ARTMatrix","text":"ARTMatrix\n\nDescription\n\nThe type of matrix used by the AdaptiveResonance.jl package, used to configure matrix growth behavior.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ARTStats","page":"Internals","title":"AdaptiveResonance.ARTStats","text":"ARTStats\n\nDescription\n\nDefinition of the ART module statistics dictionary, used to generate and store various logs during training and testing.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ARTVector","page":"Internals","title":"AdaptiveResonance.ARTVector","text":"ARTVector\n\nDescription\n\nThe type of vector used by the AdaptiveResonance.jl package, used to configure vector growth behvior.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.AbstractFuzzyART","page":"Internals","title":"AdaptiveResonance.AbstractFuzzyART","text":"abstract type AbstractFuzzyART <: ART\n\nSummary\n\nAbstract supertype of FuzzyART modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.MergeART","page":"Internals","title":"AdaptiveResonance.MergeART","text":"mutable struct MergeART <: ART\n\nSummary\n\nMergeART module struct.\n\nFor module options, see AdaptiveResonance.opts_MergeART.\n\nReferences\n\nL. E. Brito da Silva, I. Elnabarawy, and D. C. Wunsch, 'Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence,' Neural Networks, vol. 121, pp. 208-228, 2020, doi: 10.1016/j.neunet.2019.08.033.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DDVFA: DDVFA options struct.\n\nsubopts::opts_FuzzyART: FuzzyART options struct used for all F2 nodes.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nF2::Vector{FuzzyART}: List of F2 nodes (themselves FuzzyART modules).\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of total categories.\n\nepoch::Int64: Current training epoch.\n\nT::Vector: DDVFA activation values.\n\nM::Vector: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.opts_MergeART","page":"Internals","title":"AdaptiveResonance.opts_MergeART","text":"mutable struct opts_MergeART <: ARTOpts\n\nSummary\n\nMergeART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.7\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.85\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nsimilarity::Symbol: Similarity method (activation and match): similarity ∈ [:single, :average, :complete, :median, :weighted, :centroid].  Default: :single\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.  Default: true\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :gamma_activation\nmatch::Symbol: Selected match function.  Default: :gamma_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.W_norm-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.W_norm","text":"W_norm(W::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nLow-level common function for computing the 1-norm of just the weight vector.\n\nArguments\n\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nW_norm(W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:30.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.accommodate_vector!-Union{Tuple{T}, Tuple{Vector{T}, Integer}} where T","page":"Internals","title":"AdaptiveResonance.accommodate_vector!","text":"accommodate_vector!(vec::Array{T, 1}, goal_len::Integer)\n\n\nSummary\n\nExtends a vector to a goal length with zeros of its element type to accommodate in-place updates.\n\nArguments\n\nvec::Vector{T}: a vector of arbitrary element type.\ngoal_len::Integer: the length that the vector should be.\n\nMethod List / Definition Locations\n\naccommodate_vector!(vec, goal_len)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.activation_match!-Tuple{AdaptiveResonance.AbstractFuzzyART, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.activation_match!","text":"activation_match!(\n    art::AdaptiveResonance.AbstractFuzzyART,\n    x::AbstractVector{T} where T<:Real\n)\n\n\nSummary\n\nComputes the activation and match functions of the ART module against sample x.\n\nArguments\n\nart::AbstractFuzzyART: the single FuzzyART module to compute the activation and match values for all weights.\nx::RealVector: the sample to compute the activation and match functions against.\n\nExamples\n\njulia> my_FuzzyART = FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\njulia> x = rand(3, 10)\njulia> train!(my_FuzzyART, x)\njulia> activation_match!(my_FuzzyART, x[:, 1])\n\nMethod List / Definition Locations\n\nactivation_match!(art, x)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:51.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer, Vararg{Any}}","page":"Internals","title":"AdaptiveResonance.art_activation","text":"art_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer,\n    args...\n) -> Any\n\n\nSummary\n\nEvaluates the activation function of the ART/ARTMAP module on the sample 'x' with weight 'W'.\n\nPasses additional arguments for low-level optimizations using function dispatch.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_activation(art, x, index, args)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:140.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_learn-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.art_learn","text":"art_learn(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> Any\n\n\nSummary\n\nEvaluates the ART module's learning/update method.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_learn(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:161.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer, Vararg{Any}}","page":"Internals","title":"AdaptiveResonance.art_match","text":"art_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer,\n    args...\n) -> Any\n\n\nSummary\n\nEvaluates the match function of the ART/ARTMAP module on sample 'x' with weight 'W'.\n\nPasses additional arguments for low-level optimizations using function dispatch.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_match(art, x, index, args)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:126.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.average-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.average","text":"average(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nAverage linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\naverage(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:479.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_activation","text":"basic_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nSimplified FuzzyARTMAP activation function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_activation(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:59.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_match","text":"basic_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nBasic match function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_match(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_update-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_update","text":"basic_update(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nBasic weight update function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_update(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:149.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.build_art_stats-Tuple{}","page":"Internals","title":"AdaptiveResonance.build_art_stats","text":"build_art_stats() -> Dict{String, Any}\n\n\nSummary\n\nInitializes an ARTStats dictionary with zero entries.\n\nMethod List / Definition Locations\n\nbuild_art_stats()\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:138.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.centroid-Tuple{FuzzyART, AbstractVector{T} where T<:Real, Bool}","page":"Internals","title":"AdaptiveResonance.centroid","text":"centroid(\n    F2::FuzzyART,\n    sample::AbstractVector{T} where T<:Real,\n    activation::Bool\n) -> Any\n\n\nSummary\n\nCentroid linkage DDVFA similarity function.\n\nArguments:\n\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nsample::RealVector: the sample to use for computing the linkage to the F2 module.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\ncentroid(F2, sample, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:526.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.choice_by_difference-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.choice_by_difference","text":"choice_by_difference(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nDefault ARTMAP's choice-by-difference activation function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nchoice_by_difference(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:109.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.color_to_gray-Union{Tuple{Array{T, 3}}, Tuple{T}} where T<:AbstractFloat","page":"Internals","title":"AdaptiveResonance.color_to_gray","text":"color_to_gray(image::Array{T<:AbstractFloat, 3}) -> Matrix\n\n\nSummary\n\nARTSCENE Stage 1: Color-to-gray image transformation.\n\nMethod List / Definition Locations\n\ncolor_to_gray(image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:23.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.competition_kernel-Tuple{Integer, Integer}","page":"Internals","title":"AdaptiveResonance.competition_kernel","text":"competition_kernel(l::Integer, k::Integer; sign) -> Any\n\n\nSummary\n\nCompetition kernel for ARTSCENE: Stage 5.\n\nMethod List / Definition Locations\n\ncompetition_kernel(l, k; sign)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:195.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.complete-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.complete","text":"complete(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nComplete linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\ncomplete(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:488.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_insensitive_oriented_filtering-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_insensitive_oriented_filtering","text":"contrast_insensitive_oriented_filtering(\n    y::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 4: Contrast-insensitive oriented filtering.\n\nMethod List / Definition Locations\n\ncontrast_insensitive_oriented_filtering(y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:182.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_normalization-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_normalization","text":"contrast_normalization(\n    image::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 2: Constrast normalization.\n\nMethod List / Definition Locations\n\ncontrast_normalization(image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:65.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_sensitive_oriented_filtering-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_sensitive_oriented_filtering","text":"contrast_sensitive_oriented_filtering(\n    image::AbstractArray{T} where T<:Real,\n    x::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 3: Contrast-sensitive oriented filtering.\n\nMethod List / Definition Locations\n\ncontrast_sensitive_oriented_filtering(image, x)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:151.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"Summary\n\nCreates a category for the ARTModule module, expanding the weights and incrementing the category labels.\n\nArguments\n\nart::ARTModule: the ARTModule module to add a category to.\nx::RealVector: the sample to use for adding a category.\ny::Integer: the new label for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, sample, label)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:396.\n\ncreate_category!(art, x, y; new_cluster)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:237.\n\ncreate_category!(art, x, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:269.\n\ncreate_category!(art, x, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:205.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{DDVFA, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"create_category!(\n    art::DDVFA,\n    sample::AbstractVector{T} where T<:Real,\n    label::Integer\n) -> Vector{FuzzyART}\n\n\nSummary\n\nCreate a new category by appending and initializing a new FuzzyART node to F2.\n\nArguments\n\nart::DDVFA: the DDVFA module to create a new FuzzyART category in.\nsample::RealVector: the sample to use for instantiating the new category.\nlabel::Integer: the new label to use for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, sample, label)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:396.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{DVFA, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"create_category!(\n    art::DVFA,\n    x::AbstractVector{T} where T<:Real,\n    y::Integer;\n    new_cluster\n) -> Vector{Int64}\n\n\nSummary\n\nCreates a new category for the DVFA modules.\n\nArguments\n\nart::DVFA: the DVFA module to add a category to.\nx::RealVector: the sample to use for adding a category.\ny::Integer: the new label for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, x, y; new_cluster)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:237.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_x-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.ddt_x","text":"ddt_x(\n    x::AbstractArray{T} where T<:Real,\n    image::AbstractArray{T} where T<:Real,\n    sigma_s::AbstractArray{T} where T<:Real\n) -> SharedArrays.SharedArray{Float64, 3}\n\n\nSummary\n\nTime rate of change of LGN network (ARTSCENE Stage 2).\n\nMethod List / Definition Locations\n\nddt_x(x, image, sigma_s)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_y-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.ddt_y","text":"ddt_y(\n    y::AbstractArray{T} where T<:Real,\n    X_plus::AbstractArray{T} where T<:Real,\n    X_minus::AbstractArray{T} where T<:Real,\n    alpha::Real\n) -> SharedArrays.SharedArray{Float64, 4}\n\n\nSummary\n\nShunting equation for ARTSCENE Stage 3.\n\nMethod List / Definition Locations\n\nddt_y(y, X_plus, X_minus, alpha)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:112.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_z-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.ddt_z","text":"ddt_z(\n    z::AbstractArray{T} where T<:Real\n) -> SharedArrays.SharedArray{Float64, 4}\n\n\nSummary\n\nTime rate of change for ARTSCENE: Stage 5.\n\nMethod List / Definition Locations\n\nddt_z(z)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:211.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.element_min-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.element_min","text":"element_min(\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nReturns the element-wise minimum between sample x and weight W.\n\nArguments\n\nx::RealVector: the input sample.\nW::RealVector: the weight vector to compare the sample against.\n\nMethod List / Definition Locations\n\nelement_min(x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:178.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.gamma_activation","text":"gamma_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nGamma-normalized activation funtion.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\ngamma_activation(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:100.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.gamma_match","text":"gamma_match(\n    art::ARTModule,\n    _::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real,\n    gamma_act::Real\n) -> Any\n\n\nSummary\n\nGamma-normalized match function, passing a precomputed gamma activation value.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\ngamma_act::Real: the precomputed gamma activation value.\n\nMethod List / Definition Locations\n\ngamma_match(art, _, W, gamma_act)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:91.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.gamma_match","text":"gamma_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nGamma-normalized match function, recomputing the gamma activation value.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\ngamma_match(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:81.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match_sub-Tuple{ARTModule, AbstractVector{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.gamma_match_sub","text":"gamma_match_sub(\n    art::ARTModule,\n    W::AbstractVector{T} where T<:Real,\n    gamma_act::Real\n) -> Any\n\n\nSummary\n\nLow-level subroutine for the gamma match function with a precomputed gamma activation.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nW::RealVector: the weight vector to use.\ngamma_act::Real: the precomputed gamma activation value.\n\nMethod List / Definition Locations\n\ngamma_match_sub(art, W, gamma_act)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:72.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_data_shape-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_data_shape","text":"get_data_shape(\n    data::AbstractMatrix{T} where T<:Real\n) -> Tuple{Any, Any}\n\n\nSummary\n\nReturns the (dim, n_samples) of the provided 2-D data matrix, enforcing the ART package convention.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the feature dimension and number of samples from.\n\nMethod List / Definition Locations\n\nget_data_shape(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:249.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_dim-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_dim","text":"get_dim(data::AbstractMatrix{T} where T<:Real) -> Any\n\n\nSummary\n\nReturns the dimension of the data, enforcint the (dim, n_samples) convention of the package.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the feature dimension of.\n\nMethod List / Definition Locations\n\nget_dim(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:227.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_iterator-Tuple{ARTOpts, Integer}","page":"Internals","title":"AdaptiveResonance.get_iterator","text":"get_iterator(opts::ARTOpts, n_samples::Integer) -> Any\n\n\nSummary\n\nCreates an iterator object according to the ART/ARTMAP modules display settings for batch iteration.\n\nArguments\n\nopts::ARTOpts: the ART/ARTMAP module's options containing display settings.\nn_samples::Integer: the number of iterations to create the iterator for.\n\nMethod List / Definition Locations\n\nget_iterator(opts, n_samples)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:417.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_samples-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_n_samples","text":"get_n_samples(data::AbstractMatrix{T} where T<:Real) -> Any\n\n\nSummary\n\nReturns the number of samples, enforcing the convention of the package.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the number of samples from.\n\nMethod List / Definition Locations\n\nget_n_samples(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:238.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_weights-Tuple{DDVFA}","page":"Internals","title":"AdaptiveResonance.get_n_weights","text":"get_n_weights(art::DDVFA) -> Int64\n\n\nSummary\n\nConvenience function; return the sum total number of weights in the DDVFA module.\n\nMethod List / Definition Locations\n\nget_n_weights(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:567.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_weights_vec-Tuple{DDVFA}","page":"Internals","title":"AdaptiveResonance.get_n_weights_vec","text":"get_n_weights_vec(art::DDVFA) -> Vector{Int64}\n\n\nSummary\n\nConvenience function; return the number of weights in each category as a vector.\n\nArguments\n\nart::DDVFA: the DDVFA module to get all of the weights from as a list.\n\nMethod List / Definition Locations\n\nget_n_weights_vec(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:560.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_sample-Tuple{AbstractMatrix{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.get_sample","text":"get_sample(\n    x::AbstractMatrix{T} where T<:Real,\n    i::Integer\n) -> Any\n\n\nSummary\n\nReturns a sample from data array x at sample location i. This function implements the convention that columns are samples while rows are features within samples.\n\nArguments\n\nx::RealMatrix: the batch of data to grab a sample from.\ni::Integer: the index to get the sample from.\n\nMethod List / Definition Locations\n\nget_sample(x, i)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:453.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_classify!-Tuple{AbstractArray{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_classify!","text":"init_classify!(\n    x::AbstractArray{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\nInitializes the classification loop for batch inference.\n\nArguments\n\nx::RealArray: the data that is used for inference.\nart::ARTModule: the ART/ARTMAP module that will be used for inference.\npreprocessed::Bool: required flag for if the data has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_classify!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:519.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_train!-Tuple{AbstractMatrix{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_train!","text":"init_train!(\n    x::AbstractMatrix{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\nInitializes the training loop for batch learning.\n\nArguments\n\nx::RealMatrix: the data that is used for training.\nart::ARTModule: the ART/ARTMAP that will be trained.\npreprocessed::Bool: required flag for if the data has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_train!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:501.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_train!-Tuple{AbstractVector{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_train!","text":"init_train!(\n    x::AbstractVector{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nInitializes the module for training in a single iteration.\n\nThe purpose of this function is mainly to handle the conditions of complement coding. Fails if the module was incorrectly set up or if the module was not setup and the data was not preprocessed.\n\nArguments\n\nx::RealVector: the sample used for initialization.\nart::ARTModule: the ART/ARTMAP module that will be trained on the sample.\npreprocessed::Bool: a required flag for if the sample has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_train!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:470.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.initialize!-Tuple{ART, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.initialize!","text":"Summary\n\nInitializes the ART module for training with sample 'x' and optional label 'y', setting up the data configuration and instantiating the first category.\n\nThis function is used during the first training iteration when the ART module is empty.\n\nArguments\n\nart::ART: the ART module to initialize.\nx::RealVector: the sample to use for initialization.\ny::Integer=0: the optional new label for the first weight of the ART module. If not specified, defaults the new label to 1.\n\nExamples\n\njulia> my_FuzzyART = FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\njulia> initialize!(my_FuzzyART, [1, 2, 3, 4])\n\n\n# Method List / Definition Locations\n\n\njulia initialize!(art, x; y) ```\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:22.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.initialize!-Tuple{ARTMAP, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.initialize!","text":"Summary\n\nInitializes the supervised ARTMAP module for training with sample 'x' and label 'y', setting up the data configuration and instantiating the first category.\n\nArguments\n\nart::ARTMAP: the ARTMAP module to initialize.\nx::RealVector: the sample to use for initialization.\ny::Integer: the initial supervised label.\n\nExamples\n\njulia> my_sfam = SFAM()\nSFAM\n    opts: opts_SFAM\n    ...\njulia> initialize!(my_SFAM, [1, 2, 3, 4])\n\n\n# Method List / Definition Locations\n\n\njulia initialize!(art, x, y) ```\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:197.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.learn!-Tuple{AdaptiveResonance.AbstractFuzzyART, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.learn!","text":"learn!(\n    art::AdaptiveResonance.AbstractFuzzyART,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n)\n\n\nSummary\n\nIn place learning function.\n\nArguments\n\nart::AbstractFuzzyART: the FuzzyART module to update.\nx::RealVector: the sample to learn from.\nindex::Integer: the index of the FuzzyART weight to update.\n\nMethod List / Definition Locations\n\nlearn!(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:74.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.learn!-Tuple{SFAM, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.learn!","text":"learn!(\n    art::SFAM,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n)\n\n\nSummary\n\nIn-place learning function.\n\nMethod List / Definition Locations\n\nlearn!(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:341.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.log_art_stats!-Tuple{ARTModule, Integer, Bool}","page":"Internals","title":"AdaptiveResonance.log_art_stats!","text":"log_art_stats!(art::ARTModule, bmu::Integer, mismatch::Bool)\n\n\nSummary\n\nLogs common statistics of an ART module after a training/classification iteration.\n\nArguments\n\nart::ARTModule: the ART module that just underwent training/classification.\nbmu::Integer: the best-matching unit integer index.\nmismatch::Bool: flag of whether there was a mismatch in this iteration.\n\nMethod List / Definition Locations\n\nlog_art_stats!(art, bmu, mismatch)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:160.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.median-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.median","text":"median(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nMedian linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\nmedian(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:497.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.orientation_competition-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.orientation_competition","text":"orientation_competition(\n    z::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 5: Orientation competition at the same position.\n\nMethod List / Definition Locations\n\norientation_competition(z)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:236.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.oriented_kernel-Tuple{Integer, Integer, Integer, Integer, Integer, Real, Real}","page":"Internals","title":"AdaptiveResonance.oriented_kernel","text":"oriented_kernel(\n    i::Integer,\n    j::Integer,\n    p::Integer,\n    q::Integer,\n    k::Integer,\n    sigma_h::Real,\n    sigma_v::Real;\n    sign\n) -> Any\n\n\nSummary\n\nOriented, elongated, spatially offset kernel G for ARTSCENE Stage 3.\n\nMethod List / Definition Locations\n\noriented_kernel(i, j, p, q, k, sigma_h, sigma_v; sign)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:90.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.patch_orientation_color-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.patch_orientation_color","text":"patch_orientation_color(\n    z::AbstractArray{T} where T<:Real,\n    image::AbstractArray{T} where T<:Real\n) -> Tuple{Any, Array{Float64, 3}}\n\n\nSummary\n\nARTSCENE Stage 6: Create patch feature vectors.\n\nMethod List / Definition Locations\n\npatch_orientation_color(z, image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:257.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.replace_mat_index!-Tuple{AbstractMatrix{T} where T<:Real, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.replace_mat_index!","text":"replace_mat_index!(\n    mat::AbstractMatrix{T} where T<:Real,\n    vec::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nReplaces a matrix element with a vector at the column index.\n\nThis function dispatches to the low-level replacement strategy.\n\nArguments\n\nmat::RealMatrix: the matrix to update with a replaced column vector.\nvec::RealVector: the vector to put in the matrix at the column index.\nindex::Integer: the column index to put the vector.\n\nMethod List / Definition Locations\n\nreplace_mat_index!(mat, vec, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:19.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.set_threshold!-Tuple{ARTModule}","page":"Internals","title":"AdaptiveResonance.set_threshold!","text":"Summary\n\nSets the match threshold of the ART/ARTMAP module as a function of the vigilance parameter.\n\nDepending on selected ART/ARTMAP module and its options, this may be a function of other parameters as well.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module for setting a new threshold.\n\nMethod List / Definition Locations\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:254.\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:223.\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:258.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.similarity-Tuple{Symbol, FuzzyART, AbstractVector{T} where T<:Real, Bool}","page":"Internals","title":"AdaptiveResonance.similarity","text":"similarity(\n    method::Symbol,\n    F2::FuzzyART,\n    sample::AbstractVector{T} where T<:Real,\n    activation::Bool\n) -> Any\n\n\nSummary\n\nCompute the similarity metric depending on method with explicit comparisons for the field name.\n\nArguments\n\nmethod::Symbol: the linkage method to use.\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nsample::RealVector: the sample to use for computing the linkage to the F2 module.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\nsimilarity(method, F2, sample, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:438.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.single-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.single","text":"single(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nSingle linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\nsingle(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:470.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.stopping_conditions-Tuple{ARTModule}","page":"Internals","title":"AdaptiveResonance.stopping_conditions","text":"stopping_conditions(art::ARTModule) -> Any\n\n\nSummary\n\nChecks the stopping conditions for an ART module.\n\nArguments\n\nart::ART: the ART module to check stopping conditions for.\n\nMethod List / Definition Locations\n\nstopping_conditions(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:589.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.surround_kernel-NTuple{5, Integer}","page":"Internals","title":"AdaptiveResonance.surround_kernel","text":"surround_kernel(\n    i::Integer,\n    j::Integer,\n    p::Integer,\n    q::Integer,\n    scale::Integer\n) -> Any\n\n\nSummary\n\nSurround kernel S function for ARTSCENE Stage 2.\n\nMethod List / Definition Locations\n\nsurround_kernel(i, j, p, q, scale)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:32.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.unnormalized_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.unnormalized_match","text":"unnormalized_match(\n    _::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nUnnormalized match function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nunnormalized_match(_, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:49.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.unsafe_replace_mat_index!-Tuple{AbstractMatrix{T} where T<:Real, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.unsafe_replace_mat_index!","text":"unsafe_replace_mat_index!(\n    mat::AbstractMatrix{T} where T<:Real,\n    vec::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nLow-level function for unsafely replacing a matrix column with a given vector.\n\nArguments\n\nmat::RealMatrix: the matrix to update with a replaced column vector.\nvec::RealVector: the vector to put in the matrix at the column index.\nindex::Integer: the column index to put the vector.\n\nMethod List / Definition Locations\n\nunsafe_replace_mat_index!(mat, vec, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:28.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.update_iter-Tuple{ARTModule, Union{ProgressBars.ProgressBar, UnitRange}, Integer}","page":"Internals","title":"AdaptiveResonance.update_iter","text":"update_iter(\n    art::ARTModule,\n    iter::Union{ProgressBars.ProgressBar, UnitRange},\n    i::Integer\n) -> Union{Nothing, String}\n\n\nSummary\n\nUpdates the iteration of the ART/ARTMAP module, training or inference, according to its display settings.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module being iterated upon.\niter::ARTIterator: the iterator object used in the training/inference loop.\ni::Integer: the iteration during training/inference that the iterator should be updated to.\n\nMethod List / Definition Locations\n\nupdate_iter(art, iter, i)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:436.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.weighted-Tuple{FuzzyART, Bool}","page":"Internals","title":"AdaptiveResonance.weighted","text":"weighted(F2::FuzzyART, activation::Bool) -> Float64\n\n\nSummary\n\nWeighted linkage DDVFA similarity function.\n\nArguments:\n\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\nweighted(F2, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:508.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.x_W_min_norm-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.x_W_min_norm","text":"x_W_min_norm(\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nLow-level common function for computing the 1-norm of the element minimum of a sample and weights.\n\nArguments\n\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nx_W_min_norm(x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:19.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#main-index","page":"Index","title":"Index","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This page lists the core methods and types of the AdaptiveResonance.jl package. The Modules section lists the modules exported by the package including the AdaptiveResonance module itself. The Methods section lists the public methods for the package that use the modules in Types. Each of these entries link to the docstrings in the Docs section.","category":"page"},{"location":"man/full-index/","page":"Index","title":"Index","text":"ART modules document their internal working parameters and references, while their hyperparameters/options are documented under their corresponding option structs opts_....","category":"page"},{"location":"man/full-index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This section enumerates the names exported by the package, each of which links to its corresponding Documentation.","category":"page"},{"location":"man/full-index/#index-modules","page":"Index","title":"Modules","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:module]","category":"page"},{"location":"man/full-index/#index-methods","page":"Index","title":"Methods","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:function]","category":"page"},{"location":"man/full-index/#index-types","page":"Index","title":"Types","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:type]","category":"page"},{"location":"man/full-index/#index-constants","page":"Index","title":"Constants","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:constant]","category":"page"},{"location":"man/full-index/#index-docs","page":"Index","title":"Docs","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This section lists the documentation for every exported name of the AdaptiveResonance.jl package.","category":"page"},{"location":"man/full-index/#index-modules-docs","page":"Index","title":"Modules","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:module]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.AdaptiveResonance","page":"Index","title":"AdaptiveResonance.AdaptiveResonance","text":"Main module for AdaptiveResonance.jl, a Julia package of adaptive resonance theory algorithms.\n\nThis module exports all of the ART modules, options, and utilities used by the AdaptiveResonance.jl package. For full usage, see the official guide at https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/guide/.\n\nBasic Usage\n\nInstall and import the package in a script with\n\nusing Pkg\nPkg.add(\"AdaptiveResonance\")\nusing AdaptiveResonance\n\nthen create an ART module with default options\n\nmy_art = DDVFA()\n\nor custom options via keyword arguments\n\nmy_art = DDVFA(rho_ub=0.45, rho_ub=0.7)\n\nTrain all models with train! and conduct inference with classify. In batch, samples are interpreted in the Julia column-major fashion with dimensions (n_dim, n_samples) (i.e., columns are samples).\n\nTrain unsupervised ART modules incrementally or in batch with optional labels as a keyword argument y\n\n# Load your data somehow\nsamples, labels = load_some_data()\n\n# Unsupervised batch\ntrain!(my_art, samples)\n\n# Supervised batch\ntrain!(my_art, samples, y=labels)\n\n# Unsupervised incremental\nfor ix in eachindex(labels)\n    train!(my_art, samples[:, ix])\nend\n\n# Supervised incremental\nfor ix in eachindex(labels)\n    train!(my_art, samples[:, ix], y=labels[ix])\nend\n\nTrain supervised ARTMAP with positional arguments\n\nmy_artmap = SFAM()\ntrain!(my_artmap, samples, labels)\n\nWith either module, conduct inference with classify(art, samples)\n\n# Batch inference\ny_hat = classify(my_art, test_samples)\n\n# Incremental inference\nfor ix in eachindex(test_labels)\n    y_hat[ix] = classify(my_artmap, test_samples[:, ix])\nend\n\nImports\n\nThe following names are imported by the package as dependencies:\n\nBase\nCore\nDistributed\nDocStringExtensions\nElasticArrays\nLogging\nNumericalTypeAliases\nParameters\nPkg\nProgressBars\nSharedArrays\n\nExports\n\nThe following names are exported and available when using the package:\n\nACTIVATION_FUNCTIONS\nADAPTIVERESONANCE_MODULES\nADAPTIVERESONANCE_VERSION\nART\nARTMAP\nARTMAP_MODULES\nARTModule\nARTOpts\nART_MODULES\nDAM\nDDVFA\nDDVFA_METHODS\nDVFA\nDataConfig\nFAM\nFuzzyART\nGammaNormalizedFuzzyART\nMATCH_FUNCTIONS\nSFAM\nUPDATE_FUNCTIONS\nartscene_filter\nclassify\ncomplement_code\ndata_setup!\nget_W\nget_data_characteristics\nlinear_normalization\nopts_DAM\nopts_DDVFA\nopts_DVFA\nopts_FAM\nopts_FuzzyART\nopts_GammaNormalizedFuzzyART\nopts_SFAM\nperformance\ntrain!\n\n\n\n\n\n","category":"module"},{"location":"man/full-index/#index-functions-docs","page":"Index","title":"Functions","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:function]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.DAM-Tuple{opts_SFAM}","page":"Index","title":"AdaptiveResonance.DAM","text":"DAM(opts::opts_SFAM) -> SFAM\n\n\nSummary\n\nImplements a Default ARTMAP module with specified options.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nArguments\n\nopts::opts_SFAM: the Simplified FuzzyARTMAP options (see AdaptiveResonance.opts_SFAM).\n\nMethod List / Definition Locations\n\nDAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:41.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DAM-Tuple{}","page":"Index","title":"AdaptiveResonance.DAM","text":"DAM(; kwargs...) -> SFAM\n\n\nSummary\n\nConstructs a Default ARTMAP module using a SFAM module using Default ARTMAP's choice-by-difference activation function.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nArguments\n\nkwargs: keyword arguments of Simplified FuzzyARTMAP options (see AdaptiveResonance.opts_SFAM)\n\nReferences:\n\nG. P. Amis and G. A. Carpenter, 'Default ARTMAP 2,' IEEE Int. Conf. Neural Networks - Conf. Proc., vol. 2, no. September 2007, pp. 777-782, Mar. 2007, doi: 10.1109/IJCNN.2007.4371056.\n\nMethod List / Definition Locations\n\nDAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:29.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.GammaNormalizedFuzzyART-Tuple{opts_FuzzyART}","page":"Index","title":"AdaptiveResonance.GammaNormalizedFuzzyART","text":"GammaNormalizedFuzzyART(opts::opts_FuzzyART)\n\n\nSummary\n\nImplements a Gamma-Normalized FuzzyART module with specified options.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nArguments\n\nopts::opts_FuzzyART: the Fuzzy ART options (see AdaptiveResonance.opts_FuzzyART).\n\nMethod List / Definition Locations\n\nGammaNormalizedFuzzyART(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.GammaNormalizedFuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.GammaNormalizedFuzzyART","text":"GammaNormalizedFuzzyART(; kwargs...) -> FuzzyART\n\n\nSummary\n\nConstructs a Gamma-Normalized FuzzyART module as a variant of FuzzyART by using the gamma_normalization option.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nArguments\n\nkwargs: keyword arguments of FuzzyART options (see AdaptiveResonance.opts_FuzzyART)\n\nMethod List / Definition Locations\n\nGammaNormalizedFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:26.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.artscene_filter-Union{Tuple{Array{T, 3}}, Tuple{T}} where T<:AbstractFloat","page":"Index","title":"AdaptiveResonance.artscene_filter","text":"artscene_filter(\n    raw_image::Array{T<:AbstractFloat, 3}\n) -> Tuple{Array{Float64, 4}, Array{Float64, 3}}\n\n\nSummary\n\nProcess the full artscene filter toolchain on an image.\n\nArguments\n\nraw_image::Array{Real, 3}: the raw RGB image to process with the ARTSCENE filter.\n\nMethod List / Definition Locations\n\nartscene_filter(raw_image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:294.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.classify-Tuple{ARTModule, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.classify","text":"classify(\n    art::ARTModule,\n    x::AbstractMatrix{T} where T<:Real;\n    preprocessed,\n    get_bmu\n) -> Any\n\n\nSummary\n\nPredict categories of 'x' using the ART model.\n\nReturns predicted categories 'y_hat.'\n\nArguments\n\nart::ARTModule: ART or ARTMAP module to use for batch inference.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\npreprocessed::Bool=false: flag, if the data has already been complement coded or not.\nget_bmu::Bool=false, flag, if the model should return the best-matching-unit label in the case of total mismatch.\n\nExamples\n\njulia> my_DDVFA = DDVFA()\nDDVFA\n    opts: opts_DDVFA\n    ...\njulia> x, y = load_data()\njulia> train!(my_DDVFA, x)\njulia> y_hat = classify(my_DDVFA, y)\n\nMethod List / Definition Locations\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:554.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.classify-Tuple{ARTModule, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.classify","text":"Summary\n\nPredict categories of a single sample of features 'x' using the ART model.\n\nReturns predicted category 'y_hat.'\n\nArguments\n\nart::ARTModule: ART or ARTMAP module to use for batch inference.\nx::RealVector: the single sample of features to classify.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\nget_bmu::Bool=false: optional, flag if the model should return the best-matching-unit label in the case of total mismatch.\n\nMethod List / Definition Locations\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:335.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:337.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:370.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:293.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.complement_code-Tuple{AbstractArray{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.complement_code","text":"complement_code(\n    data::AbstractArray{T} where T<:Real;\n    config\n) -> Any\n\n\nSummary\n\nNormalizes the data x to [0, 1] and returns the augmented vector [x, 1 - x].\n\nArguments\n\ndata::RealArray: the 1-D or 2-D data to be complement coded.\nconfig::DataConfig=DataConfig(): the data configuration for the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\ncomplement_code(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:402.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.data_setup!-Tuple{ARTModule, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.data_setup!","text":"data_setup!(\n    art::ARTModule,\n    data::AbstractMatrix{T} where T<:Real\n)\n\n\nSummary\n\nConvenience method for setting up the DataConfig of an ART module in advance.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module to manually configure the data config for.\ndata::RealArray: the 2-D batch of data used to create the data config.\n\nMethod List / Definition Locations\n\ndata_setup!(art, data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:295.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.data_setup!-Tuple{DataConfig, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.data_setup!","text":"data_setup!(\n    config::DataConfig,\n    data::AbstractMatrix{T} where T<:Real\n)\n\n\nSummary\n\nSets up the data config for the ART module before training.\n\nThis function crucially gets the original and complement-coded dimensions of the data, and it infers the bounds of the data (minimums and maximums) by the largest and smallest values along each feature dimension.\n\nArguments\n\nconfig::DataConfig: the ART/ARTMAP module's data configuration object.\ndata::RealMatrix: the 2-D batch of data to use for creating the data configuration.\n\nMethod List / Definition Locations\n\ndata_setup!(config, data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:268.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.get_W-Tuple{DDVFA}","page":"Index","title":"AdaptiveResonance.get_W","text":"get_W(art::DDVFA) -> Vector\n\n\nSummary\n\nConvenience function; return a concatenated array of all DDVFA weights.\n\nArguments\n\nart::DDVFA: the DDVFA module to get all of the weights from as a list.\n\nMethod List / Definition Locations\n\nget_W(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:549.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.get_data_characteristics-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.get_data_characteristics","text":"get_data_characteristics(\n    data::AbstractMatrix{T} where T<:Real;\n    config\n) -> NTuple{4, Any}\n\n\nSummary\n\nGet the characteristics of the data, taking account if a data config is passed.\n\nIf no DataConfig is passed, then the data characteristics come from the array itself. Otherwise, use the config for the statistics of the data and the data array for the number of samples.\n\nArguments\n\ndata::RealMatrix: the 2-D data to be complement coded.\nconfig::DataConfig=DataConfig(): the data configuration for the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nget_data_characteristics(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:310.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.linear_normalization-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.linear_normalization","text":"linear_normalization(\n    data::AbstractMatrix{T} where T<:Real;\n    config\n) -> Any\n\n\nSummary\n\nNormalize the data to the range [0, 1] along each feature.\n\nArguments\n\ndata::RealMatrix: the 2-D batch of data to normalize.\nconfig::DataConfig=DataConfig(): the data configuration from the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nlinear_normalization(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:369.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.linear_normalization-Tuple{AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.linear_normalization","text":"linear_normalization(\n    data::AbstractVector{T} where T<:Real;\n    config\n) -> Vector{Float64}\n\n\nSummary\n\nNormalize the data to the range [0, 1] along each feature.\n\nArguments\n\ndata::RealVector: the 1-D sample of data to normalize.\nconfig::DataConfig=DataConfig(): the data configuration from the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nlinear_normalization(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:339.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_DAM-Tuple{}","page":"Index","title":"AdaptiveResonance.opts_DAM","text":"opts_DAM(; kwargs...) -> opts_SFAM\n\n\nSummary\n\nImplements a Default ARTMAP module's options.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nMethod List / Definition Locations\n\nopts_DAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:52.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_GammaNormalizedFuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.opts_GammaNormalizedFuzzyART","text":"opts_GammaNormalizedFuzzyART(; kwargs...)\n\n\nSummary\n\nImplements a Gamma-Normalized FuzzyART module's options.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nMethod List / Definition Locations\n\nopts_GammaNormalizedFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:50.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.performance-Tuple{AbstractVector{T} where T<:Integer, AbstractVector{T} where T<:Integer}","page":"Index","title":"AdaptiveResonance.performance","text":"performance(\n    y_hat::AbstractVector{T} where T<:Integer,\n    y::AbstractVector{T} where T<:Integer\n) -> Any\n\n\nSummary\n\nConvenience function to get the categorization performance of y_hat against y.\n\nArguments\n\ny_hat::IntegerVector: the estimated labels.\ny::IntegerVector: the true labels.\n\nMethod List / Definition Locations\n\nperformance(y_hat, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:200.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!","page":"Index","title":"AdaptiveResonance.train!","text":"train!(\n    art::ARTMAP,\n    x::AbstractMatrix{T} where T<:Real,\n    y::AbstractVector{T} where T<:Integer\n) -> Any\ntrain!(\n    art::ARTMAP,\n    x::AbstractMatrix{T} where T<:Real,\n    y::AbstractVector{T} where T<:Integer,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\ntrain!(art::ARTMAP, x::RealMatrix, y::IntegerVector, preprocessed::Bool=false)\n\nTrain the ARTMAP model on a batch of data 'x' with supervisory labels 'y.'\n\nArguments\n\nart::ARTMAP: the supervised ARTMAP model to train.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\ny::IntegerVector: labels for supervisory training.\npreprocessed::Bool=false: flag, if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x, y)\ntrain!(art, x, y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/common.jl:23.\n\n\n\n\n\n","category":"function"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ART, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.train!","text":"train!(\n    art::ART,\n    x::AbstractMatrix{T} where T<:Real;\n    y,\n    preprocessed\n) -> Any\n\n\nSummary\n\nTrain the ART model on a batch of data 'x' with optional supervisory labels 'y.'\n\nArguments\n\nart::ART: the unsupervised ART model to train.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\ny::IntegerVector=Int[]: optional, labels for simple supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/common.jl:21.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ART, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.train!","text":"Summary\n\nTrain the ART model on a single sample of features 'x' with an optional supervisory label.\n\nArguments\n\nart::ART: the unsupervised ART model to train.\nx::RealVector: the single sample feature vector to train upon.\ny::Integer=0: optional, a label for simple supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:266.\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:260.\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:292.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ARTMAP, AbstractVector{T} where T<:Real, Integer}","page":"Index","title":"AdaptiveResonance.train!","text":"Summary\n\nTrain the supervised ARTMAP model on a single sample of features 'x' with supervisory label 'y'.\n\nArguments\n\nart::ARTMAP: the supervised ART model to train.\nx::RealVector: the single sample feature vector to train upon.\ny::Integer: the label for supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x, y; preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:227.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#index-types-docs","page":"Index","title":"Types","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:type]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.ART","page":"Index","title":"AdaptiveResonance.ART","text":"abstract type ART <: ARTModule\n\nSummary\n\nAbstract supertype for all default unsupervised ART modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTMAP","page":"Index","title":"AdaptiveResonance.ARTMAP","text":"abstract type ARTMAP <: ARTModule\n\nSummary\n\nAbstract supertype for all supervised ARTMAP modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTModule","page":"Index","title":"AdaptiveResonance.ARTModule","text":"abstract type ARTModule\n\nSummary\n\nAbstract supertype for both ART (unsupervised) and ARTMAP (supervised) modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTOpts","page":"Index","title":"AdaptiveResonance.ARTOpts","text":"abstract type ARTOpts\n\nSummary\n\nAbstract supertype for all ART module options.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DDVFA","page":"Index","title":"AdaptiveResonance.DDVFA","text":"mutable struct DDVFA <: ART\n\nSummary\n\nDistributed Dual Vigilance Fuzzy ARTMAP module struct.\n\nFor module options, see AdaptiveResonance.opts_DDVFA.\n\nReferences\n\nL. E. Brito da Silva, I. Elnabarawy, and D. C. Wunsch, 'Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence,' Neural Networks, vol. 121, pp. 208-228, 2020, doi: 10.1016/j.neunet.2019.08.033.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DDVFA: DDVFA options struct.\n\nsubopts::opts_FuzzyART: FuzzyART options struct used for all F2 nodes.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nF2::Vector{FuzzyART}: List of F2 nodes (themselves FuzzyART modules).\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of total categories.\n\nepoch::Int64: Current training epoch.\n\nT::Vector{Float64}: DDVFA activation values.\n\nM::Vector{Float64}: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DDVFA-Tuple{opts_DDVFA}","page":"Index","title":"AdaptiveResonance.DDVFA","text":"DDVFA(opts::opts_DDVFA) -> DDVFA\n\n\nSummary\n\nImplements a DDVFA learner with specified options.\n\nArguments\n\nopts::opts_DDVFA: the DDVFA options (see AdaptiveResonance.opts_DDVFA).\n\nExamples\n\njulia> my_opts = opts_DDVFA()\njulia> DDVFA(my_opts)\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nDDVFA(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:219.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DDVFA-Tuple{}","page":"Index","title":"AdaptiveResonance.DDVFA","text":"DDVFA(; kwargs...) -> DDVFA\n\n\nSummary\n\nImplements a DDVFA learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the DDVFA options struct (see AdaptiveResonance.opts_DDVFA.)\n\nExamples\n\nBy default:\n\njulia> DDVFA()\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nor with keyword arguments:\n\njulia> DDVFA(rho_lb=0.4, rho_ub = 0.75)\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nDDVFA(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:198.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DVFA","page":"Index","title":"AdaptiveResonance.DVFA","text":"mutable struct DVFA <: AdaptiveResonance.AbstractFuzzyART\n\nSummary\n\nDual Vigilance Fuzzy ARTMAP module struct.\n\nFor module options, see AdaptiveResonance.opts_DVFA.\n\nReferences:\n\nL. E. Brito da Silva, I. Elnabarawy and D. C. Wunsch II, 'Dual Vigilance Fuzzy ART,' Neural Networks Letters. To appear.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DVFA: DVFA options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold_ub::Float64: Operating upper bound module threshold value, a function of the upper bound vigilance parameter.\n\nthreshold_lb::Float64: Operating lower bound module threshold value, a function of the lower bound vigilance parameter.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nT::Vector{Float64}: Activation values for every weight for a given sample.\n\nM::Vector{Float64}: Match values for every weight for a given sample.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nn_clusters::Int64: Number of labeled clusters, may be lower than n_categories\n\nepoch::Int64: Current training epoch.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DVFA-Tuple{opts_DVFA}","page":"Index","title":"AdaptiveResonance.DVFA","text":"DVFA(opts::opts_DVFA) -> DVFA\n\n\nSummary\n\nImplements a DVFA learner with specified options.\n\nArguments\n\nopts::opts_DVFA: the DVFA options (see AdaptiveResonance.opts_DVFA).\n\nExamples\n\njulia> my_opts = opts_DVFA()\njulia> DVFA(my_opts)\nDVFA\n    opts: opts_DVFA\n    ...\n\nMethod List / Definition Locations\n\nDVFA(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:201.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DVFA-Tuple{}","page":"Index","title":"AdaptiveResonance.DVFA","text":"DVFA(; kwargs...) -> DVFA\n\n\nSummary\n\nImplements a DVFA learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the DVFA options struct (see AdaptiveResonance.opts_DVFA.)\n\nExamples\n\nBy default:\n\njulia> DVFA()\nDVFA\n    opts: opts_DVFA\n    ...\n\nor with keyword arguments:\n\njulia> DVFA(rho=0.7)\nDVFA\n    opts: opts_DVFA\n    ...\n\nMethod List / Definition Locations\n\nDVFA(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:181.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig","page":"Index","title":"AdaptiveResonance.DataConfig","text":"mutable struct DataConfig\n\nSummary\n\nContainer to standardize training/testing data configuration.\n\nThis container declares if a data configuration has been setup, what the original and complement coded dimensions are, and what the minimums and maximums of the values along each feature dimension are.\n\nFields\n\nsetup::Bool: Flag if data has been setup yet or not.\n\nmins::Vector{Float64}: List of minimum values for each feature.\n\nmaxs::Vector{Float64}: List of maximum values for each feature.\n\ndim::Int64: Dimensionality of the feature vectors (i.e., number of features).\n\ndim_comp::Int64: Complement coded feature dimensionality, twice the size of dim.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(\n    data::AbstractMatrix{T} where T<:Real\n) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only the data matrix.\n\nArguments\n\ndata::RealMatrix: the 2-D batch of data to be used for inferring the data configuration.\n\nMethod List / Definition Locations\n\nDataConfig(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:120.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(\n    mins::AbstractVector{T} where T<:Real,\n    maxs::AbstractVector{T} where T<:Real\n) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only mins and maxs of the features.\n\nThis constructor is used when the mins and maxs differ across features. The dimension is inferred by the length of the mins and maxs.\n\nArguments\n\nmins::RealVector: a vector of minimum values for each feature dimension.\nmaxs::RealVector: a vector of maximum values for each feature dimension.\n\nMethod List / Definition Locations\n\nDataConfig(mins, maxs)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:79.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{Real, Real, Integer}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(min::Real, max::Real, dim::Integer) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only a global min, max, and dim.\n\nThis constructor is used in the case that the feature mins and maxs are all the same respectively.\n\nArguments\n\nmin::Real: the minimum value across all features.\nmax::Real: the maximum value across all features.\ndim::Integer: the dimension of the features, which must be provided because it cannot be inferred from just the minimum or maximum values.\n\nMethod List / Definition Locations\n\nDataConfig(min, max, dim)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:104.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig() -> DataConfig\n\n\nSummary\n\nDefault constructor for a data configuration, not set up.\n\nMethod List / Definition Locations\n\nDataConfig()\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:60.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FAM","page":"Index","title":"AdaptiveResonance.FAM","text":"mutable struct FAM <: ARTMAP\n\nSummary\n\nFuzzy ARTMAP struct.\n\nFor module options, see AdaptiveResonance.opts_FAM.\n\nReferences\n\nG. A. Carpenter, S. Grossberg, N. Markuzon, J. H. Reynolds, and D. B. Rosen, “Fuzzy ARTMAP: A Neural Network Architecture for Incremental Supervised Learning of Analog Multidimensional Maps,” IEEE Trans. Neural Networks, vol. 3, no. 5, pp. 698-713, 1992, doi: 10.1109/72.159059.\n\nFields\n\nopts::opts_FAM: Fuzzy ARTMAP options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.FAM-Tuple{opts_FAM}","page":"Index","title":"AdaptiveResonance.FAM","text":"FAM(opts::opts_FAM) -> FAM\n\n\nSummary\n\nImplements a Fuzzy ARTMAP learner with specified options.\n\nExamples\n\njulia> opts = opts_FAM()\njulia> FAM(opts)\nFAM\n    opts: opts_FAM\n    ...\n\nMethod List / Definition Locations\n\nFAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/FAM.jl:138.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FAM-Tuple{}","page":"Index","title":"AdaptiveResonance.FAM","text":"FAM(; kwargs...) -> FAM\n\n\nSummary\n\nImplements a Fuzzy ARTMAP learner with optional keyword arguments.\n\nExamples\n\nBy default:\n\njulia> FAM()\nFAM\n    opts: opts_FAM\n    ...\n\nor with keyword arguments:\n\njulia> FAM(rho=0.7)\nFAM\n    opts: opts_FAM\n    ...\n\nMethod List / Definition Locations\n\nFAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/FAM.jl:121.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"mutable struct FuzzyART <: AdaptiveResonance.AbstractFuzzyART\n\nSummary\n\nGamma-Normalized Fuzzy ART learner struct\n\nFor module options, see AdaptiveResonance.opts_FuzzyART.\n\nReferences\n\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_FuzzyART: FuzzyART options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nT::Vector{Float64}: Activation values for every weight for a given sample.\n\nM::Vector{Float64}: Match values for every weight for a given sample.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nn_instance::Vector{Int64}: Number of weights associated with each category.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{opts_FuzzyART, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(\n    opts::opts_FuzzyART,\n    sample::AbstractVector{T} where T<:Real;\n    preprocessed\n) -> FuzzyART\n\n\nSummary\n\nCreate and initialize a FuzzyART with a single sample in one step.\n\nPrincipally used as a method for initialization within DDVFA.\n\nArguments\n\nopts::opts_FuzzyART: the FuzzyART options contains.\nsample::RealVector: the sample to use as a basis for setting up the FuzzyART.\npreprocessed::Bool=false: flag for if the sample is already complement coded and normalized.\n\nMethod List / Definition Locations\n\nFuzzyART(opts, sample; preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:239.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{opts_FuzzyART}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(opts::opts_FuzzyART) -> FuzzyART\n\n\nSummary\n\nImplements a Fuzzy ART learner with specified options.\n\nArguments\n\nopts::opts_FuzzyART: the FuzzyART options struct with specified options (see AdaptiveResonance.opts_FuzzyART).\n\nExamples\n\njulia> FuzzyART(opts)\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nFuzzyART(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:206.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(; kwargs...) -> FuzzyART\n\n\nSummary\n\nImplements a Fuzzy ART learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments of FuzzyART options (see AdaptiveResonance.opts_FuzzyART).\n\nExamples\n\nBy default:\n\njulia> FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nor with keyword arguments:\n\njulia> FuzzyART(rho=0.7)\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:184.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.SFAM","page":"Index","title":"AdaptiveResonance.SFAM","text":"mutable struct SFAM <: ARTMAP\n\nSummary\n\nSimple Fuzzy ARTMAP struct.\n\nFor module options, see AdaptiveResonance.opts_SFAM.\n\nReferences\n\nG. A. Carpenter, S. Grossberg, N. Markuzon, J. H. Reynolds, and D. B. Rosen, “Fuzzy ARTMAP: A Neural Network Architecture for Incremental Supervised Learning of Analog Multidimensional Maps,” IEEE Trans. Neural Networks, vol. 3, no. 5, pp. 698-713, 1992, doi: 10.1109/72.159059.\n\nFields\n\nopts::opts_SFAM: Simplified Fuzzy ARTMAP options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\nT::Vector{Float64}: DDVFA activation values.\n\nM::Vector{Float64}: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.SFAM-Tuple{opts_SFAM}","page":"Index","title":"AdaptiveResonance.SFAM","text":"SFAM(opts::opts_SFAM) -> SFAM\n\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner with specified options.\n\nArguments\n\nopts::opts_SFAM: the Simple Fuzzy ARTMAP options (see AdaptiveResonance.opts_SFAM).\n\nExamples\n\njulia> opts = opts_SFAM()\njulia> SFAM(opts)\nSFAM\n    opts: opts_SFAM\n    ...\n\nMethod List / Definition Locations\n\nSFAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:178.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.SFAM-Tuple{}","page":"Index","title":"AdaptiveResonance.SFAM","text":"SFAM(; kwargs...) -> SFAM\n\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the Simple Fuzzy ARTMAP options struct (see AdaptiveResonance.opts_SFAM.)\n\nExamples\n\nBy default:\n\njulia> SFAM()\nSFAM\n    opts: opts_SFAM\n    ...\n\nor with keyword arguments:\n\njulia> SFAM(rho=0.6)\nSFAM\n    opts: opts_SFAM\n    ...\n\nMethod List / Definition Locations\n\nSFAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:158.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_DDVFA","page":"Index","title":"AdaptiveResonance.opts_DDVFA","text":"mutable struct opts_DDVFA <: ARTOpts\n\nSummary\n\nDistributed Dual Vigilance Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.7\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.85\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nsimilarity::Symbol: Similarity method (activation and match): similarity ∈ [:single, :average, :complete, :median, :weighted, :centroid].  Default: :single\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.  Default: true\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :gamma_activation\nmatch::Symbol: Selected match function.  Default: :gamma_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_DVFA","page":"Index","title":"AdaptiveResonance.opts_DVFA","text":"mutable struct opts_DVFA <: ARTOpts\n\nSummary\n\nDual Vigilance Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.55\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.75\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training.  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nmatch::Symbol: Selected match function.  Default: :unnormalized_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_FAM","page":"Index","title":"AdaptiveResonance.opts_FAM","text":"mutable struct opts_FAM <: ARTOpts\n\nSummary\n\nImplements a Fuzzy ARTMAP learner's options.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.6\nalpha::Float64: Choice parameter: alpha > 0.  Default: 1.0e-7\nepsilon::Float64: Match tracking parameter: epsilon ∈ (0, 1).  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epochs::Int64: Maximum number of epochs during training: max_epochs ∈ [1, Inf)  Default: 1\nuncommitted::Bool: Uncommitted node flag.  Default: true\ndisplay::Bool: Display flag for progress bars.  Default: false\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_FuzzyART","page":"Index","title":"AdaptiveResonance.opts_FuzzyART","text":"mutable struct opts_FuzzyART <: ARTOpts\n\nSummary\n\nGamma-Normalized Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.6\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.\nNOTE: this flag overwrites the activation and match settings here to their gamma-normalized equivalents along with adjusting the thresold.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nmatch::Symbol: Selected match function.  Default: :basic_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_SFAM","page":"Index","title":"AdaptiveResonance.opts_SFAM","text":"mutable struct opts_SFAM <: ARTOpts\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner's options.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.75\nalpha::Float64: Choice parameter: alpha > 0.  Default: 1.0e-7\nepsilon::Float64: Match tracking parameter: epsilon ∈ (0, 1).  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training: max_epoch ∈ [1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nmatch::Symbol: Selected match function.  Default: :basic_match\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#index-constants-docs","page":"Index","title":"Constants","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:constant]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.ACTIVATION_FUNCTIONS","page":"Index","title":"AdaptiveResonance.ACTIVATION_FUNCTIONS","text":"ACTIVATION_FUNCTIONS\n\nDescription\n\nEnumerates all of the activation functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ADAPTIVERESONANCE_MODULES","page":"Index","title":"AdaptiveResonance.ADAPTIVERESONANCE_MODULES","text":"ADAPTIVERESONANCE_MODULES\n\nDescription\n\nA combined list of all unsupervised ART and supervised ARTMAP modules from the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ADAPTIVERESONANCE_VERSION","page":"Index","title":"AdaptiveResonance.ADAPTIVERESONANCE_VERSION","text":"ADAPTIVERESONANCE_VERSION\n\nDescription\n\nA constant that contains the version of the installed AdaptiveResonance.jl package.\n\nThis value is computed at compile time, so it may be used to programmatically verify the version of AdaptiveResonance that is installed in case a compat entry in your Project.toml is missing or otherwise incorrect.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ARTMAP_MODULES","page":"Index","title":"AdaptiveResonance.ARTMAP_MODULES","text":"ARTMAP_MODULES\n\nDescription\n\nA list of supervised ARTMAP modules that are available in the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ART_MODULES","page":"Index","title":"AdaptiveResonance.ART_MODULES","text":"ART_MODULES\n\nDescription\n\nA list of (default) unsupervised ART modules that are available in the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.DDVFA_METHODS","page":"Index","title":"AdaptiveResonance.DDVFA_METHODS","text":"DDVFA_METHODS\n\nDescription\n\nA list of all DDVFA similarity linkage methods.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.MATCH_FUNCTIONS","page":"Index","title":"AdaptiveResonance.MATCH_FUNCTIONS","text":"MATCH_FUNCTIONS\n\nDescription\n\nEnumerates all of the match functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.UPDATE_FUNCTIONS","page":"Index","title":"AdaptiveResonance.UPDATE_FUNCTIONS","text":"UPDATE_FUNCTIONS\n\nDescription\n\nEnumerates all of the update functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/incremental-batch.jl\"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#incremental_batch","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Overview","page":"Incremental vs. Batch Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"All modules in AdaptiveResonance.jl are designed to handle incremental and batch training. In fact, ART modules are generally incremental in their implementation, so their batch methods wrap the incremental ones and handle preprocessing, etc. For example, DDVFA can be run incrementally (i.e. with one sample at a time) with custom algorithmic options and a predetermined data configuration.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"note: Note\nIn the incremental case, it is necessary to provide a data configuration if the model is not pretrained because the model has no knowledge of the boundaries and dimensionality of the data, which are necessary in the complement coding step. For more info, see the guide in the docs on incremental vs. batch.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Data-Setup","page":"Incremental vs. Batch Example","title":"Data Setup","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(([4.5 6.3 4.4 6.5 5.5 5.6 6.0 5.9 5.0 5.3 6.9 5.5 7.1 4.9 6.1 6.6 6.1 6.2 6.9 5.6 5.5 5.1 4.8 6.0 5.5 6.3 5.6 7.7 6.4 6.4 5.7 5.7 4.6 7.7 4.6 4.6 6.6 5.4 5.4 6.4 5.4 5.7 4.4 6.8 6.3 5.4 5.8 5.1 5.2 5.7 6.7 6.2 5.9 6.9 5.6 5.5 6.0 5.0 5.7 5.8 7.7 7.4 4.8 6.0 7.6 5.1 5.7 5.8 5.2 7.2 6.5 6.2 4.9 5.7 4.3 6.7 4.8 6.3 4.8 5.0 6.8 5.0 7.2 7.3 6.4 5.5 5.0 5.1 5.1 6.3 6.7 5.2 6.7 6.7 6.0 6.4 4.7 4.6 6.7 7.0 5.0 7.7 6.1 7.2 7.9; 2.3 2.7 3.2 3.0 3.5 3.0 2.7 3.2 3.6 3.7 3.1 2.6 3.0 3.0 2.9 2.9 2.6 2.9 3.2 2.7 2.4 3.5 3.0 2.2 4.2 3.3 2.5 2.6 3.1 2.9 2.8 2.6 3.4 3.0 3.2 3.6 3.0 3.9 3.4 3.2 3.7 3.0 2.9 3.0 3.3 3.0 2.7 3.3 3.4 4.4 2.5 3.4 3.0 3.1 3.0 2.5 3.0 2.3 2.8 2.7 3.8 2.8 3.0 3.4 3.0 3.7 2.9 2.7 3.5 3.0 3.0 2.8 2.4 3.8 3.0 3.0 3.1 2.5 3.4 3.4 3.2 3.3 3.6 2.9 3.2 2.4 3.5 3.5 3.4 2.9 3.3 4.1 3.1 3.1 2.9 2.7 3.2 3.1 3.1 3.2 3.5 2.8 3.0 3.2 3.8; 1.3 4.9 1.3 5.2 1.3 4.5 5.1 4.8 1.4 1.5 5.1 4.4 5.9 1.4 4.7 4.6 5.6 4.3 5.7 4.2 3.8 1.4 1.4 4.0 1.4 6.0 3.9 6.9 5.5 4.3 4.5 3.5 1.4 6.1 1.4 1.0 4.4 1.3 1.7 5.3 1.5 4.2 1.4 5.5 4.7 4.5 4.1 1.7 1.4 1.5 5.8 5.4 5.1 4.9 4.1 4.0 4.8 3.3 4.1 5.1 6.7 6.1 1.4 4.5 6.6 1.5 4.2 3.9 1.5 5.8 5.8 4.8 3.3 1.7 1.1 5.2 1.6 4.9 1.9 1.6 5.9 1.4 6.1 6.3 4.5 3.7 1.3 1.4 1.5 5.6 5.7 1.5 4.4 5.6 4.5 5.3 1.6 1.5 4.7 4.7 1.6 6.7 4.9 6.0 6.4; 0.3 1.8 0.2 2.0 0.2 1.5 1.6 1.8 0.2 0.2 2.3 1.2 2.1 0.2 1.4 1.3 1.4 1.3 2.3 1.3 1.1 0.3 0.3 1.0 0.2 2.5 1.1 2.3 1.8 1.3 1.3 1.0 0.3 2.3 0.2 0.2 1.4 0.4 0.2 2.3 0.2 1.2 0.2 2.1 1.6 1.5 1.0 0.5 0.2 0.4 1.8 2.3 1.8 1.5 1.3 1.3 1.8 1.0 1.3 1.9 2.2 1.9 0.1 1.6 2.1 0.4 1.3 1.2 0.2 1.6 2.2 1.8 1.0 0.3 0.1 2.3 0.2 1.5 0.2 0.4 2.3 0.2 2.5 1.8 1.5 1.0 0.3 0.2 0.2 1.8 2.1 0.1 1.4 2.4 1.5 1.9 0.2 0.2 1.5 1.4 0.6 2.0 1.8 1.8 2.0], [1, 3, 1, 3, 1, 2, 2, 2, 1, 1, 3, 2, 3, 1, 2, 2, 3, 2, 3, 2, 2, 1, 1, 2, 1, 3, 2, 3, 3, 2, 2, 2, 1, 3, 1, 1, 2, 1, 1, 3, 1, 2, 1, 3, 2, 2, 2, 1, 1, 1, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 2, 1, 3, 3, 3, 2, 1, 1, 3, 1, 2, 1, 1, 3, 1, 3, 3, 2, 2, 1, 1, 1, 3, 3, 1, 2, 3, 2, 3, 1, 1, 2, 2, 1, 3, 3, 3, 3]), ([6.1 5.5 5.0 6.0 5.0 5.8 4.7 4.9 6.7 6.8 6.7 5.1 5.8 5.6 4.9 6.3 5.1 5.2 6.2 4.9 5.1 4.9 6.3 5.6 4.4 6.3 5.8 6.9 5.1 5.4 5.4 6.4 6.5 6.1 6.1 5.0 6.5 5.8 5.7 4.8 6.3 5.0 6.4 5.9 6.5; 2.8 2.3 3.4 2.2 3.0 2.6 3.2 2.5 3.3 2.8 3.0 3.8 2.8 2.9 3.1 3.4 3.8 2.7 2.2 3.1 2.5 3.1 2.5 2.8 3.0 2.3 4.0 3.1 3.8 3.4 3.9 2.8 2.8 3.0 2.8 2.0 3.0 2.7 2.5 3.4 2.8 3.2 2.8 3.0 3.2; 4.0 4.0 1.5 5.0 1.6 4.0 1.3 4.5 5.7 4.8 5.0 1.6 5.1 3.6 1.5 5.6 1.9 3.9 4.5 1.5 3.0 1.5 5.0 4.9 1.3 4.4 1.2 5.4 1.5 1.5 1.7 5.6 4.6 4.6 4.7 3.5 5.5 5.1 5.0 1.6 5.1 1.2 5.6 4.2 5.1; 1.3 1.3 0.2 1.5 0.2 1.2 0.2 1.7 2.5 1.4 1.7 0.2 2.4 1.3 0.1 2.4 0.4 1.4 1.5 0.1 1.1 0.1 1.9 2.0 0.2 1.3 0.2 2.1 0.3 0.4 0.4 2.1 1.5 1.4 1.2 1.0 1.8 1.9 2.0 0.2 1.5 0.2 2.2 1.5 2.0], [2, 2, 1, 3, 1, 2, 1, 3, 3, 2, 2, 1, 3, 2, 1, 3, 1, 2, 2, 1, 2, 1, 3, 3, 1, 2, 1, 3, 1, 1, 1, 3, 2, 2, 2, 2, 3, 3, 3, 1, 3, 1, 3, 2, 3]))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Incremental-vs.-Batch","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/#Setup","page":"Incremental vs. Batch Example","title":"Setup","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Now, we can create several modules to illustrate training one in batch and one incrementaly.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Create several modules for batch and incremental training.\n# We can take advantage of the options instantiation method here to use the same options for both modules.\nopts = opts_DDVFA(rho_lb=0.6, rho_ub=0.75)\nart_batch = DDVFA(opts)\nart_incremental = DDVFA(opts)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"For the incremental version, we must setup the data configuration in advance. In batch mode, this is done automatically based upon the provided data, but the incremental variant has not way of knowing the bounds of the individual features. We could preprocess the data and set the data configuration with art.config = DataConfig(0, 1, 4), which translates to the data containing four features  that all range from 0 to 1. This would be done in scenarios where we have either done some preprocessing on the data or have prior knowledge about the bounds of individual features. However, in this example we will let the module determine the bounds with the convenience method data_setup!:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Setup the data config on all of the features.\ndata_setup!(art_incremental.config, features)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Training","page":"Incremental vs. Batch Example","title":"Training","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can train in batch with a simple supervised mode by passing the labels as a keyword argument.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"y_hat_batch_train = train!(art_batch, X_train, y=y_train)\nprintln(\"Training labels: \",  size(y_hat_batch_train), \" \", typeof(y_hat_batch_train))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can also train incrementally with the same method, being careful that we pass a vector features and a single integer as the labels","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Get the number of training samples\nn_train = length(y_train)\n# Create a container for the training output labels\ny_hat_incremental_train = zeros(Int, n_train)\n# Iterate over all training samples\nfor ix in eachindex(y_train)\n    sample = X_train[:, ix]\n    label = y_train[ix]\n    y_hat_incremental_train[ix] = train!(art_incremental, sample, y=label)\nend","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Testing","page":"Incremental vs. Batch Example","title":"Testing","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can then classify both networks and check that their performances are equivalent. For both, we will use the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Classify one model in batch mode\ny_hat_batch = AdaptiveResonance.classify(art_batch, X_test, get_bmu=true)\n\n# Classify one model incrementally\nn_test = length(y_test)\ny_hat_incremental = zeros(Int, n_test)\nfor ix = 1:n_test\n    y_hat_incremental[ix] = AdaptiveResonance.classify(art_incremental, X_test[:, ix], get_bmu=true)\nend\n\n# Check the shape and type of the output labels\nprintln(\"Batch testing labels: \",  size(y_hat_batch), \" \", typeof(y_hat_batch))\nprintln(\"Incremental testing labels: \",  size(y_hat_incremental), \" \", typeof(y_hat_incremental))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Batch testing labels: (45,) Vector{Int64}\nIncremental testing labels: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Finally, we check the performance (number of correct classifications over total number of test samples) for both models, verifying that they produce the same results.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train_batch = performance(y_hat_batch_train, y_train)\nperf_train_incremental = performance(y_hat_incremental_train, y_train)\nperf_test_batch = performance(y_hat_batch, y_test)\nperf_test_incremental = performance(y_hat_incremental, y_test)\n\n# Format each performance number for comparison\n@printf \"Batch training performance: %.4f\\n\" perf_train_batch\n@printf \"Incremental training performance: %.4f\\n\" perf_train_incremental\n@printf \"Batch testing performance: %.4f\\n\" perf_test_batch\n@printf \"Incremental testing performance: %.4f\\n\" perf_test_incremental","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Batch training performance: 1.0000\nIncremental training performance: 1.0000\nBatch testing performance: 0.9111\nIncremental testing performance: 0.9111\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Visualization","page":"Incremental vs. Batch Example","title":"Visualization","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"So we showed that the performance and behavior of modules are identical in incremental and batch modes. Great! Sadly, illustrating this point doesn't lend itself to visualization in any meaningful way. Nonetheless, we would like a pretty picture at the end of the experiment to verify that these identical solutions work in the first place. Sanity checks are meaningful in their own right, right?","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"To do this, we will reduce the dimensionality of the dataset to two dimensions and show in a scatter plot how the modules classify the test data into groups. This will be done with principal component analysis (PCA) to cast the points into a 2-D space while trying to preserve the relative distances between points in the higher dimension. The process isn't perfect by any means, but it suffices for visualization.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Import visualization utilities\nusing Printf            # Formatted number printing\nusing MultivariateStats # Principal component analysis (PCA)\nusing Plots             # Plotting frontend\ngr()                    # Use the default GR backend explicitly\n\n# Train a PCA model\nM = fit(PCA, features; maxoutdim=2)\n\n# Apply the PCA model to the testing set\nX_test_pca = MultivariateStats.transform(M, X_test)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"2×45 Matrix{Float64}:\n -0.356787   -0.180967  2.62648   -1.29833    2.50792   -0.228879   2.88982   -0.519383  -2.41939   -1.33104  -1.5574    2.53757   -1.58527    0.174864   2.67384   -2.14499   2.20883    0.0101901  -0.942362   2.67384    0.908463   2.67384   -1.52566   -1.1981     2.98184  -0.812868  2.64354  -2.10765   2.58735   2.41008  2.2799    -2.12285   -1.08713    -0.89016    -0.920503   0.511086  -1.94925    -1.41407   -1.34459   2.61314    -1.4431    2.867      -2.15874   -0.511098  -1.66193\n -0.0668238  -0.825604  0.170405  -0.761014  -0.139056  -0.402258  -0.137346  -1.19135    0.303504   0.24467   0.267393  0.510368  -0.539307  -0.251816  -0.106692   0.138907  0.442696  -0.720575   -0.541822  -0.106692  -0.751569  -0.106692  -0.375021  -0.605579  -0.48025  -0.370679  1.18619   0.371482  0.520474  0.41808  0.747783  -0.210855   0.0753904  -0.0338124  -0.18239   -1.26249    0.0407303  -0.574925  -0.776415  0.0215206  -0.143801  0.0771931  -0.218326  -0.102284   0.242038","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Now that we have the test points cast into a 2-D set of points, we can create a scatter plot that shows how each point is categorized by the modules.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Create a scatterplot object from the data with some additional formatting options\nscatter(\n    X_test_pca[1, :],       # PCA dimension 1\n    X_test_pca[2, :],       # PCA dimension 2\n    group = y_hat_batch,    # labels belonging to each point\n    markersize = 8,         # size of scatter points\n    legend = false,         # no legend\n    xtickfontsize = 12,     # x-tick size\n    ytickfontsize = 12,     # y-tick size\n    dpi = 300,              # Set the dots-per-inch\n    xlims = :round,         # Round up the x-limits to the nearest whole number\n    xlabel = \"\\$PCA_1\\$\",   # x-label\n    ylabel = \"\\$PCA_2\\$\",   # y-label\n    title = (@sprintf \"DDVFA Iris Clusters\"),   # formatted title\n)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip970\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip970)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip971\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip970)\" d=\"M310.676 1405.9 L2352.76 1405.9 L2352.76 123.472 L310.676 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip972\">\n    <rect x=\"310\" y=\"123\" width=\"2043\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"651.023,1405.9 651.023,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"991.369,1405.9 991.369,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1331.72,1405.9 1331.72,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1672.06,1405.9 1672.06,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2012.41,1405.9 2012.41,123.472 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2352.76,1405.9 2352.76,123.472 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 2352.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"651.023,1405.9 651.023,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"991.369,1405.9 991.369,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1331.72,1405.9 1331.72,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1672.06,1405.9 1672.06,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2012.41,1405.9 2012.41,1387 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2352.76,1405.9 2352.76,1387 \"/>\n<path clip-path=\"url(#clip970)\" d=\"M264.878 1464.66 L309.391 1464.66 L309.391 1470.56 L264.878 1470.56 L264.878 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M345.78 1461.95 Q350.815 1463.02 353.627 1466.43 Q356.474 1469.83 356.474 1474.83 Q356.474 1482.5 351.197 1486.71 Q345.919 1490.91 336.197 1490.91 Q332.933 1490.91 329.461 1490.25 Q326.023 1489.62 322.343 1488.34 L322.343 1481.57 Q325.259 1483.27 328.731 1484.14 Q332.204 1485 335.988 1485 Q342.586 1485 346.023 1482.4 Q349.495 1479.8 349.495 1474.83 Q349.495 1470.25 346.266 1467.68 Q343.072 1465.07 337.342 1465.07 L331.301 1465.07 L331.301 1459.31 L337.62 1459.31 Q342.794 1459.31 345.537 1457.26 Q348.28 1455.18 348.28 1451.29 Q348.28 1447.3 345.433 1445.18 Q342.62 1443.03 337.342 1443.03 Q334.461 1443.03 331.162 1443.65 Q327.863 1444.28 323.905 1445.59 L323.905 1439.34 Q327.898 1438.23 331.37 1437.68 Q334.877 1437.12 337.967 1437.12 Q345.954 1437.12 350.606 1440.77 Q355.259 1444.38 355.259 1450.56 Q355.259 1454.87 352.794 1457.85 Q350.329 1460.8 345.78 1461.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M605.936 1464.66 L650.45 1464.66 L650.45 1470.56 L605.936 1470.56 L605.936 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M671.63 1484 L696.109 1484 L696.109 1489.9 L663.193 1489.9 L663.193 1484 Q667.186 1479.87 674.061 1472.92 Q680.97 1465.94 682.741 1463.93 Q686.109 1460.14 687.429 1457.54 Q688.783 1454.9 688.783 1452.37 Q688.783 1448.23 685.866 1445.63 Q682.984 1443.03 678.332 1443.03 Q675.033 1443.03 671.352 1444.17 Q667.707 1445.32 663.54 1447.64 L663.54 1440.56 Q667.776 1438.86 671.457 1437.99 Q675.137 1437.12 678.193 1437.12 Q686.248 1437.12 691.04 1441.15 Q695.831 1445.18 695.831 1451.91 Q695.831 1455.11 694.616 1457.99 Q693.436 1460.84 690.276 1464.73 Q689.408 1465.73 684.755 1470.56 Q680.102 1475.35 671.63 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M946.005 1464.66 L990.519 1464.66 L990.519 1470.56 L946.005 1470.56 L946.005 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1006.87 1484 L1018.33 1484 L1018.33 1444.45 L1005.87 1446.95 L1005.87 1440.56 L1018.26 1438.06 L1025.28 1438.06 L1025.28 1484 L1036.73 1484 L1036.73 1489.9 L1006.87 1489.9 L1006.87 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1331.72 1442.68 Q1326.3 1442.68 1323.56 1448.03 Q1320.85 1453.34 1320.85 1464.03 Q1320.85 1474.69 1323.56 1480.04 Q1326.3 1485.35 1331.72 1485.35 Q1337.17 1485.35 1339.88 1480.04 Q1342.62 1474.69 1342.62 1464.03 Q1342.62 1453.34 1339.88 1448.03 Q1337.17 1442.68 1331.72 1442.68 M1331.72 1437.12 Q1340.43 1437.12 1345.01 1444.03 Q1349.63 1450.91 1349.63 1464.03 Q1349.63 1477.12 1345.01 1484.03 Q1340.43 1490.91 1331.72 1490.91 Q1323 1490.91 1318.38 1484.03 Q1313.8 1477.12 1313.8 1464.03 Q1313.8 1450.91 1318.38 1444.03 Q1323 1437.12 1331.72 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1657.64 1484 L1669.09 1484 L1669.09 1444.45 L1656.63 1446.95 L1656.63 1440.56 L1669.02 1438.06 L1676.04 1438.06 L1676.04 1484 L1687.5 1484 L1687.5 1489.9 L1657.64 1489.9 L1657.64 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2004.39 1484 L2028.87 1484 L2028.87 1489.9 L1995.95 1489.9 L1995.95 1484 Q1999.94 1479.87 2006.82 1472.92 Q2013.73 1465.94 2015.5 1463.93 Q2018.87 1460.14 2020.19 1457.54 Q2021.54 1454.9 2021.54 1452.37 Q2021.54 1448.23 2018.62 1445.63 Q2015.74 1443.03 2011.09 1443.03 Q2007.79 1443.03 2004.11 1444.17 Q2000.46 1445.32 1996.3 1447.64 L1996.3 1440.56 Q2000.53 1438.86 2004.21 1437.99 Q2007.9 1437.12 2010.95 1437.12 Q2019.01 1437.12 2023.8 1441.15 Q2028.59 1445.18 2028.59 1451.91 Q2028.59 1455.11 2027.37 1457.99 Q2026.19 1460.84 2023.03 1464.73 Q2022.17 1465.73 2017.51 1470.56 Q2012.86 1475.35 2004.39 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M2359.13 1461.95 Q2364.16 1463.02 2366.97 1466.43 Q2369.82 1469.83 2369.82 1474.83 Q2369.82 1482.5 2364.54 1486.71 Q2359.27 1490.91 2349.54 1490.91 Q2346.28 1490.91 2342.81 1490.25 Q2339.37 1489.62 2335.69 1488.34 L2335.69 1481.57 Q2338.61 1483.27 2342.08 1484.14 Q2345.55 1485 2349.34 1485 Q2355.93 1485 2359.37 1482.4 Q2362.84 1479.8 2362.84 1474.83 Q2362.84 1470.25 2359.61 1467.68 Q2356.42 1465.07 2350.69 1465.07 L2344.65 1465.07 L2344.65 1459.31 L2350.97 1459.31 Q2356.14 1459.31 2358.88 1457.26 Q2361.63 1455.18 2361.63 1451.29 Q2361.63 1447.3 2358.78 1445.18 Q2355.97 1443.03 2350.69 1443.03 Q2347.81 1443.03 2344.51 1443.65 Q2341.21 1444.28 2337.25 1445.59 L2337.25 1439.34 Q2341.25 1438.23 2344.72 1437.68 Q2348.22 1437.12 2351.31 1437.12 Q2359.3 1437.12 2363.95 1440.77 Q2368.61 1444.38 2368.61 1450.56 Q2368.61 1454.87 2366.14 1457.85 Q2363.68 1460.8 2359.13 1461.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1293.14 1527.31 Q1293.14 1530.92 1290.47 1534.24 Q1287.83 1537.55 1283.52 1539.58 Q1279.23 1541.58 1274.63 1541.58 L1263.42 1541.58 L1259.33 1558.07 Q1259.3 1558.17 1259.2 1558.58 Q1259.1 1558.97 1259.1 1559.2 Q1259.1 1560 1260.1 1560.19 Q1261.13 1560.39 1263.42 1560.39 Q1264.9 1560.39 1265.13 1560.65 Q1265.25 1560.81 1265.25 1561.1 Q1265.25 1561.55 1265.13 1561.87 Q1265 1562.16 1264.74 1562.26 Q1264.51 1562.35 1264.35 1562.38 Q1264.19 1562.42 1263.93 1562.42 Q1263.26 1562.42 1261.81 1562.35 Q1260.39 1562.29 1259.65 1562.29 L1255.43 1562.22 L1247.06 1562.42 Q1246.06 1562.42 1246.06 1561.61 Q1246.06 1561 1246.32 1560.74 Q1246.58 1560.45 1246.86 1560.42 Q1247.15 1560.39 1247.9 1560.39 Q1249.51 1560.39 1250.47 1560.29 Q1251.44 1560.19 1252.05 1560.07 Q1252.69 1559.9 1253.02 1559.45 Q1253.37 1559 1253.53 1558.62 Q1253.69 1558.2 1253.92 1557.26 L1262.74 1521.84 Q1263 1520.77 1263 1520.61 Q1263 1520.07 1262.68 1519.87 Q1262.39 1519.65 1261.55 1519.55 Q1259.94 1519.42 1258.72 1519.42 Q1257.91 1519.42 1257.59 1519.39 Q1257.3 1519.36 1257.04 1519.2 Q1256.82 1519 1256.82 1518.62 Q1256.82 1518 1257.07 1517.75 Q1257.36 1517.46 1257.69 1517.42 Q1258.01 1517.36 1258.78 1517.36 L1280.17 1517.36 Q1286.32 1517.36 1289.73 1520.29 Q1293.14 1523.22 1293.14 1527.31 M1287.03 1525.73 Q1287.03 1519.42 1278.04 1519.42 L1271.73 1519.42 Q1269.63 1519.42 1269.12 1519.81 Q1268.6 1520.16 1268.15 1521.93 L1263.68 1539.87 L1272.98 1539.87 Q1279.23 1539.87 1283.13 1536.36 Q1284.9 1534.75 1285.96 1531.4 Q1287.03 1528.05 1287.03 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1343.51 1516.59 L1339.36 1533.4 Q1339.07 1534.46 1338.88 1534.59 Q1338.72 1534.72 1338.2 1534.72 Q1337.2 1534.72 1337.2 1534.04 Q1337.2 1533.98 1337.3 1533.14 Q1337.39 1532.27 1337.39 1530.69 Q1337.39 1524.86 1334.56 1521.42 Q1331.76 1517.97 1326.77 1517.97 Q1322.45 1517.97 1318.1 1520.16 Q1313.79 1522.35 1310.7 1525.93 Q1308.38 1528.63 1306.67 1532.05 Q1305 1535.46 1304.19 1538.58 Q1303.42 1541.71 1303.06 1544.06 Q1302.71 1546.41 1302.71 1548.12 Q1302.71 1550.6 1303.22 1552.69 Q1303.77 1554.78 1304.74 1556.27 Q1305.7 1557.71 1306.93 1558.84 Q1308.18 1559.94 1309.63 1560.58 Q1311.11 1561.22 1312.6 1561.55 Q1314.08 1561.84 1315.62 1561.84 Q1321.84 1561.84 1327.77 1557.01 Q1332.47 1553.04 1334.43 1546.57 Q1334.59 1545.93 1335.27 1545.93 Q1336.07 1545.93 1336.07 1546.57 Q1336.07 1546.7 1335.91 1547.34 Q1335.75 1547.96 1335.27 1549.21 Q1334.79 1550.44 1334.05 1551.82 Q1333.3 1553.21 1331.92 1554.94 Q1330.53 1556.68 1328.83 1558.2 Q1325.93 1560.71 1322.26 1562.29 Q1318.59 1563.87 1314.56 1563.87 Q1309.54 1563.87 1305.48 1561.64 Q1301.42 1559.42 1299.04 1555.27 Q1296.69 1551.11 1296.69 1545.8 Q1296.69 1540.19 1299.26 1534.69 Q1301.84 1529.18 1305.93 1525.09 Q1310.02 1521 1315.43 1518.46 Q1320.84 1515.91 1326.25 1515.91 Q1328.31 1515.91 1330.15 1516.46 Q1331.98 1517.01 1333.08 1517.68 Q1334.21 1518.36 1335.2 1519.36 Q1336.2 1520.32 1336.53 1520.77 Q1336.88 1521.23 1337.2 1521.77 L1341.81 1516.72 Q1342.61 1515.91 1342.81 1515.91 Q1343.19 1515.91 1343.35 1516.14 Q1343.51 1516.36 1343.51 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1388.64 1561.1 Q1388.64 1561.71 1388.38 1562.03 Q1388.15 1562.32 1387.93 1562.38 Q1387.73 1562.42 1387.44 1562.42 Q1386.61 1562.42 1383.71 1562.32 Q1380.81 1562.22 1379.97 1562.22 Q1378.62 1562.22 1375.85 1562.32 Q1373.08 1562.42 1371.73 1562.42 Q1370.83 1562.42 1370.83 1561.68 Q1370.83 1561.19 1370.92 1560.93 Q1371.02 1560.65 1371.28 1560.55 Q1371.57 1560.42 1371.73 1560.42 Q1371.92 1560.39 1372.4 1560.39 Q1373.05 1560.39 1373.72 1560.32 Q1374.4 1560.23 1375.24 1560.03 Q1376.07 1559.84 1376.59 1559.36 Q1377.14 1558.87 1377.14 1558.2 Q1377.14 1557.91 1376.91 1555.52 Q1376.69 1553.14 1376.4 1550.37 Q1376.11 1547.57 1376.07 1547.18 L1359.52 1547.18 Q1358.01 1549.79 1356.94 1551.6 Q1355.88 1553.4 1355.5 1554.01 Q1355.11 1554.62 1354.88 1555.01 Q1354.66 1555.4 1354.53 1555.62 Q1353.6 1557.33 1353.6 1558.07 Q1353.6 1560.13 1356.69 1560.39 Q1357.75 1560.39 1357.75 1561.16 Q1357.75 1561.74 1357.49 1562.06 Q1357.23 1562.35 1357.01 1562.38 Q1356.82 1562.42 1356.49 1562.42 Q1355.43 1562.42 1353.21 1562.32 Q1350.99 1562.22 1349.89 1562.22 Q1348.96 1562.22 1347.03 1562.32 Q1345.09 1562.42 1344.22 1562.42 Q1343.84 1562.42 1343.61 1562.19 Q1343.39 1561.97 1343.39 1561.68 Q1343.39 1561.22 1343.45 1560.97 Q1343.55 1560.71 1343.8 1560.58 Q1344.06 1560.45 1344.19 1560.45 Q1344.32 1560.42 1344.77 1560.39 Q1347.22 1560.23 1349.12 1559.07 Q1351.05 1557.88 1352.89 1554.82 L1375.82 1516.3 Q1376.04 1515.91 1376.2 1515.72 Q1376.36 1515.52 1376.69 1515.36 Q1377.04 1515.2 1377.56 1515.2 Q1378.36 1515.2 1378.52 1515.46 Q1378.68 1515.69 1378.78 1516.78 L1382.81 1558 Q1382.9 1558.87 1382.97 1559.23 Q1383.06 1559.55 1383.48 1559.9 Q1383.93 1560.23 1384.74 1560.32 Q1385.58 1560.39 1387.12 1560.39 Q1387.7 1560.39 1387.93 1560.42 Q1388.15 1560.42 1388.38 1560.58 Q1388.64 1560.74 1388.64 1561.1 M1375.88 1545.12 L1373.79 1523.38 L1360.78 1545.12 L1375.88 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1395.24 1554.34 L1395.24 1552.9 Q1400.78 1552.9 1403.65 1549.94 Q1404.44 1549.94 1404.57 1550.12 Q1404.71 1550.3 1404.71 1551.14 L1404.71 1577.04 Q1404.71 1578.42 1405.38 1578.84 Q1406.06 1579.27 1409.01 1579.27 L1410.48 1579.27 L1410.48 1580.69 Q1408.85 1580.56 1402.99 1580.56 Q1397.13 1580.56 1395.53 1580.69 L1395.53 1579.27 L1397 1579.27 Q1399.9 1579.27 1400.6 1578.87 Q1401.3 1578.44 1401.3 1577.04 L1401.3 1553.12 Q1398.89 1554.34 1395.24 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1239.91 2352.76,1239.91 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,992.876 2352.76,992.876 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,745.838 2352.76,745.838 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,498.8 2352.76,498.8 \"/>\n<polyline clip-path=\"url(#clip972)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,251.762 2352.76,251.762 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1239.91 329.574,1239.91 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,992.876 329.574,992.876 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,745.838 329.574,745.838 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,498.8 329.574,498.8 \"/>\n<polyline clip-path=\"url(#clip970)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,251.762 329.574,251.762 \"/>\n<path clip-path=\"url(#clip970)\" d=\"M114.26 1240.59 L158.774 1240.59 L158.774 1246.49 L114.26 1246.49 L114.26 1240.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M175.128 1259.93 L186.586 1259.93 L186.586 1220.38 L174.121 1222.88 L174.121 1216.49 L186.517 1213.99 L193.531 1213.99 L193.531 1259.93 L204.989 1259.93 L204.989 1265.83 L175.128 1265.83 L175.128 1259.93 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M219.155 1257.01 L226.482 1257.01 L226.482 1265.83 L219.155 1265.83 L219.155 1257.01 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M256.759 1218.61 Q251.343 1218.61 248.6 1223.96 Q245.891 1229.27 245.891 1239.97 Q245.891 1250.63 248.6 1255.97 Q251.343 1261.29 256.759 1261.29 Q262.211 1261.29 264.919 1255.97 Q267.662 1250.63 267.662 1239.97 Q267.662 1229.27 264.919 1223.96 Q262.211 1218.61 256.759 1218.61 M256.759 1213.06 Q265.475 1213.06 270.058 1219.97 Q274.676 1226.84 274.676 1239.97 Q274.676 1253.06 270.058 1259.97 Q265.475 1266.84 256.759 1266.84 Q248.044 1266.84 243.426 1259.97 Q238.843 1253.06 238.843 1239.97 Q238.843 1226.84 243.426 1219.97 Q248.044 1213.06 256.759 1213.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M115.753 993.553 L160.267 993.553 L160.267 999.456 L115.753 999.456 L115.753 993.553 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M190.406 971.574 Q184.989 971.574 182.246 976.921 Q179.538 982.233 179.538 992.928 Q179.538 1003.59 182.246 1008.93 Q184.989 1014.25 190.406 1014.25 Q195.857 1014.25 198.565 1008.93 Q201.308 1003.59 201.308 992.928 Q201.308 982.233 198.565 976.921 Q195.857 971.574 190.406 971.574 M190.406 966.018 Q199.121 966.018 203.704 972.928 Q208.322 979.803 208.322 992.928 Q208.322 1006.02 203.704 1012.93 Q199.121 1019.8 190.406 1019.8 Q181.69 1019.8 177.072 1012.93 Q172.489 1006.02 172.489 992.928 Q172.489 979.803 177.072 972.928 Q181.69 966.018 190.406 966.018 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M220.648 1009.98 L227.975 1009.98 L227.975 1018.8 L220.648 1018.8 L220.648 1009.98 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M243.322 966.956 L270.857 966.956 L270.857 972.858 L249.746 972.858 L249.746 985.567 Q251.273 985.046 252.801 984.803 Q254.329 984.525 255.857 984.525 Q264.537 984.525 269.607 989.282 Q274.676 994.039 274.676 1002.16 Q274.676 1010.53 269.468 1015.18 Q264.259 1019.8 254.78 1019.8 Q251.516 1019.8 248.114 1019.25 Q244.746 1018.69 241.134 1017.58 L241.134 1010.53 Q244.259 1012.23 247.593 1013.07 Q250.926 1013.9 254.641 1013.9 Q260.648 1013.9 264.155 1010.74 Q267.662 1007.58 267.662 1002.16 Q267.662 996.747 264.155 993.588 Q260.648 990.428 254.641 990.428 Q251.829 990.428 249.016 991.053 Q246.239 991.678 243.322 992.997 L243.322 966.956 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M188.913 724.536 Q183.496 724.536 180.753 729.883 Q178.045 735.195 178.045 745.89 Q178.045 756.549 180.753 761.897 Q183.496 767.209 188.913 767.209 Q194.364 767.209 197.072 761.897 Q199.815 756.549 199.815 745.89 Q199.815 735.195 197.072 729.883 Q194.364 724.536 188.913 724.536 M188.913 718.98 Q197.628 718.98 202.211 725.89 Q206.829 732.765 206.829 745.89 Q206.829 758.98 202.211 765.89 Q197.628 772.765 188.913 772.765 Q180.197 772.765 175.579 765.89 Q170.996 758.98 170.996 745.89 Q170.996 732.765 175.579 725.89 Q180.197 718.98 188.913 718.98 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M219.155 762.938 L226.482 762.938 L226.482 771.758 L219.155 771.758 L219.155 762.938 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M256.759 724.536 Q251.343 724.536 248.6 729.883 Q245.891 735.195 245.891 745.89 Q245.891 756.549 248.6 761.897 Q251.343 767.209 256.759 767.209 Q262.211 767.209 264.919 761.897 Q267.662 756.549 267.662 745.89 Q267.662 735.195 264.919 729.883 Q262.211 724.536 256.759 724.536 M256.759 718.98 Q265.475 718.98 270.058 725.89 Q274.676 732.765 274.676 745.89 Q274.676 758.98 270.058 765.89 Q265.475 772.765 256.759 772.765 Q248.044 772.765 243.426 765.89 Q238.843 758.98 238.843 745.89 Q238.843 732.765 243.426 725.89 Q248.044 718.98 256.759 718.98 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M190.406 477.498 Q184.989 477.498 182.246 482.845 Q179.538 488.157 179.538 498.852 Q179.538 509.511 182.246 514.859 Q184.989 520.171 190.406 520.171 Q195.857 520.171 198.565 514.859 Q201.308 509.511 201.308 498.852 Q201.308 488.157 198.565 482.845 Q195.857 477.498 190.406 477.498 M190.406 471.942 Q199.121 471.942 203.704 478.852 Q208.322 485.727 208.322 498.852 Q208.322 511.942 203.704 518.852 Q199.121 525.727 190.406 525.727 Q181.69 525.727 177.072 518.852 Q172.489 511.942 172.489 498.852 Q172.489 485.727 177.072 478.852 Q181.69 471.942 190.406 471.942 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M220.648 515.9 L227.975 515.9 L227.975 524.72 L220.648 524.72 L220.648 515.9 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M243.322 472.88 L270.857 472.88 L270.857 478.782 L249.746 478.782 L249.746 491.491 Q251.273 490.97 252.801 490.727 Q254.329 490.449 255.857 490.449 Q264.537 490.449 269.607 495.206 Q274.676 499.963 274.676 508.088 Q274.676 516.456 269.468 521.109 Q264.259 525.727 254.78 525.727 Q251.516 525.727 248.114 525.171 Q244.746 524.616 241.134 523.504 L241.134 516.456 Q244.259 518.157 247.593 518.991 Q250.926 519.824 254.641 519.824 Q260.648 519.824 264.155 516.664 Q267.662 513.504 267.662 508.088 Q267.662 502.671 264.155 499.512 Q260.648 496.352 254.641 496.352 Q251.829 496.352 249.016 496.977 Q246.239 497.602 243.322 498.921 L243.322 472.88 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M175.128 271.779 L186.586 271.779 L186.586 232.231 L174.121 234.731 L174.121 228.342 L186.517 225.842 L193.531 225.842 L193.531 271.779 L204.989 271.779 L204.989 277.682 L175.128 277.682 L175.128 271.779 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M219.155 268.862 L226.482 268.862 L226.482 277.682 L219.155 277.682 L219.155 268.862 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M256.759 230.46 Q251.343 230.46 248.6 235.807 Q245.891 241.119 245.891 251.814 Q245.891 262.473 248.6 267.821 Q251.343 273.133 256.759 273.133 Q262.211 273.133 264.919 267.821 Q267.662 262.473 267.662 251.814 Q267.662 241.119 264.919 235.807 Q262.211 230.46 256.759 230.46 M256.759 224.904 Q265.475 224.904 270.058 231.814 Q274.676 238.689 274.676 251.814 Q274.676 264.904 270.058 271.814 Q265.475 278.689 256.759 278.689 Q248.044 278.689 243.426 271.814 Q238.843 264.904 238.843 251.814 Q238.843 238.689 243.426 231.814 Q248.044 224.904 256.759 224.904 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M28.8883 804.838 Q32.4954 804.838 35.8126 807.511 Q39.1298 810.152 41.1587 814.467 Q43.1555 818.751 43.1555 823.356 L43.1555 834.564 L59.6449 838.654 Q59.7415 838.686 60.1602 838.783 Q60.5467 838.879 60.7721 838.879 Q61.5772 838.879 61.7705 837.881 Q61.9637 836.85 61.9637 834.564 Q61.9637 833.082 62.2214 832.857 Q62.3824 832.728 62.6722 832.728 Q63.1231 832.728 63.4452 832.857 Q63.735 832.986 63.8317 833.243 Q63.9283 833.469 63.9605 833.63 Q63.9927 833.791 63.9927 834.048 Q63.9927 834.725 63.9283 836.174 Q63.8639 837.591 63.8639 838.332 L63.7995 842.551 L63.9927 850.924 Q63.9927 851.923 63.1875 851.923 Q62.5756 851.923 62.318 851.665 Q62.0281 851.407 61.9959 851.117 Q61.9637 850.828 61.9637 850.087 Q61.9637 848.477 61.8671 847.51 Q61.7705 846.544 61.6417 845.932 Q61.4806 845.288 61.0297 844.966 Q60.5789 844.612 60.1924 844.451 Q59.7737 844.29 58.8398 844.064 L23.4133 835.24 Q22.3505 834.982 22.1895 834.982 Q21.642 834.982 21.4487 835.304 Q21.2233 835.594 21.1267 836.432 Q20.9979 838.042 20.9979 839.266 Q20.9979 840.071 20.9657 840.393 Q20.9335 840.683 20.7724 840.94 Q20.5792 841.166 20.1927 841.166 Q19.5808 841.166 19.3232 840.908 Q19.0333 840.618 19.0011 840.296 Q18.9367 839.974 18.9367 839.201 L18.9367 817.817 Q18.9367 811.665 21.8674 808.251 Q24.7982 804.838 28.8883 804.838 M27.3102 810.957 Q20.9979 810.957 20.9979 819.942 L20.9979 826.255 Q20.9979 828.348 21.3843 828.863 Q21.7386 829.378 23.5099 829.829 L41.4486 834.306 L41.4486 824.998 Q41.4486 818.751 37.9381 814.854 Q36.3279 813.082 32.9784 812.02 Q29.629 810.957 27.3102 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M18.1637 754.469 L34.9752 758.623 Q36.038 758.913 36.1668 759.106 Q36.2956 759.267 36.2956 759.783 Q36.2956 760.781 35.6193 760.781 Q35.5549 760.781 34.7176 760.684 Q33.848 760.588 32.2699 760.588 Q26.4407 760.588 22.9946 763.422 Q19.5486 766.224 19.5486 771.216 Q19.5486 775.531 21.7386 779.879 Q23.9286 784.195 27.5034 787.286 Q30.2087 789.605 33.6226 791.312 Q37.0364 792.987 40.1604 793.792 Q43.2843 794.565 45.6353 794.919 Q47.9864 795.273 49.6933 795.273 Q52.1731 795.273 54.2665 794.758 Q56.3599 794.211 57.8414 793.244 Q59.2906 792.278 60.4178 791.055 Q61.5128 789.798 62.157 788.349 Q62.8011 786.868 63.1231 785.386 Q63.413 783.905 63.413 782.359 Q63.413 776.143 58.5821 770.217 Q54.6208 765.515 48.1474 763.551 Q47.5033 763.39 47.5033 762.713 Q47.5033 761.908 48.1474 761.908 Q48.2762 761.908 48.9203 762.069 Q49.5323 762.23 50.7883 762.713 Q52.0121 763.196 53.397 763.937 Q54.7818 764.678 56.5209 766.063 Q58.26 767.448 59.7737 769.155 Q62.2858 772.053 63.8639 775.725 Q65.442 779.396 65.442 783.422 Q65.442 788.446 63.2197 792.504 Q60.9975 796.562 56.843 798.945 Q52.6884 801.296 47.3745 801.296 Q41.7706 801.296 36.2634 798.719 Q30.7562 796.143 26.6661 792.053 Q22.576 787.963 20.0317 782.552 Q17.4874 777.142 17.4874 771.731 Q17.4874 769.67 18.0349 767.834 Q18.5824 765.998 19.2587 764.903 Q19.9351 763.776 20.9335 762.778 Q21.8996 761.779 22.3505 761.457 Q22.8014 761.103 23.3489 760.781 L18.2926 756.176 Q17.4874 755.37 17.4874 755.177 Q17.4874 754.791 17.7129 754.63 Q17.9383 754.469 18.1637 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M62.6722 709.347 Q63.2842 709.347 63.6062 709.605 Q63.8961 709.83 63.9605 710.056 Q63.9927 710.249 63.9927 710.539 Q63.9927 711.376 63.8961 714.275 Q63.7995 717.173 63.7995 718.011 Q63.7995 719.363 63.8961 722.133 Q63.9927 724.903 63.9927 726.255 Q63.9927 727.157 63.252 727.157 Q62.7689 727.157 62.5112 727.061 Q62.2214 726.964 62.1247 726.706 Q61.9959 726.416 61.9959 726.255 Q61.9637 726.062 61.9637 725.579 Q61.9637 724.935 61.8993 724.259 Q61.8027 723.582 61.6095 722.745 Q61.4162 721.908 60.9331 721.392 Q60.45 720.845 59.7737 720.845 Q59.4839 720.845 57.1006 721.07 Q54.7174 721.296 51.9477 721.586 Q49.1458 721.875 48.7593 721.908 L48.7593 738.461 Q51.368 739.975 53.1715 741.038 Q54.975 742.101 55.587 742.487 Q56.1989 742.874 56.5853 743.099 Q56.9718 743.325 57.1973 743.453 Q58.9042 744.387 59.6449 744.387 Q61.7061 744.387 61.9637 741.296 Q61.9637 740.233 62.7367 740.233 Q63.3164 740.233 63.6384 740.49 Q63.9283 740.748 63.9605 740.973 Q63.9927 741.167 63.9927 741.489 Q63.9927 742.552 63.8961 744.774 Q63.7995 746.996 63.7995 748.091 Q63.7995 749.025 63.8961 750.957 Q63.9927 752.89 63.9927 753.759 Q63.9927 754.146 63.7672 754.371 Q63.5418 754.597 63.252 754.597 Q62.8011 754.597 62.5434 754.532 Q62.2858 754.436 62.157 754.178 Q62.0281 753.92 62.0281 753.791 Q61.9959 753.663 61.9637 753.212 Q61.8027 750.764 60.6433 748.864 Q59.4517 746.932 56.3921 745.096 L17.8739 722.165 Q17.4874 721.94 17.2942 721.779 Q17.101 721.618 16.9399 721.296 Q16.7789 720.941 16.7789 720.426 Q16.7789 719.621 17.0365 719.46 Q17.262 719.299 18.357 719.202 L59.5805 715.177 Q60.45 715.08 60.8043 715.016 Q61.1264 714.919 61.4806 714.5 Q61.8027 714.049 61.8993 713.244 Q61.9637 712.407 61.9637 710.861 Q61.9637 710.281 61.9959 710.056 Q61.9959 709.83 62.157 709.605 Q62.318 709.347 62.6722 709.347 M46.6981 722.101 L24.9592 724.194 L46.6981 737.205 L46.6981 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M82.2693 702.744 Q81.4351 702.744 81.1871 702.676 Q80.9391 702.586 80.5559 702.226 L70.6816 693.366 Q65.2259 688.519 60.4691 688.519 Q57.3806 688.519 55.1712 690.142 Q52.9619 691.743 52.9619 694.696 Q52.9619 696.725 54.2018 698.438 Q55.4418 700.151 57.6511 700.941 Q57.606 700.805 57.606 700.332 Q57.606 699.182 58.3274 698.551 Q59.0488 697.897 60.0182 697.897 Q61.2581 697.897 61.8668 698.709 Q62.453 699.498 62.453 700.287 Q62.453 700.602 62.3854 701.031 Q62.3177 701.437 61.6865 702.09 Q61.0327 702.744 59.883 702.744 Q56.6592 702.744 54.0891 700.309 Q51.5191 697.852 51.5191 694.11 Q51.5191 689.871 54.044 687.098 Q56.5464 684.303 60.4691 684.303 Q61.8443 684.303 63.1068 684.731 Q64.3467 685.137 65.3161 685.701 Q66.2855 686.242 67.841 687.73 Q69.3966 689.218 70.5012 690.412 Q71.6059 691.607 73.9505 694.29 L78.7073 699.182 L78.7073 690.863 Q78.7073 686.805 78.3466 686.49 Q77.6928 686.039 74.2436 685.475 L74.2436 684.303 L82.2693 685.611 L82.2693 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M948.399 18.8205 L948.399 65.8515 L958.283 65.8515 Q970.801 65.8515 976.593 60.1802 Q982.427 54.509 982.427 42.2752 Q982.427 30.1225 976.593 24.4918 Q970.801 18.8205 958.283 18.8205 L948.399 18.8205 M940.216 12.096 L957.028 12.096 Q974.608 12.096 982.832 19.4281 Q991.055 26.7198 991.055 42.2752 Q991.055 57.9117 982.791 65.2439 Q974.527 72.576 957.028 72.576 L940.216 72.576 L940.216 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1012.28 18.8205 L1012.28 65.8515 L1022.17 65.8515 Q1034.68 65.8515 1040.48 60.1802 Q1046.31 54.509 1046.31 42.2752 Q1046.31 30.1225 1040.48 24.4918 Q1034.68 18.8205 1022.17 18.8205 L1012.28 18.8205 M1004.1 12.096 L1020.91 12.096 Q1038.49 12.096 1046.71 19.4281 Q1054.94 26.7198 1054.94 42.2752 Q1054.94 57.9117 1046.67 65.2439 Q1038.41 72.576 1020.91 72.576 L1004.1 72.576 L1004.1 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1082.12 72.576 L1059.03 12.096 L1067.58 12.096 L1086.74 63.0159 L1105.94 12.096 L1114.45 12.096 L1091.4 72.576 L1082.12 72.576 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1123.28 12.096 L1158.03 12.096 L1158.03 18.9825 L1131.46 18.9825 L1131.46 36.8065 L1155.44 36.8065 L1155.44 43.6931 L1131.46 43.6931 L1131.46 72.576 L1123.28 72.576 L1123.28 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1183.59 20.1573 L1172.5 50.2555 L1194.73 50.2555 L1183.59 20.1573 M1178.98 12.096 L1188.25 12.096 L1211.3 72.576 L1202.8 72.576 L1197.29 57.061 L1170.02 57.061 L1164.51 72.576 L1155.89 72.576 L1178.98 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1246.51 12.096 L1254.69 12.096 L1254.69 72.576 L1246.51 72.576 L1246.51 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1296.94 34.1734 Q1295.68 33.4443 1294.18 33.1202 Q1292.73 32.7556 1290.94 32.7556 Q1284.62 32.7556 1281.22 36.8875 Q1277.86 40.9789 1277.86 48.6757 L1277.86 72.576 L1270.36 72.576 L1270.36 27.2059 L1277.86 27.2059 L1277.86 34.2544 Q1280.21 30.1225 1283.98 28.1376 Q1287.74 26.1121 1293.13 26.1121 Q1293.9 26.1121 1294.83 26.2337 Q1295.76 26.3147 1296.9 26.5172 L1296.94 34.1734 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1304.76 27.2059 L1312.21 27.2059 L1312.21 72.576 L1304.76 72.576 L1304.76 27.2059 M1304.76 9.54393 L1312.21 9.54393 L1312.21 18.9825 L1304.76 18.9825 L1304.76 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1356.73 28.5427 L1356.73 35.5912 Q1353.57 33.9709 1350.17 33.1607 Q1346.77 32.3505 1343.12 32.3505 Q1337.57 32.3505 1334.77 34.0519 Q1332.02 35.7533 1332.02 39.156 Q1332.02 41.7486 1334 43.2475 Q1335.99 44.7058 1341.98 46.0426 L1344.54 46.6097 Q1352.48 48.3111 1355.8 51.4303 Q1359.16 54.509 1359.16 60.0587 Q1359.16 66.3781 1354.14 70.0644 Q1349.16 73.7508 1340.41 73.7508 Q1336.76 73.7508 1332.79 73.0216 Q1328.86 72.3329 1324.49 70.9151 L1324.49 63.2184 Q1328.62 65.3654 1332.63 66.4591 Q1336.64 67.5124 1340.57 67.5124 Q1345.83 67.5124 1348.67 65.73 Q1351.5 63.9071 1351.5 60.6258 Q1351.5 57.5877 1349.44 55.9673 Q1347.41 54.3469 1340.49 52.8481 L1337.89 52.2405 Q1330.97 50.7821 1327.89 47.7845 Q1324.81 44.7463 1324.81 39.4801 Q1324.81 33.0797 1329.35 29.5959 Q1333.88 26.1121 1342.23 26.1121 Q1346.36 26.1121 1350.01 26.7198 Q1353.65 27.3274 1356.73 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1443.01 16.7545 L1443.01 25.383 Q1438.88 21.5346 1434.18 19.6307 Q1429.53 17.7268 1424.26 17.7268 Q1413.89 17.7268 1408.38 24.0867 Q1402.87 30.4061 1402.87 42.3968 Q1402.87 54.3469 1408.38 60.7069 Q1413.89 67.0263 1424.26 67.0263 Q1429.53 67.0263 1434.18 65.1223 Q1438.88 63.2184 1443.01 59.3701 L1443.01 67.9175 Q1438.72 70.8341 1433.9 72.2924 Q1429.12 73.7508 1423.77 73.7508 Q1410.04 73.7508 1402.14 65.3654 Q1394.24 56.9395 1394.24 42.3968 Q1394.24 27.8135 1402.14 19.4281 Q1410.04 11.0023 1423.77 11.0023 Q1429.2 11.0023 1433.98 12.4606 Q1438.8 13.8784 1443.01 16.7545 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1455.33 9.54393 L1462.78 9.54393 L1462.78 72.576 L1455.33 72.576 L1455.33 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1477.61 54.671 L1477.61 27.2059 L1485.06 27.2059 L1485.06 54.3874 Q1485.06 60.8284 1487.57 64.0691 Q1490.09 67.2693 1495.11 67.2693 Q1501.15 67.2693 1504.63 63.421 Q1508.15 59.5726 1508.15 52.9291 L1508.15 27.2059 L1515.61 27.2059 L1515.61 72.576 L1508.15 72.576 L1508.15 65.6084 Q1505.44 69.7404 1501.83 71.7658 Q1498.27 73.7508 1493.53 73.7508 Q1485.71 73.7508 1481.66 68.8897 Q1477.61 64.0286 1477.61 54.671 M1496.36 26.1121 L1496.36 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1559.88 28.5427 L1559.88 35.5912 Q1556.72 33.9709 1553.32 33.1607 Q1549.92 32.3505 1546.27 32.3505 Q1540.72 32.3505 1537.93 34.0519 Q1535.17 35.7533 1535.17 39.156 Q1535.17 41.7486 1537.16 43.2475 Q1539.14 44.7058 1545.14 46.0426 L1547.69 46.6097 Q1555.63 48.3111 1558.95 51.4303 Q1562.31 54.509 1562.31 60.0587 Q1562.31 66.3781 1557.29 70.0644 Q1552.31 73.7508 1543.56 73.7508 Q1539.91 73.7508 1535.94 73.0216 Q1532.01 72.3329 1527.64 70.9151 L1527.64 63.2184 Q1531.77 65.3654 1535.78 66.4591 Q1539.79 67.5124 1543.72 67.5124 Q1548.99 67.5124 1551.82 65.73 Q1554.66 63.9071 1554.66 60.6258 Q1554.66 57.5877 1552.59 55.9673 Q1550.57 54.3469 1543.64 52.8481 L1541.05 52.2405 Q1534.12 50.7821 1531.04 47.7845 Q1527.96 44.7463 1527.96 39.4801 Q1527.96 33.0797 1532.5 29.5959 Q1537.04 26.1121 1545.38 26.1121 Q1549.51 26.1121 1553.16 26.7198 Q1556.8 27.3274 1559.88 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1581.56 14.324 L1581.56 27.2059 L1596.91 27.2059 L1596.91 32.9987 L1581.56 32.9987 L1581.56 57.6282 Q1581.56 63.1779 1583.05 64.7578 Q1584.59 66.3376 1589.25 66.3376 L1596.91 66.3376 L1596.91 72.576 L1589.25 72.576 Q1580.62 72.576 1577.34 69.3758 Q1574.06 66.1351 1574.06 57.6282 L1574.06 32.9987 L1568.59 32.9987 L1568.59 27.2059 L1574.06 27.2059 L1574.06 14.324 L1581.56 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1645.52 48.0275 L1645.52 51.6733 L1611.25 51.6733 Q1611.73 59.3701 1615.87 63.421 Q1620.04 67.4314 1627.45 67.4314 Q1631.75 67.4314 1635.76 66.3781 Q1639.81 65.3249 1643.78 63.2184 L1643.78 70.267 Q1639.77 71.9684 1635.55 72.8596 Q1631.34 73.7508 1627.01 73.7508 Q1616.15 73.7508 1609.79 67.4314 Q1603.47 61.1119 1603.47 50.3365 Q1603.47 39.1965 1609.47 32.6746 Q1615.5 26.1121 1625.71 26.1121 Q1634.87 26.1121 1640.17 32.0264 Q1645.52 37.9003 1645.52 48.0275 M1638.07 45.84 Q1637.98 39.7232 1634.62 36.0774 Q1631.3 32.4315 1625.79 32.4315 Q1619.55 32.4315 1615.79 35.9558 Q1612.06 39.4801 1611.49 45.8805 L1638.07 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1684.04 34.1734 Q1682.79 33.4443 1681.29 33.1202 Q1679.83 32.7556 1678.05 32.7556 Q1671.73 32.7556 1668.33 36.8875 Q1664.96 40.9789 1664.96 48.6757 L1664.96 72.576 L1657.47 72.576 L1657.47 27.2059 L1664.96 27.2059 L1664.96 34.2544 Q1667.31 30.1225 1671.08 28.1376 Q1674.85 26.1121 1680.24 26.1121 Q1681.01 26.1121 1681.94 26.2337 Q1682.87 26.3147 1684 26.5172 L1684.04 34.1734 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip970)\" d=\"M1720.79 28.5427 L1720.79 35.5912 Q1717.63 33.9709 1714.22 33.1607 Q1710.82 32.3505 1707.17 32.3505 Q1701.62 32.3505 1698.83 34.0519 Q1696.07 35.7533 1696.07 39.156 Q1696.07 41.7486 1698.06 43.2475 Q1700.04 44.7058 1706.04 46.0426 L1708.59 46.6097 Q1716.53 48.3111 1719.85 51.4303 Q1723.22 54.509 1723.22 60.0587 Q1723.22 66.3781 1718.19 70.0644 Q1713.21 73.7508 1704.46 73.7508 Q1700.81 73.7508 1696.84 73.0216 Q1692.91 72.3329 1688.54 70.9151 L1688.54 63.2184 Q1692.67 65.3654 1696.68 66.4591 Q1700.69 67.5124 1704.62 67.5124 Q1709.89 67.5124 1712.72 65.73 Q1715.56 63.9071 1715.56 60.6258 Q1715.56 57.5877 1713.49 55.9673 Q1711.47 54.3469 1704.54 52.8481 L1701.95 52.2405 Q1695.02 50.7821 1691.94 47.7845 Q1688.86 44.7463 1688.86 39.4801 Q1688.86 33.0797 1693.4 29.5959 Q1697.94 26.1121 1706.28 26.1121 Q1710.41 26.1121 1714.06 26.7198 Q1717.71 27.3274 1720.79 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip972)\" cx=\"2225.63\" cy=\"661.645\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2185.28\" cy=\"814.542\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2315.26\" cy=\"813.697\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2195.37\" cy=\"493.677\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2241.75\" cy=\"798.552\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2083.48\" cy=\"527.112\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2241.75\" cy=\"798.552\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2241.75\" cy=\"798.552\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2346.58\" cy=\"983.118\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2231.44\" cy=\"159.767\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2212.31\" cy=\"488.684\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2151.98\" cy=\"539.274\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2107.67\" cy=\"376.376\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2221.09\" cy=\"735.205\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"2307.49\" cy=\"707.698\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1210.28\" cy=\"778.854\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1270.12\" cy=\"1153.75\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"889.834\" cy=\"1121.84\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1253.82\" cy=\"944.584\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1154.95\" cy=\"1334.46\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"878.7\" cy=\"624.952\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1391.23\" cy=\"870.254\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1335.18\" cy=\"1101.86\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1010.99\" cy=\"1013.54\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1640.91\" cy=\"1117.17\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1055.06\" cy=\"928.981\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"961.713\" cy=\"708.589\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1028.75\" cy=\"762.544\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1018.43\" cy=\"835.952\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1505.66\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"840.561\" cy=\"816.886\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"1157.77\" cy=\"796.374\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"508.284\" cy=\"595.884\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"801.661\" cy=\"613.725\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"792.176\" cy=\"1012.3\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"601.677\" cy=\"677.207\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"812.461\" cy=\"931.127\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"923.947\" cy=\"1045.04\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"614.383\" cy=\"562.297\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"609.21\" cy=\"850.016\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"668.296\" cy=\"725.714\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"850.441\" cy=\"1029.89\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"874.088\" cy=\"1129.45\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"596.997\" cy=\"853.707\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip972)\" cx=\"766.082\" cy=\"626.252\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n</svg>\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"This plot shows that the DDVFA modules do well at identifying the structure of the three clusters despite not achieving 100% test performance.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"\"assets/incremental-batch-cover.png\"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DocTestSetup = quote\n    using AdaptiveResonance, Dates\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"These pages serve as the official documentation for the AdaptiveResonance.jl Julia package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Adaptive Resonance Theory (ART) began as a neurocognitive theory of how fields of cells can continuously learn stable representations, and it has been utilized as the basis for a myriad of practical machine learning algorithms. Pioneered by Stephen Grossberg and Gail Carpenter, the field has had contributions across many years and from many disciplines, resulting in a plethora of engineering applications and theoretical advancements that have enabled ART-based algorithms to compete with many other modern learning and clustering algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The purpose of this package is to provide a home for the development and use of these ART-based machine learning algorithms in the Julia programming language.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See the Index for the complete list of documented functions and types.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation is split into the following sections:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/guide.md\",\n    \"../examples/index.md\",\n    \"man/modules.md\",\n    \"man/contributing.md\",\n    \"man/full-index.md\",\n    \"man/dev-index.md\",\n]\nDepth = 1","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Package Guide provides a tutorial to the full usage of the package, while Examples gives sample workflows using a variety of ART modules. A list of the implemented ART modules is included in Modules, where different options are also listed for creating variants of these modules that exist in the literature.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Instructions on how to contribute to the package are found in Contributing, and docstrings for every element of the package is listed in the Index. Names internal to the package are also listed under the Developer Index.","category":"page"},{"location":"#Documentation-Build","page":"Home","title":"Documentation Build","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation was built using Documenter.jl with the following version and OS:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using AdaptiveResonance, Dates # hide\nprintln(\"AdaptiveResonance v$(ADAPTIVERESONANCE_VERSION) docs built $(Dates.now()) with Julia $(VERSION) on $(Sys.KERNEL)\") # hide","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you make use of this project, please generate your citation with the CITATION.cff file of the repository. Alternatively, you may use the following BibTeX entry for the JOSS paper associated with the repository:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{Petrenko2022,\n  doi = {10.21105/joss.03671},\n  url = {https://doi.org/10.21105/joss.03671},\n  year = {2022},\n  publisher = {The Open Journal},\n  volume = {7},\n  number = {73},\n  pages = {3671},\n  author = {Sasha Petrenko and Donald C. Wunsch},\n  title = {AdaptiveResonance.jl: A Julia Implementation of Adaptive Resonance Theory (ART) Algorithms},\n  journal = {Journal of Open Source Software}\n}","category":"page"}]
}
