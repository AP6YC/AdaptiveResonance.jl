{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All modules in `AdaptiveResonance.jl` are designed to handle incremental and batch training.\n",
    "In fact, ART modules are generally incremental in their implementation, so their batch methods wrap the incremental ones and handle preprocessing, etc.\n",
    "For example, DDVFA can be run incrementally (i.e. with one sample at a time) with custom algorithmic options and a predetermined data configuration."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! note\n",
    "    In the incremental case, it is necessary to provide a data configuration if the model is not pretrained because the model has no knowledge of the boundaries and dimensionality of the data, which are necessary in the complement coding step.\n",
    "    For more info, see the guide in the docs on incremental vs. batch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using AdaptiveResonance # ART\n",
    "using MLDatasets        # Iris dataset\n",
    "using MLDataUtils       # Shuffling and splitting\n",
    "using Printf            # Formatted number printing"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will download the Iris dataset for its small size and benchmark use for clustering algorithms."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], [\"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\"  …  \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\"])"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "Iris.download(i_accept_the_terms_of_use=true)\n",
    "features, labels = Iris.features(), Iris.labels()"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because the MLDatasets package gives us Iris labels as strings, we will use the `MLDataUtils.convertlabel` method with the `MLLabelUtils.LabelEnc.Indices` type to get a list of integers representing each class:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3-element Array{Int64,1}:\n 1\n 2\n 3"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "labels = convertlabel(LabelEnc.Indices{Int}, labels)\n",
    "unique(labels)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will create a train/test split with the `MLDataUtils.stratifiedobs` utility:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(([6.4 5.1 … 6.2 5.7; 2.7 3.8 … 2.8 4.4; 5.3 1.5 … 4.8 1.5; 1.9 0.3 … 1.8 0.4], [3, 1, 2, 1, 1, 3, 1, 1, 2, 3  …  1, 2, 2, 2, 1, 1, 3, 3, 3, 1]), ([5.9 6.1 … 5.0 5.0; 3.0 2.9 … 3.4 3.5; 5.1 4.7 … 1.6 1.3; 1.8 1.4 … 0.4 0.3], [3, 2, 2, 2, 3, 1, 2, 3, 2, 2  …  1, 1, 2, 3, 1, 1, 1, 3, 1, 1]))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Incremental vs. Batch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can create several modules to illustrate training one in batch and one incrementaly."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  method: String \"single\"\n  display: Bool true\n  max_epoch: Int64 1\n  gamma_normalization: Bool true\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  display: Bool false\n  max_epochs: Int64 1\n  gamma_normalization: Bool true\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, 0.0, 0.0)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "# Create several modules for batch and incremental training.\n",
    "# We can take advantage of the options instantiation method here to use the same options for both modules.\n",
    "opts = opts_DDVFA(rho_lb=0.6, rho_ub=0.75)\n",
    "art_batch = DDVFA(opts)\n",
    "art_incremental = DDVFA(opts)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the incremental version, we must setup the data configuration in advance.\n",
    "In batch mode, this is done automatically based upon the provided data, but the incremental variant has not way of knowing the bounds of the individual features.\n",
    "We *could* preprocess the data and set the data configuration with `art.config = DataConfig(0, 1, 4)`, which translates to the data containing four features  that *all* range from 0 to 1.\n",
    "This would be done in scenarios where we have either done some preprocessing on the data or have prior knowledge about the bounds of individual features.\n",
    "However, in this example we will let the module determine the bounds with the convenience method `data_setup!`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4-element Array{Float64,1}:\n 7.9\n 4.4\n 6.9\n 2.5"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "# Setup the data config on all of the features.\n",
    "data_setup!(art_incremental.config, features)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can train in batch with a simple supervised mode by passing the labels as a keyword argument."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Training DDVFA\n",
      "\r0.0%┣                                               ┫ 0/105 [00:00<00:-5, 0s/it]\n",
      "\u001b[1A\rEp: 1, ID: 1, Cat: 0 1.0%┣▏                    ┫ 1/105 [00:00<Inf:Inf, InfGs/it]\n",
      "\u001b[1A\rEp: 1, ID: 105, Cat: 10 100.0%┣████████████████┫ 105/105 [00:00<00:00, 1.8kit/s]\n",
      "Training labels: (105,) Array{Int64,1}\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "y_hat_batch_train = train!(art_batch, X_train, y=y_train)\n",
    "println(\"Training labels: \",  size(y_hat_batch_train), \" \", typeof(y_hat_batch_train))"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also train incrementally with the same method, being careful that we pass a vector features and a single integer as the labels"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Get the number of training samples\n",
    "n_train = length(y_train)\n",
    "# Create a container for the training output labels\n",
    "y_hat_incremental_train = zeros(Int, n_train)\n",
    "# Iterate over all training samples\n",
    "for ix = 1:length(y_train)\n",
    "    sample = X_train[:, ix]\n",
    "    label = y_train[ix]\n",
    "    y_hat_incremental_train[ix] = train!(art_incremental, sample, y=label)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then classify both networks and check that their performances are equivalent.\n",
    "For both, we will use the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Testing DDVFA\n",
      "\r0.0%┣                                                ┫ 0/45 [00:00<00:-2, 0s/it]\n",
      "\u001b[1A\rEp: 1, ID: 1, Cat: 10 2.2%┣▌                    ┫ 1/45 [00:00<Inf:Inf, InfGs/it]\n",
      "\u001b[1A\rEp: 1, ID: 45, Cat: 10 100.0%┣████████████████████┫ 45/45 [00:00<00:00, 827it/s]\n",
      "Batch testing labels: (45,) Array{Int64,1}\n",
      "Incremental testing labels: (45,) Array{Int64,1}\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "# Classify one model in batch mode\n",
    "y_hat_batch = AdaptiveResonance.classify(art_batch, X_test, get_bmu=true)\n",
    "\n",
    "# Classify one model incrementally\n",
    "n_test = length(y_test)\n",
    "y_hat_incremental = zeros(Int, n_test)\n",
    "for ix = 1:n_test\n",
    "    y_hat_incremental[ix] = AdaptiveResonance.classify(art_incremental, X_test[:, ix], get_bmu=true)\n",
    "end\n",
    "\n",
    "# Check the shape and type of the output labels\n",
    "println(\"Batch testing labels: \",  size(y_hat_batch), \" \", typeof(y_hat_batch))\n",
    "println(\"Incremental testing labels: \",  size(y_hat_incremental), \" \", typeof(y_hat_incremental))"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we check the performance (number of correct classifications over total number of test samples) for both models, verifying that they produce the same results."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training performance: 1.0000\n",
      "Incremental training performance: 1.0000\n",
      "Batch testing performance: 0.8667\n",
      "Incremental testing performance: 0.8667\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "# Calculate performance on training data, testing data, and with get_bmu\n",
    "perf_train_batch = performance(y_hat_batch_train, y_train)\n",
    "perf_train_incremental = performance(y_hat_incremental_train, y_train)\n",
    "perf_test_batch = performance(y_hat_batch, y_test)\n",
    "perf_test_incremental = performance(y_hat_incremental, y_test)\n",
    "\n",
    "# Format each performance number for comparison\n",
    "@printf \"Batch training performance: %.4f\\n\" perf_train_batch\n",
    "@printf \"Incremental training performance: %.4f\\n\" perf_train_incremental\n",
    "@printf \"Batch testing performance: %.4f\\n\" perf_test_batch\n",
    "@printf \"Incremental testing performance: %.4f\\n\" perf_test_incremental"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  },
  "kernelspec": {
   "name": "julia-1.4",
   "display_name": "Julia 1.4.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
