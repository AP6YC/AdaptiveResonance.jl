{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In their derivations, ART modules have some special requirements when it comes to their input features.\n",
    "FuzzyART in particular, and subsequently its derivatives, has a requirement that the inputs be bounded and complement coded.\n",
    "This is due to some consequences such as weight decay that occur when using real-valued patterns rather than binary ones (and hence operations like fuzzy membership)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing of the features occurs as follows:\n",
    "1. The features are linearly normalized from 0 to 1 with respect to each feature with `linear_normalization`.\n",
    "   This is done according to some known bounds that each feature has.\n",
    "2. The features are then complement coded, meaning that the feature vector is appended to its 1-complement (i.e., $x \\rightarrow \\left[x, 1-x\\right]$) with `complement_code`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This preprocessing has the ultimate consequence that the input features must be bounded.\n",
    "This many not be a problem in some offline applications with a fixed dataset, but in others where the bounds are not known, techniques such as sigmoidal limiting are often used to place an artificial limit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataConfig"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regardless, this process requires some *a-priori* knowledge about the minimums and maximums that each feature can have, which is stored as a preprocessing configuration.\n",
    "This preprocessing configuration is saved in every ART module as a `DataConfig` object called `config`, which we can see is uninitialized at first:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataConfig(false, Float64[], Float64[], 0, 0)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "# Load the library\n",
    "using AdaptiveResonance\n",
    "\n",
    "# Create a new ART module and inspect its uninitialized data config `config`\n",
    "art = FuzzyART()\n",
    "art.config"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the type of `art.config` is `DataConfig`.\n",
    "We can see what the internal elements of this struct are with `fieldnames`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(:setup, :mins, :maxs, :dim, :dim_comp)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "fieldnames(AdaptiveResonance.DataConfig)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that the dataconfig has a boolean setup flag, minimum and maximum feature vectors, dimensionality of the data, and the complement coded dimensionality (twice the size of the original dimension)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Automatic Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In batch training mode, the minimums and maximums are detected automatically; the minimum and maximum values for every feature are saved and used for the preprocessing step at every subsequent iteration."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "using MLDatasets        # Iris dataset\n",
    "using DataFrames        # DataFrames, necessary for MLDatasets.Iris()\n",
    "using MLDataUtils       # Shuffling and splitting"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will download the Iris dataset for its small size and benchmark use for clustering algorithms."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" … \"Iris-virginica\" \"Iris-virginica\"])"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "# Get the iris dataset\n",
    "iris = Iris(as_df=false)\n",
    "# Manipulate the features and labels into a matrix of features and a vector of labels\n",
    "features, labels = iris.features, iris.targets"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because the MLDatasets package gives us Iris labels as strings, we will use the `MLDataUtils.convertlabel` method with the `MLLabelUtils.LabelEnc.Indices` type to get a list of integers representing each class:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3-element Vector{Int64}:\n 1\n 2\n 3"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\n",
    "unique(labels)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! note\n",
    "    This automatic detection of feature characteristics only occurs if the `config` is not already setup.\n",
    "    If it is setup beforehand, then that config is used instead."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manual Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As mentioned before, we may not always have the luxury of having a representative dataset in advance.\n",
    "Alternatively, we may know the bounds of the features but wish to run incrementally rather than in batch.\n",
    "In these cases, we can setup the config the various `DataConfig` constructors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For example, if the features are all bounded from -1 to 1, we have to also specify the original dimension of the data in `DataConfig(min, max, dim)`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataConfig(true, [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 20, 40)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "# Reinitialize the FuzzyART module\n",
    "art = FuzzyART()\n",
    "# Tell the module that we have 20 features all ranging from -1 to 1\n",
    "art.config = DataConfig(-1, 1, 20)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the features differ in their ranges, we can specify with `DataConfig(mins, maxs)`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DataConfig(true, [-1.0, -2.0, -1.5], [3.0, 2.0, 1.0], 3, 6)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "# Assume some minimum and maximum values for each feature\n",
    "mins = [-1,-2,-1.5]\n",
    "maxs = [3, 2, 1]\n",
    "art.config = DataConfig(mins, maxs)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we don't need to specify the feature dimensionality because it is inferred from the length of the range values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "!!! note\n",
    "    After the first training run, the weights of the network are set to the size of the complement coded dimension.\n",
    "    If you wish to change the dimension of the features, you will need to create a new network."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "kernelspec": {
   "name": "julia-1.8",
   "display_name": "Julia 1.8.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
