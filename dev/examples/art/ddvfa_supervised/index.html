<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Supervised DDVFA Example · AdaptiveResonance.jl</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../../democards/gridtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="AdaptiveResonance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">AdaptiveResonance.jl</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../../getting-started/whatisart/">Background</a></li><li><a class="tocitem" href="../../../getting-started/basic-example/">Basic Example</a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../../man/guide/">Guide</a></li><li><a class="tocitem" href="../../">Examples</a></li><li><a class="tocitem" href="../../../man/modules/">Modules</a></li><li><a class="tocitem" href="../../../man/contributing/">Contributing</a></li><li><a class="tocitem" href="../../../man/full-index/">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Supervised DDVFA Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Supervised DDVFA Example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AP6YC/AdaptiveResonance.jl/blob/master/docs/examples/art/ddvfa_supervised.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ddvfa_supervised"><a class="docs-heading-anchor" href="#ddvfa_supervised">Supervised DDVFA Example</a><a id="ddvfa_supervised-1"></a><a class="docs-heading-anchor-permalink" href="#ddvfa_supervised" title="Permalink"></a></h1><p><a href="../ddvfa_supervised.jl"><img src="https://img.shields.io/badge/download-julia-brightgreen.svg" alt="Source code"/></a> <a href="https://nbviewer.jupyter.org/github/AP6YC/AdaptiveResonance.jl/blob/gh-pages/dev/examples/art/ddvfa_supervised.ipynb"><img src="https://img.shields.io/badge/show-nbviewer-579ACA.svg" alt="notebook"/></a> <img src="https://img.shields.io/badge/julia-1.6.0-blue.svg" alt="compat"/> <a href="https://github.com/AP6YC"><img src="https://img.shields.io/badge/Author-Sasha%20Petrenko-blue" alt="Author"/></a> <img src="https://img.shields.io/date/1638230400" alt="Update time"/></p><p>DDVFA is an unsupervised clustering algorithm by definition, but it can be adaptived for supervised learning by mapping the module&#39;s internal categories to the true labels. ART modules such as DDVFA can also be used in simple supervised mode where provided labels are used in place of internal incremental labels for the clusters, providing a method of assessing the clustering performance when labels are available.</p><p>We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.</p><pre><code class="language-julia hljs">using AdaptiveResonance # ART
using MLDatasets        # Iris dataset
using MLDataUtils       # Shuffling and splitting
using Printf            # Formatted number printing</code></pre><p>We will download the Iris dataset for its small size and benchmark use for clustering algorithms.</p><pre><code class="language-julia hljs">Iris.download(i_accept_the_terms_of_use=true)
features, labels = Iris.features(), Iris.labels()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], [&quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;  …  &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;])</code></pre><p>Because the MLDatasets package gives us Iris labels as strings, we will use the <code>MLDataUtils.convertlabel</code> method with the <code>MLLabelUtils.LabelEnc.Indices</code> type to get a list of integers representing each class:</p><pre><code class="language-julia hljs">labels = convertlabel(LabelEnc.Indices{Int}, labels)
unique(labels)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Array{Int64,1}:
 1
 2
 3</code></pre><p>Next, we will create a train/test split with the <code>MLDataUtils.stratifiedobs</code> utility:</p><pre><code class="language-julia hljs">(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(([6.5 5.1 … 4.8 5.0; 3.0 3.8 … 3.0 3.4; 5.2 1.5 … 1.4 1.6; 2.0 0.3 … 0.3 0.4], [3, 1, 1, 1, 2, 2, 1, 2, 3, 1  …  2, 3, 1, 1, 3, 3, 3, 3, 1, 1]), ([5.3 6.1 … 6.7 6.3; 3.7 2.8 … 3.0 2.9; 1.5 4.0 … 5.2 5.6; 0.2 1.3 … 2.3 1.8], [1, 2, 1, 2, 2, 1, 3, 1, 3, 1  …  3, 2, 3, 2, 2, 1, 3, 1, 3, 3]))</code></pre><p>Now, we can create our DDVFA module. We&#39;ll do so with the default contstructor, though the module itself has many options that you can alter during instantiation.</p><pre><code class="language-julia hljs">art = DDVFA()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DDVFA(opts_DDVFA
  rho_lb: Float64 0.7
  rho_ub: Float64 0.85
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  method: String &quot;single&quot;
  display: Bool true
  max_epoch: Int64 1
  gamma_normalization: Bool true
, opts_FuzzyART
  rho: Float64 0.85
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  display: Bool false
  max_epochs: Int64 1
  gamma_normalization: Bool true
, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, 0.0, 0.0)</code></pre><p>We can train the model in batch mode upon the data in a simple supervised mode. We do so by passing the integer vector of labels to the training method with the simple keyword <code>y</code>. Just as in unsupervised training, we can extract the module&#39;s prescribed labels from the training method, which should match up to the training labels as we will see later.</p><pre><code class="language-julia hljs"># Train in simple supervised mode by passing the labels as a keyword argument.
y_hat_train = train!(art, X_train, y=y_train)
println(&quot;Training labels: &quot;,  size(y_hat_train), &quot; &quot;, typeof(y_hat_train))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Training DDVFA
0.0%┣                                               ┫ 0/105 [00:00&lt;00:-5, 0s/it]
Ep: 1, ID: 1, Cat: 0 1.0%┣▏                    ┫ 1/105 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 105, Cat: 17 100.0%┣████████████████┫ 105/105 [00:00&lt;00:00, 1.7kit/s]
Training labels: (105,) Array{Int64,1}</code></pre><p>We can classify the testing data to see how we generalize. At the same time, we can see the effect of getting the best-matching unit in the case of complete mismatch (see the docs on <a href="../../../man/guide/#mismatch-bmu">Mismatch vs. BMU</a>)</p><pre><code class="language-julia hljs"># Classify both ways
y_hat = AdaptiveResonance.classify(art, X_test)
y_hat_bmu = AdaptiveResonance.classify(art, X_test, get_bmu=true)

# Check the shape and type of the output labels
println(&quot;Testing labels: &quot;,  size(y_hat), &quot; &quot;, typeof(y_hat))
println(&quot;Testing labels with bmu: &quot;,  size(y_hat_bmu), &quot; &quot;, typeof(y_hat_bmu))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Testing DDVFA
0.0%┣                                                ┫ 0/45 [00:00&lt;00:-2, 0s/it]
Ep: 1, ID: 1, Cat: 17 2.2%┣▌                    ┫ 1/45 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 45, Cat: 17 100.0%┣████████████████████┫ 45/45 [00:00&lt;00:00, 777it/s]
[ Info: Testing DDVFA
0.0%┣                                                ┫ 0/45 [00:00&lt;00:-2, 0s/it]
Ep: 1, ID: 1, Cat: 17 2.2%┣▌                    ┫ 1/45 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 45, Cat: 17 100.0%┣████████████████████┫ 45/45 [00:00&lt;00:00, 778it/s]
Testing labels: (45,) Array{Int64,1}
Testing labels with bmu: (45,) Array{Int64,1}</code></pre><p>Finally, we can calculate the performances (number correct over total) of the model upon all three regimes:</p><ol><li>Training data</li><li>Testing data</li><li>Testing data with <code>get_bmu=true</code></li></ol><pre><code class="language-julia hljs"># Calculate performance on training data, testing data, and with get_bmu
perf_train = performance(y_hat_train, y_train)
perf_test = performance(y_hat, y_test)
perf_test_bmu = performance(y_hat_bmu, y_test)

# Format each performance number for comparison
@printf &quot;Training performance: %.4f\n&quot; perf_train
@printf &quot;Testing performance: %.4f\n&quot; perf_test
@printf &quot;Best-matching unit testing performance: %.4f\n&quot; perf_test_bmu</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Training performance: 1.0000
Testing performance: 0.9556
Best-matching unit testing performance: 0.9778</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/johnnychen94/DemoCards.jl">DemoCards.jl</a> and <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Friday 29 April 2022 21:20">Friday 29 April 2022</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
