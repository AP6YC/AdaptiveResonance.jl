{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "DDVFA is an unsupervised clustering algorithm by definition, so it can be used to cluster a set of samples all at once in batch mode."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We begin with importing AdaptiveResonance for the ART modules and MLDatasets for loading some data."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using AdaptiveResonance # ART\n",
    "using MLDatasets        # Iris dataset\n",
    "using DataFrames        # DataFrames, necessary for MLDatasets.Iris()\n",
    "using MLDataUtils       # Shuffling and splitting"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will download the Iris dataset for its small size and benchmark use for clustering algorithms."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4×150 Matrix{Float64}:\n 5.1  4.9  4.7  4.6  5.0  5.4  4.6  5.0  …  6.8  6.7  6.7  6.3  6.5  6.2  5.9\n 3.5  3.0  3.2  3.1  3.6  3.9  3.4  3.4     3.2  3.3  3.0  2.5  3.0  3.4  3.0\n 1.4  1.4  1.3  1.5  1.4  1.7  1.4  1.5     5.9  5.7  5.2  5.0  5.2  5.4  5.1\n 0.2  0.2  0.2  0.2  0.2  0.4  0.3  0.2     2.3  2.5  2.3  1.9  2.0  2.3  1.8"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "# Get the iris dataset\n",
    "iris = Iris(as_df=false)\n",
    "# Extract the features into a local variable\n",
    "features = iris.features"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we will instantiate a DDVFA module.\n",
    "We could create an options struct for reuse with `opts=opts_DDVFA(...)`, but for now we will use the direct keyword arguments approach."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  method: String \"single\"\n  display: Bool true\n  max_epoch: Int64 1\n  gamma_normalization: Bool true\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  display: Bool false\n  max_epochs: Int64 1\n  gamma_normalization: Bool true\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, 0.0, 0.0)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "art = DDVFA(rho_lb=0.6, rho_ub=0.75)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "To train the module on the training data, we use `train!`.\n",
    "The train method returns the prescribed cluster labels, which are just what the algorithm believes are unique/separate cluster.\n",
    "This is because we are doing *unsupervised* learning rather than supervised learning with known labels."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Training DDVFA\n",
      "\r0.0%┣                                              ┫ 0/150 [00:00<00:-8, -0s/it]\n",
      "\u001b[1A\rEp: 1, ID: 1, Cat: 0 0.7%┣▏                    ┫ 1/150 [00:00<Inf:Inf, InfGs/it]\n",
      "\u001b[1A\rEp: 1, ID: 150, Cat: 5 100.0%┣█████████████████┫ 150/150 [00:00<00:00, 2.6kit/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "150-element Vector{Int64}:\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n ⋮\n 5\n 3\n 5\n 5\n 5\n 3\n 3\n 5\n 3"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "y_hat_train = train!(art, features)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Though we could inspect the unique entries in the list above, we can see the number of categories directly from the art module."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "art.n_categories"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because DDVFA actually has FuzzyART modules for F2 nodes, each category has its own category prototypes.\n",
    "We can see the total number of weights in the DDVFA module by summing `n_categories` across all F2 nodes."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "total_vec = [art.F2[i].n_categories for i = 1:art.n_categories]\n",
    "total_cat = sum(total_vec)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "kernelspec": {
   "name": "julia-1.8",
   "display_name": "Julia 1.8.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
