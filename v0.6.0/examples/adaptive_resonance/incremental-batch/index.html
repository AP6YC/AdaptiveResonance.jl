<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Incremental vs. Batch Example · AdaptiveResonance.jl</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../../democards/gridtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="AdaptiveResonance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">AdaptiveResonance.jl</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../../getting-started/whatisart/">Background</a></li><li><a class="tocitem" href="../../../getting-started/basic-example/">Basic Example</a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../../man/guide/">Guide</a></li><li><a class="tocitem" href="../../">Examples</a></li><li><a class="tocitem" href="../../../man/modules/">Modules</a></li><li><a class="tocitem" href="../../../man/contributing/">Contributing</a></li><li><a class="tocitem" href="../../../man/full-index/">Index</a></li><li><a class="tocitem" href="../../../man/dev-index/">Internals</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Incremental vs. Batch Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Incremental vs. Batch Example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AP6YC/AdaptiveResonance.jl/blob/develop/docs/examples/adaptive_resonance/incremental-batch.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="incremental_batch"><a class="docs-heading-anchor" href="#incremental_batch">Incremental vs. Batch Example</a><a id="incremental_batch-1"></a><a class="docs-heading-anchor-permalink" href="#incremental_batch" title="Permalink"></a></h1><p><a href="../incremental-batch.jl"><img src="https://img.shields.io/badge/download-julia-brightgreen.svg" alt="Source code"/></a> <a href="https://nbviewer.jupyter.org/github/AP6YC/AdaptiveResonance.jl/blob/gh-pages/v0.6.0/examples/adaptive_resonance/incremental-batch.ipynb"><img src="https://img.shields.io/badge/show-nbviewer-579ACA.svg" alt="notebook"/></a> <img src="https://img.shields.io/badge/julia-1.8.0-blue.svg" alt="compat"/> <a href="https://github.com/AP6YC"><img src="https://img.shields.io/badge/Author-Sasha%20Petrenko-blue" alt="Author"/></a> <img src="https://img.shields.io/date/1638316800" alt="Update time"/></p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>All modules in <code>AdaptiveResonance.jl</code> are designed to handle incremental and batch training. In fact, ART modules are generally incremental in their implementation, so their batch methods wrap the incremental ones and handle preprocessing, etc. For example, DDVFA can be run incrementally (i.e. with one sample at a time) with custom algorithmic options and a predetermined data configuration.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In the incremental case, it is necessary to provide a data configuration if the model is not pretrained because the model has no knowledge of the boundaries and dimensionality of the data, which are necessary in the complement coding step. For more info, see the guide in the docs on <a href="../../../man/guide/#incremental_vs_batch">incremental vs. batch</a>.</p></div></div><h2 id="Data-Setup"><a class="docs-heading-anchor" href="#Data-Setup">Data Setup</a><a id="Data-Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Setup" title="Permalink"></a></h2><p>We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.</p><pre><code class="language-julia hljs">using AdaptiveResonance # ART
using MLDatasets        # Iris dataset
using DataFrames        # DataFrames, necessary for MLDatasets.Iris()
using MLDataUtils       # Shuffling and splitting
using Printf            # Formatted number printing</code></pre><p>We will download the Iris dataset for its small size and benchmark use for clustering algorithms.</p><pre><code class="language-julia hljs"># Get the iris dataset
iris = Iris(as_df=false)
# Manipulate the features and labels into a matrix of features and a vector of labels
features, labels = iris.features, iris.targets</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], InlineStrings.String15[&quot;Iris-setosa&quot; &quot;Iris-setosa&quot; … &quot;Iris-virginica&quot; &quot;Iris-virginica&quot;])</code></pre><p>Because the MLDatasets package gives us Iris labels as strings, we will use the <code>MLDataUtils.convertlabel</code> method with the <code>MLLabelUtils.LabelEnc.Indices</code> type to get a list of integers representing each class:</p><pre><code class="language-julia hljs">labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))
unique(labels)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Int64}:
 1
 2
 3</code></pre><p>Next, we will create a train/test split with the <code>MLDataUtils.stratifiedobs</code> utility:</p><pre><code class="language-julia hljs">(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(([5.6 7.0 … 6.0 6.0; 2.7 3.2 … 2.9 2.2; 4.2 4.7 … 4.5 4.0; 1.3 1.4 … 1.5 1.0], [2, 2, 3, 1, 3, 3, 3, 1, 2, 2  …  1, 2, 2, 1, 1, 2, 2, 3, 2, 2]), ([4.9 7.7 … 6.3 6.3; 2.4 3.0 … 2.7 2.8; 3.3 6.1 … 4.9 5.1; 1.0 2.3 … 1.8 1.5], [2, 3, 3, 1, 2, 3, 3, 1, 3, 2  …  3, 1, 3, 2, 1, 1, 2, 3, 3, 3]))</code></pre><h2 id="Incremental-vs.-Batch"><a class="docs-heading-anchor" href="#Incremental-vs.-Batch">Incremental vs. Batch</a><a id="Incremental-vs.-Batch-1"></a><a class="docs-heading-anchor-permalink" href="#Incremental-vs.-Batch" title="Permalink"></a></h2><h3 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h3><p>Now, we can create several modules to illustrate training one in batch and one incrementaly.</p><pre><code class="language-julia hljs"># Create several modules for batch and incremental training.
# We can take advantage of the options instantiation method here to use the same options for both modules.
opts = opts_DDVFA(rho_lb=0.6, rho_ub=0.75)
art_batch = DDVFA(opts)
art_incremental = DDVFA(opts)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DDVFA(opts_DDVFA
  rho_lb: Float64 0.6
  rho_ub: Float64 0.75
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  method: String &quot;single&quot;
  max_epoch: Int64 1
  display: Bool true
  gamma_normalization: Bool true
, opts_FuzzyART
  rho: Float64 0.75
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  max_epochs: Int64 1
  display: Bool false
  gamma_normalization: Bool true
, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, 0.0, 0.0)</code></pre><p>For the incremental version, we must setup the data configuration in advance. In batch mode, this is done automatically based upon the provided data, but the incremental variant has not way of knowing the bounds of the individual features. We <em>could</em> preprocess the data and set the data configuration with <code>art.config = DataConfig(0, 1, 4)</code>, which translates to the data containing four features  that <em>all</em> range from 0 to 1. This would be done in scenarios where we have either done some preprocessing on the data or have prior knowledge about the bounds of individual features. However, in this example we will let the module determine the bounds with the convenience method <code>data_setup!</code>:</p><pre><code class="language-julia hljs"># Setup the data config on all of the features.
data_setup!(art_incremental.config, features)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 7.9
 4.4
 6.9
 2.5</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>We can train in batch with a simple supervised mode by passing the labels as a keyword argument.</p><pre><code class="language-julia hljs">y_hat_batch_train = train!(art_batch, X_train, y=y_train)
println(&quot;Training labels: &quot;,  size(y_hat_batch_train), &quot; &quot;, typeof(y_hat_batch_train))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Training DDVFA
0.0%┣                                              ┫ 0/105 [00:00&lt;00:-5, -0s/it]
Ep: 1, ID: 1, Cat: 0 1.0%┣▏                    ┫ 1/105 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 105, Cat: 14 100.0%┣████████████████┫ 105/105 [00:00&lt;00:00, 1.9kit/s]
Training labels: (105,) Vector{Int64}</code></pre><p>We can also train incrementally with the same method, being careful that we pass a vector features and a single integer as the labels</p><pre><code class="language-julia hljs"># Get the number of training samples
n_train = length(y_train)
# Create a container for the training output labels
y_hat_incremental_train = zeros(Int, n_train)
# Iterate over all training samples
for ix in eachindex(y_train)
    sample = X_train[:, ix]
    label = y_train[ix]
    y_hat_incremental_train[ix] = train!(art_incremental, sample, y=label)
end</code></pre><h3 id="Testing"><a class="docs-heading-anchor" href="#Testing">Testing</a><a id="Testing-1"></a><a class="docs-heading-anchor-permalink" href="#Testing" title="Permalink"></a></h3><p>We can then classify both networks and check that their performances are equivalent. For both, we will use the best-matching unit in the case of complete mismatch (see the docs on <a href="../../../man/guide/#mismatch-bmu">Mismatch vs. BMU</a>)</p><pre><code class="language-julia hljs"># Classify one model in batch mode
y_hat_batch = AdaptiveResonance.classify(art_batch, X_test, get_bmu=true)

# Classify one model incrementally
n_test = length(y_test)
y_hat_incremental = zeros(Int, n_test)
for ix = 1:n_test
    y_hat_incremental[ix] = AdaptiveResonance.classify(art_incremental, X_test[:, ix], get_bmu=true)
end

# Check the shape and type of the output labels
println(&quot;Batch testing labels: &quot;,  size(y_hat_batch), &quot; &quot;, typeof(y_hat_batch))
println(&quot;Incremental testing labels: &quot;,  size(y_hat_incremental), &quot; &quot;, typeof(y_hat_incremental))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Testing DDVFA
0.0%┣                                               ┫ 0/45 [00:00&lt;00:-2, -0s/it]
Ep: 1, ID: 1, Cat: 14 2.2%┣▌                    ┫ 1/45 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 45, Cat: 14 100.0%┣████████████████████┫ 45/45 [00:00&lt;00:00, 843it/s]
Batch testing labels: (45,) Vector{Int64}
Incremental testing labels: (45,) Vector{Int64}</code></pre><p>Finally, we check the performance (number of correct classifications over total number of test samples) for both models, verifying that they produce the same results.</p><pre><code class="language-julia hljs"># Calculate performance on training data, testing data, and with get_bmu
perf_train_batch = performance(y_hat_batch_train, y_train)
perf_train_incremental = performance(y_hat_incremental_train, y_train)
perf_test_batch = performance(y_hat_batch, y_test)
perf_test_incremental = performance(y_hat_incremental, y_test)

# Format each performance number for comparison
@printf &quot;Batch training performance: %.4f\n&quot; perf_train_batch
@printf &quot;Incremental training performance: %.4f\n&quot; perf_train_incremental
@printf &quot;Batch testing performance: %.4f\n&quot; perf_test_batch
@printf &quot;Incremental testing performance: %.4f\n&quot; perf_test_incremental</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Batch training performance: 1.0000
Incremental training performance: 1.0000
Batch testing performance: 0.9778
Incremental testing performance: 0.9778</code></pre><h2 id="Visualization"><a class="docs-heading-anchor" href="#Visualization">Visualization</a><a id="Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization" title="Permalink"></a></h2><p>So we showed that the performance and behavior of modules are identical in incremental and batch modes. Great! Sadly, illustrating this point doesn&#39;t lend itself to visualization in any meaningful way. Nonetheless, we would like a pretty picture at the end of the experiment to verify that these identical solutions work in the first place. Sanity checks are meaningful in their own right, right?</p><p>To do this, we will reduce the dimensionality of the dataset to two dimensions and show in a scatter plot how the modules classify the test data into groups. This will be done with principal component analysis (PCA) to cast the points into a 2-D space while trying to preserve the relative distances between points in the higher dimension. The process isn&#39;t perfect by any means, but it suffices for visualization.</p><pre><code class="language-julia hljs"># Import visualization utilities
using Printf            # Formatted number printing
using MultivariateStats # Principal component analysis (PCA)
using Plots             # Plotting frontend
gr()                    # Use the default GR backend explicitly

# Train a PCA model
M = fit(PCA, features; maxoutdim=2)

# Apply the PCA model to the testing set
X_test_pca = MultivariateStats.transform(M, X_test)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×45 Matrix{Float64}:
  0.751467  -3.07652   -1.94402   …  -2.93201   -1.38767   -1.4431
 -1.00111    0.685764   0.187415      0.352377  -0.204031  -0.143801</code></pre><p>Now that we have the test points cast into a 2-D set of points, we can create a scatter plot that shows how each point is categorized by the modules.</p><pre><code class="language-julia hljs"># Create a scatterplot object from the data with some additional formatting options
scatter(
    X_test_pca[1, :],       # PCA dimension 1
    X_test_pca[2, :],       # PCA dimension 2
    group = y_hat_batch,    # labels belonging to each point
    markersize = 8,         # size of scatter points
    legend = false,         # no legend
    xtickfontsize = 12,     # x-tick size
    ytickfontsize = 12,     # y-tick size
    dpi = 300,              # Set the dots-per-inch
    xlims = :round,         # Round up the x-limits to the nearest whole number
    xlabel = &quot;\$PCA_1\$&quot;,   # x-label
    ylabel = &quot;\$PCA_2\$&quot;,   # y-label
    title = (@sprintf &quot;DDVFA Iris Clusters&quot;),   # formatted title
)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip870">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip870)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip871">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<defs>
  <clipPath id="clip872">
    <rect x="1346" y="99" width="1008" height="1363"/>
  </clipPath>
</defs>
<path clip-path="url(#clip870)" d="
M146.102 1461.9 L2352.76 1461.9 L2352.76 62.9921 L146.102 62.9921  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip873">
    <rect x="146" y="62" width="2208" height="1400"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,1461.9 146.102,62.9921 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  697.765,1461.9 697.765,62.9921 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1249.43,1461.9 1249.43,62.9921 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1801.09,1461.9 1801.09,62.9921 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2352.76,1461.9 2352.76,62.9921 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 2352.76,1461.9 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 146.102,1443 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  697.765,1461.9 697.765,1443 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1249.43,1461.9 1249.43,1443 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1801.09,1461.9 1801.09,1443 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2352.76,1461.9 2352.76,1443 
  "/>
<path clip-path="url(#clip870)" d="M99.4526 1520.66 L143.966 1520.66 L143.966 1526.56 L99.4526 1526.56 L99.4526 1520.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M178.376 1500.17 L160.668 1527.84 L178.376 1527.84 L178.376 1500.17 M176.535 1494.06 L185.355 1494.06 L185.355 1527.84 L192.751 1527.84 L192.751 1533.68 L185.355 1533.68 L185.355 1545.9 L178.376 1545.9 L178.376 1533.68 L154.973 1533.68 L154.973 1526.91 L176.535 1494.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M652.679 1520.66 L697.192 1520.66 L697.192 1526.56 L652.679 1526.56 L652.679 1520.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M718.373 1540 L742.852 1540 L742.852 1545.9 L709.935 1545.9 L709.935 1540 Q713.928 1535.86 720.803 1528.92 Q727.713 1521.94 729.484 1519.93 Q732.852 1516.14 734.171 1513.54 Q735.525 1510.9 735.525 1508.36 Q735.525 1504.23 732.609 1501.63 Q729.727 1499.02 725.074 1499.02 Q721.775 1499.02 718.095 1500.17 Q714.449 1501.32 710.282 1503.64 L710.282 1496.56 Q714.519 1494.86 718.199 1493.99 Q721.88 1493.12 724.935 1493.12 Q732.991 1493.12 737.782 1497.15 Q742.574 1501.18 742.574 1507.91 Q742.574 1511.11 741.359 1513.99 Q740.178 1516.84 737.018 1520.72 Q736.15 1521.73 731.498 1526.56 Q726.845 1531.35 718.373 1540 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1249.43 1498.68 Q1244.01 1498.68 1241.27 1504.02 Q1238.56 1509.34 1238.56 1520.03 Q1238.56 1530.69 1241.27 1536.04 Q1244.01 1541.35 1249.43 1541.35 Q1254.88 1541.35 1257.59 1536.04 Q1260.33 1530.69 1260.33 1520.03 Q1260.33 1509.34 1257.59 1504.02 Q1254.88 1498.68 1249.43 1498.68 M1249.43 1493.12 Q1258.14 1493.12 1262.73 1500.03 Q1267.35 1506.91 1267.35 1520.03 Q1267.35 1533.12 1262.73 1540.03 Q1258.14 1546.91 1249.43 1546.91 Q1240.71 1546.91 1236.1 1540.03 Q1231.51 1533.12 1231.51 1520.03 Q1231.51 1506.91 1236.1 1500.03 Q1240.71 1493.12 1249.43 1493.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1793.07 1540 L1817.55 1540 L1817.55 1545.9 L1784.63 1545.9 L1784.63 1540 Q1788.63 1535.86 1795.5 1528.92 Q1802.41 1521.94 1804.18 1519.93 Q1807.55 1516.14 1808.87 1513.54 Q1810.22 1510.9 1810.22 1508.36 Q1810.22 1504.23 1807.31 1501.63 Q1804.43 1499.02 1799.77 1499.02 Q1796.47 1499.02 1792.79 1500.17 Q1789.15 1501.32 1784.98 1503.64 L1784.98 1496.56 Q1789.22 1494.86 1792.9 1493.99 Q1796.58 1493.12 1799.63 1493.12 Q1807.69 1493.12 1812.48 1497.15 Q1817.27 1501.18 1817.27 1507.91 Q1817.27 1511.11 1816.06 1513.99 Q1814.88 1516.84 1811.72 1520.72 Q1810.85 1521.73 1806.2 1526.56 Q1801.54 1531.35 1793.07 1540 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M2357.27 1500.17 L2339.56 1527.84 L2357.27 1527.84 L2357.27 1500.17 M2355.43 1494.06 L2364.25 1494.06 L2364.25 1527.84 L2371.64 1527.84 L2371.64 1533.68 L2364.25 1533.68 L2364.25 1545.9 L2357.27 1545.9 L2357.27 1533.68 L2333.87 1533.68 L2333.87 1526.91 L2355.43 1494.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1210.86 1583.31 Q1210.86 1586.92 1208.18 1590.23 Q1205.54 1593.55 1201.23 1595.58 Q1196.94 1597.58 1192.34 1597.58 L1181.13 1597.58 L1177.04 1614.07 Q1177.01 1614.16 1176.91 1614.58 Q1176.82 1614.97 1176.82 1615.19 Q1176.82 1616 1177.81 1616.19 Q1178.84 1616.39 1181.13 1616.39 Q1182.61 1616.39 1182.84 1616.64 Q1182.97 1616.8 1182.97 1617.09 Q1182.97 1617.55 1182.84 1617.87 Q1182.71 1618.16 1182.45 1618.25 Q1182.23 1618.35 1182.07 1618.38 Q1181.9 1618.41 1181.65 1618.41 Q1180.97 1618.41 1179.52 1618.35 Q1178.1 1618.29 1177.36 1618.29 L1173.14 1618.22 L1164.77 1618.41 Q1163.77 1618.41 1163.77 1617.61 Q1163.77 1617 1164.03 1616.74 Q1164.29 1616.45 1164.58 1616.42 Q1164.87 1616.39 1165.61 1616.39 Q1167.22 1616.39 1168.18 1616.29 Q1169.15 1616.19 1169.76 1616.06 Q1170.41 1615.9 1170.73 1615.45 Q1171.08 1615 1171.24 1614.61 Q1171.41 1614.2 1171.63 1613.26 L1180.46 1577.84 Q1180.71 1576.77 1180.71 1576.61 Q1180.71 1576.06 1180.39 1575.87 Q1180.1 1575.65 1179.26 1575.55 Q1177.65 1575.42 1176.43 1575.42 Q1175.62 1575.42 1175.3 1575.39 Q1175.01 1575.36 1174.75 1575.19 Q1174.53 1575 1174.53 1574.61 Q1174.53 1574 1174.79 1573.75 Q1175.08 1573.46 1175.4 1573.42 Q1175.72 1573.36 1176.49 1573.36 L1197.88 1573.36 Q1204.03 1573.36 1207.44 1576.29 Q1210.86 1579.22 1210.86 1583.31 M1204.74 1581.73 Q1204.74 1575.42 1195.75 1575.42 L1189.44 1575.42 Q1187.35 1575.42 1186.83 1575.81 Q1186.32 1576.16 1185.87 1577.93 L1181.39 1595.87 L1190.7 1595.87 Q1196.94 1595.87 1200.84 1592.36 Q1202.61 1590.75 1203.68 1587.4 Q1204.74 1584.05 1204.74 1581.73 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1261.23 1572.59 L1257.07 1589.4 Q1256.78 1590.46 1256.59 1590.59 Q1256.43 1590.72 1255.91 1590.72 Q1254.91 1590.72 1254.91 1590.04 Q1254.91 1589.98 1255.01 1589.14 Q1255.11 1588.27 1255.11 1586.69 Q1255.11 1580.86 1252.27 1577.42 Q1249.47 1573.97 1244.48 1573.97 Q1240.16 1573.97 1235.82 1576.16 Q1231.5 1578.35 1228.41 1581.93 Q1226.09 1584.63 1224.38 1588.04 Q1222.71 1591.46 1221.9 1594.58 Q1221.13 1597.71 1220.78 1600.06 Q1220.42 1602.41 1220.42 1604.12 Q1220.42 1606.6 1220.94 1608.69 Q1221.48 1610.78 1222.45 1612.26 Q1223.42 1613.71 1224.64 1614.84 Q1225.9 1615.94 1227.35 1616.58 Q1228.83 1617.22 1230.31 1617.55 Q1231.79 1617.84 1233.34 1617.84 Q1239.55 1617.84 1245.48 1613 Q1250.18 1609.04 1252.14 1602.57 Q1252.31 1601.93 1252.98 1601.93 Q1253.79 1601.93 1253.79 1602.57 Q1253.79 1602.7 1253.63 1603.34 Q1253.46 1603.95 1252.98 1605.21 Q1252.5 1606.43 1251.76 1607.82 Q1251.02 1609.2 1249.63 1610.94 Q1248.25 1612.68 1246.54 1614.2 Q1243.64 1616.71 1239.97 1618.29 Q1236.3 1619.86 1232.27 1619.86 Q1227.25 1619.86 1223.19 1617.64 Q1219.13 1615.42 1216.75 1611.27 Q1214.4 1607.11 1214.4 1601.8 Q1214.4 1596.19 1216.98 1590.69 Q1219.55 1585.18 1223.64 1581.09 Q1227.73 1577 1233.14 1574.45 Q1238.55 1571.91 1243.96 1571.91 Q1246.03 1571.91 1247.86 1572.46 Q1249.7 1573 1250.79 1573.68 Q1251.92 1574.36 1252.92 1575.36 Q1253.92 1576.32 1254.24 1576.77 Q1254.59 1577.22 1254.91 1577.77 L1259.52 1572.71 Q1260.32 1571.91 1260.52 1571.91 Q1260.9 1571.91 1261.07 1572.14 Q1261.23 1572.36 1261.23 1572.59 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1306.35 1617.09 Q1306.35 1617.71 1306.09 1618.03 Q1305.86 1618.32 1305.64 1618.38 Q1305.45 1618.41 1305.16 1618.41 Q1304.32 1618.41 1301.42 1618.32 Q1298.52 1618.22 1297.68 1618.22 Q1296.33 1618.22 1293.56 1618.32 Q1290.79 1618.41 1289.44 1618.41 Q1288.54 1618.41 1288.54 1617.67 Q1288.54 1617.19 1288.63 1616.93 Q1288.73 1616.64 1288.99 1616.55 Q1289.28 1616.42 1289.44 1616.42 Q1289.63 1616.39 1290.12 1616.39 Q1290.76 1616.39 1291.44 1616.32 Q1292.11 1616.22 1292.95 1616.03 Q1293.79 1615.84 1294.3 1615.36 Q1294.85 1614.87 1294.85 1614.2 Q1294.85 1613.91 1294.62 1611.52 Q1294.4 1609.14 1294.11 1606.37 Q1293.82 1603.57 1293.79 1603.18 L1277.23 1603.18 Q1275.72 1605.79 1274.66 1607.59 Q1273.59 1609.4 1273.21 1610.01 Q1272.82 1610.62 1272.6 1611.01 Q1272.37 1611.39 1272.24 1611.62 Q1271.31 1613.33 1271.31 1614.07 Q1271.31 1616.13 1274.4 1616.39 Q1275.46 1616.39 1275.46 1617.16 Q1275.46 1617.74 1275.2 1618.06 Q1274.95 1618.35 1274.72 1618.38 Q1274.53 1618.41 1274.21 1618.41 Q1273.14 1618.41 1270.92 1618.32 Q1268.7 1618.22 1267.6 1618.22 Q1266.67 1618.22 1264.74 1618.32 Q1262.81 1618.41 1261.94 1618.41 Q1261.55 1618.41 1261.32 1618.19 Q1261.1 1617.96 1261.1 1617.67 Q1261.1 1617.22 1261.16 1616.97 Q1261.26 1616.71 1261.52 1616.58 Q1261.77 1616.45 1261.9 1616.45 Q1262.03 1616.42 1262.48 1616.39 Q1264.93 1616.22 1266.83 1615.07 Q1268.76 1613.87 1270.6 1610.81 L1293.53 1572.3 Q1293.76 1571.91 1293.92 1571.72 Q1294.08 1571.52 1294.4 1571.36 Q1294.75 1571.2 1295.27 1571.2 Q1296.07 1571.2 1296.24 1571.46 Q1296.4 1571.68 1296.49 1572.78 L1300.52 1614 Q1300.62 1614.87 1300.68 1615.23 Q1300.78 1615.55 1301.19 1615.9 Q1301.65 1616.22 1302.45 1616.32 Q1303.29 1616.39 1304.83 1616.39 Q1305.41 1616.39 1305.64 1616.42 Q1305.86 1616.42 1306.09 1616.58 Q1306.35 1616.74 1306.35 1617.09 M1293.59 1601.12 L1291.5 1579.38 L1278.49 1601.12 L1293.59 1601.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1312.95 1610.34 L1312.95 1608.89 Q1318.5 1608.89 1321.36 1605.94 Q1322.15 1605.94 1322.28 1606.12 Q1322.42 1606.3 1322.42 1607.14 L1322.42 1633.04 Q1322.42 1634.41 1323.1 1634.84 Q1323.77 1635.27 1326.73 1635.27 L1328.19 1635.27 L1328.19 1636.69 Q1326.57 1636.56 1320.71 1636.56 Q1314.84 1636.56 1313.24 1636.69 L1313.24 1635.27 L1314.71 1635.27 Q1317.62 1635.27 1318.32 1634.87 Q1319.02 1634.44 1319.02 1633.04 L1319.02 1609.12 Q1316.6 1610.34 1312.95 1610.34 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,1421.64 2352.76,1421.64 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,1119.96 2352.76,1119.96 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,818.282 2352.76,818.282 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,516.604 2352.76,516.604 
  "/>
<polyline clip-path="url(#clip873)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,214.926 2352.76,214.926 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 146.102,62.9921 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1421.64 164.999,1421.64 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1119.96 164.999,1119.96 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,818.282 164.999,818.282 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,516.604 164.999,516.604 
  "/>
<polyline clip-path="url(#clip870)" style="stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,214.926 164.999,214.926 
  "/>
<path clip-path="url(#clip870)" d="M-50.3142 1422.32 L-5.80054 1422.32 L-5.80054 1428.22 L-50.3142 1428.22 L-50.3142 1422.32 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M10.5535 1441.66 L22.0118 1441.66 L22.0118 1402.11 L9.5466 1404.61 L9.5466 1398.22 L21.9424 1395.72 L28.9562 1395.72 L28.9562 1441.66 L40.4145 1441.66 L40.4145 1447.56 L10.5535 1447.56 L10.5535 1441.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M54.5811 1438.74 L61.9074 1438.74 L61.9074 1447.56 L54.5811 1447.56 L54.5811 1438.74 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M92.185 1400.34 Q86.7684 1400.34 84.0254 1405.68 Q81.317 1411 81.317 1421.69 Q81.317 1432.35 84.0254 1437.7 Q86.7684 1443.01 92.185 1443.01 Q97.6364 1443.01 100.345 1437.7 Q103.088 1432.35 103.088 1421.69 Q103.088 1411 100.345 1405.68 Q97.6364 1400.34 92.185 1400.34 M92.185 1394.78 Q100.9 1394.78 105.484 1401.69 Q110.102 1408.57 110.102 1421.69 Q110.102 1434.78 105.484 1441.69 Q100.9 1448.57 92.185 1448.57 Q83.4698 1448.57 78.8518 1441.69 Q74.2685 1434.78 74.2685 1421.69 Q74.2685 1408.57 78.8518 1401.69 Q83.4698 1394.78 92.185 1394.78 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M-48.8211 1120.64 L-4.30749 1120.64 L-4.30749 1126.54 L-48.8211 1126.54 L-48.8211 1120.64 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M25.8312 1098.66 Q20.4146 1098.66 17.6716 1104.01 Q14.9632 1109.32 14.9632 1120.01 Q14.9632 1130.67 17.6716 1136.02 Q20.4146 1141.33 25.8312 1141.33 Q31.2826 1141.33 33.9909 1136.02 Q36.734 1130.67 36.734 1120.01 Q36.734 1109.32 33.9909 1104.01 Q31.2826 1098.66 25.8312 1098.66 M25.8312 1093.1 Q34.5465 1093.1 39.1298 1100.01 Q43.7478 1106.89 43.7478 1120.01 Q43.7478 1133.1 39.1298 1140.01 Q34.5465 1146.89 25.8312 1146.89 Q17.116 1146.89 12.498 1140.01 Q7.91466 1133.1 7.91466 1120.01 Q7.91466 1106.89 12.498 1100.01 Q17.116 1093.1 25.8312 1093.1 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M56.0741 1137.06 L63.4005 1137.06 L63.4005 1145.88 L56.0741 1145.88 L56.0741 1137.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M78.7476 1094.04 L106.282 1094.04 L106.282 1099.94 L85.1712 1099.94 L85.1712 1112.65 Q86.699 1112.13 88.2267 1111.89 Q89.7545 1111.61 91.2823 1111.61 Q99.9628 1111.61 105.032 1116.37 Q110.102 1121.12 110.102 1129.25 Q110.102 1137.62 104.893 1142.27 Q99.685 1146.89 90.2059 1146.89 Q86.942 1146.89 83.5393 1146.33 Q80.1712 1145.78 76.5601 1144.67 L76.5601 1137.62 Q79.6851 1139.32 83.0184 1140.15 Q86.3517 1140.98 90.067 1140.98 Q96.0739 1140.98 99.5808 1137.82 Q103.088 1134.67 103.088 1129.25 Q103.088 1123.83 99.5808 1120.67 Q96.0739 1117.51 90.067 1117.51 Q87.2545 1117.51 84.442 1118.14 Q81.6643 1118.76 78.7476 1120.08 L78.7476 1094.04 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M24.3382 796.98 Q18.9215 796.98 16.1785 802.327 Q13.4702 807.64 13.4702 818.334 Q13.4702 828.994 16.1785 834.341 Q18.9215 839.653 24.3382 839.653 Q29.7895 839.653 32.4979 834.341 Q35.2409 828.994 35.2409 818.334 Q35.2409 807.64 32.4979 802.327 Q29.7895 796.98 24.3382 796.98 M24.3382 791.425 Q33.0534 791.425 37.6367 798.334 Q42.2548 805.209 42.2548 818.334 Q42.2548 831.424 37.6367 838.334 Q33.0534 845.209 24.3382 845.209 Q15.623 845.209 11.0049 838.334 Q6.42162 831.424 6.42162 818.334 Q6.42162 805.209 11.0049 798.334 Q15.623 791.425 24.3382 791.425 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M54.5811 835.383 L61.9074 835.383 L61.9074 844.202 L54.5811 844.202 L54.5811 835.383 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M92.185 796.98 Q86.7684 796.98 84.0254 802.327 Q81.317 807.64 81.317 818.334 Q81.317 828.994 84.0254 834.341 Q86.7684 839.653 92.185 839.653 Q97.6364 839.653 100.345 834.341 Q103.088 828.994 103.088 818.334 Q103.088 807.64 100.345 802.327 Q97.6364 796.98 92.185 796.98 M92.185 791.425 Q100.9 791.425 105.484 798.334 Q110.102 805.209 110.102 818.334 Q110.102 831.424 105.484 838.334 Q100.9 845.209 92.185 845.209 Q83.4698 845.209 78.8518 838.334 Q74.2685 831.424 74.2685 818.334 Q74.2685 805.209 78.8518 798.334 Q83.4698 791.425 92.185 791.425 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M25.8312 495.302 Q20.4146 495.302 17.6716 500.649 Q14.9632 505.962 14.9632 516.656 Q14.9632 527.316 17.6716 532.663 Q20.4146 537.975 25.8312 537.975 Q31.2826 537.975 33.9909 532.663 Q36.734 527.316 36.734 516.656 Q36.734 505.962 33.9909 500.649 Q31.2826 495.302 25.8312 495.302 M25.8312 489.746 Q34.5465 489.746 39.1298 496.656 Q43.7478 503.531 43.7478 516.656 Q43.7478 529.746 39.1298 536.656 Q34.5465 543.531 25.8312 543.531 Q17.116 543.531 12.498 536.656 Q7.91466 529.746 7.91466 516.656 Q7.91466 503.531 12.498 496.656 Q17.116 489.746 25.8312 489.746 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M56.0741 533.704 L63.4005 533.704 L63.4005 542.524 L56.0741 542.524 L56.0741 533.704 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M78.7476 490.684 L106.282 490.684 L106.282 496.587 L85.1712 496.587 L85.1712 509.295 Q86.699 508.774 88.2267 508.531 Q89.7545 508.253 91.2823 508.253 Q99.9628 508.253 105.032 513.01 Q110.102 517.767 110.102 525.892 Q110.102 534.26 104.893 538.913 Q99.685 543.531 90.2059 543.531 Q86.942 543.531 83.5393 542.975 Q80.1712 542.42 76.5601 541.309 L76.5601 534.26 Q79.6851 535.961 83.0184 536.795 Q86.3517 537.628 90.067 537.628 Q96.0739 537.628 99.5808 534.468 Q103.088 531.309 103.088 525.892 Q103.088 520.475 99.5808 517.316 Q96.0739 514.156 90.067 514.156 Q87.2545 514.156 84.442 514.781 Q81.6643 515.406 78.7476 516.725 L78.7476 490.684 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M10.5535 234.943 L22.0118 234.943 L22.0118 195.395 L9.5466 197.895 L9.5466 191.506 L21.9424 189.006 L28.9562 189.006 L28.9562 234.943 L40.4145 234.943 L40.4145 240.846 L10.5535 240.846 L10.5535 234.943 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M54.5811 232.026 L61.9074 232.026 L61.9074 240.846 L54.5811 240.846 L54.5811 232.026 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M92.185 193.624 Q86.7684 193.624 84.0254 198.971 Q81.317 204.283 81.317 214.978 Q81.317 225.637 84.0254 230.985 Q86.7684 236.297 92.185 236.297 Q97.6364 236.297 100.345 230.985 Q103.088 225.637 103.088 214.978 Q103.088 204.283 100.345 198.971 Q97.6364 193.624 92.185 193.624 M92.185 188.068 Q100.9 188.068 105.484 194.978 Q110.102 201.853 110.102 214.978 Q110.102 228.068 105.484 234.978 Q100.9 241.853 92.185 241.853 Q83.4698 241.853 78.8518 234.978 Q74.2685 228.068 74.2685 214.978 Q74.2685 201.853 78.8518 194.978 Q83.4698 188.068 92.185 188.068 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M-135.686 802.597 Q-132.079 802.597 -128.762 805.27 Q-125.445 807.911 -123.416 812.226 Q-121.419 816.51 -121.419 821.115 L-121.419 832.323 L-104.929 836.413 Q-104.833 836.445 -104.414 836.542 Q-104.028 836.638 -103.802 836.638 Q-102.997 836.638 -102.804 835.64 Q-102.611 834.61 -102.611 832.323 Q-102.611 830.841 -102.353 830.616 Q-102.192 830.487 -101.902 830.487 Q-101.451 830.487 -101.129 830.616 Q-100.839 830.745 -100.743 831.002 Q-100.646 831.228 -100.614 831.389 Q-100.582 831.55 -100.582 831.808 Q-100.582 832.484 -100.646 833.933 Q-100.71 835.35 -100.71 836.091 L-100.775 840.31 L-100.582 848.683 Q-100.582 849.682 -101.387 849.682 Q-101.999 849.682 -102.256 849.424 Q-102.546 849.167 -102.578 848.877 Q-102.611 848.587 -102.611 847.846 Q-102.611 846.236 -102.707 845.27 Q-102.804 844.303 -102.933 843.692 Q-103.094 843.047 -103.545 842.725 Q-103.995 842.371 -104.382 842.21 Q-104.801 842.049 -105.735 841.824 L-141.161 832.999 Q-142.224 832.742 -142.385 832.742 Q-142.932 832.742 -143.126 833.064 Q-143.351 833.353 -143.448 834.191 Q-143.576 835.801 -143.576 837.025 Q-143.576 837.83 -143.609 838.152 Q-143.641 838.442 -143.802 838.7 Q-143.995 838.925 -144.382 838.925 Q-144.994 838.925 -145.251 838.667 Q-145.541 838.378 -145.573 838.056 Q-145.638 837.733 -145.638 836.961 L-145.638 815.576 Q-145.638 809.425 -142.707 806.011 Q-139.776 802.597 -135.686 802.597 M-137.264 808.716 Q-143.576 808.716 -143.576 817.701 L-143.576 824.014 Q-143.576 826.107 -143.19 826.622 Q-142.836 827.138 -141.064 827.589 L-123.126 832.065 L-123.126 822.758 Q-123.126 816.51 -126.636 812.613 Q-128.246 810.842 -131.596 809.779 Q-134.945 808.716 -137.264 808.716 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M-146.411 752.228 L-129.599 756.382 Q-128.536 756.672 -128.408 756.866 Q-128.279 757.027 -128.279 757.542 Q-128.279 758.54 -128.955 758.54 Q-129.019 758.54 -129.857 758.444 Q-130.726 758.347 -132.304 758.347 Q-138.134 758.347 -141.58 761.181 Q-145.026 763.983 -145.026 768.975 Q-145.026 773.291 -142.836 777.638 Q-140.646 781.954 -137.071 785.046 Q-134.366 787.365 -130.952 789.071 Q-127.538 790.746 -124.414 791.551 Q-121.29 792.324 -118.939 792.678 Q-116.588 793.033 -114.881 793.033 Q-112.401 793.033 -110.308 792.517 Q-108.214 791.97 -106.733 791.004 Q-105.284 790.038 -104.157 788.814 Q-103.062 787.558 -102.417 786.108 Q-101.773 784.627 -101.451 783.146 Q-101.161 781.664 -101.161 780.118 Q-101.161 773.902 -105.992 767.977 Q-109.954 763.275 -116.427 761.31 Q-117.071 761.149 -117.071 760.473 Q-117.071 759.667 -116.427 759.667 Q-116.298 759.667 -115.654 759.828 Q-115.042 759.99 -113.786 760.473 Q-112.562 760.956 -111.177 761.696 Q-109.793 762.437 -108.053 763.822 Q-106.314 765.207 -104.801 766.914 Q-102.289 769.812 -100.71 773.484 Q-99.1324 777.155 -99.1324 781.181 Q-99.1324 786.205 -101.355 790.263 Q-103.577 794.321 -107.731 796.704 Q-111.886 799.055 -117.2 799.055 Q-122.804 799.055 -128.311 796.479 Q-133.818 793.902 -137.908 789.812 Q-141.998 785.722 -144.543 780.311 Q-147.087 774.901 -147.087 769.49 Q-147.087 767.429 -146.539 765.593 Q-145.992 763.758 -145.316 762.663 Q-144.639 761.535 -143.641 760.537 Q-142.675 759.539 -142.224 759.217 Q-141.773 758.862 -141.225 758.54 L-146.282 753.935 Q-147.087 753.13 -147.087 752.936 Q-147.087 752.55 -146.861 752.389 Q-146.636 752.228 -146.411 752.228 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M-101.902 707.107 Q-101.29 707.107 -100.968 707.364 Q-100.678 707.59 -100.614 707.815 Q-100.582 708.008 -100.582 708.298 Q-100.582 709.136 -100.678 712.034 Q-100.775 714.933 -100.775 715.77 Q-100.775 717.123 -100.678 719.892 Q-100.582 722.662 -100.582 724.015 Q-100.582 724.916 -101.322 724.916 Q-101.805 724.916 -102.063 724.82 Q-102.353 724.723 -102.45 724.466 Q-102.578 724.176 -102.578 724.015 Q-102.611 723.821 -102.611 723.338 Q-102.611 722.694 -102.675 722.018 Q-102.772 721.342 -102.965 720.504 Q-103.158 719.667 -103.641 719.152 Q-104.124 718.604 -104.801 718.604 Q-105.09 718.604 -107.474 718.83 Q-109.857 719.055 -112.627 719.345 Q-115.429 719.635 -115.815 719.667 L-115.815 736.221 Q-113.206 737.734 -111.403 738.797 Q-109.599 739.86 -108.987 740.246 Q-108.375 740.633 -107.989 740.858 Q-107.603 741.084 -107.377 741.213 Q-105.67 742.147 -104.929 742.147 Q-102.868 742.147 -102.611 739.055 Q-102.611 737.992 -101.838 737.992 Q-101.258 737.992 -100.936 738.25 Q-100.646 738.507 -100.614 738.733 Q-100.582 738.926 -100.582 739.248 Q-100.582 740.311 -100.678 742.533 Q-100.775 744.755 -100.775 745.85 Q-100.775 746.784 -100.678 748.717 Q-100.582 750.649 -100.582 751.518 Q-100.582 751.905 -100.807 752.13 Q-101.033 752.356 -101.322 752.356 Q-101.773 752.356 -102.031 752.291 Q-102.289 752.195 -102.417 751.937 Q-102.546 751.68 -102.546 751.551 Q-102.578 751.422 -102.611 750.971 Q-102.772 748.523 -103.931 746.623 Q-105.123 744.691 -108.182 742.855 L-146.7 719.925 Q-147.087 719.699 -147.28 719.538 Q-147.473 719.377 -147.634 719.055 Q-147.795 718.701 -147.795 718.185 Q-147.795 717.38 -147.538 717.219 Q-147.312 717.058 -146.217 716.962 L-104.994 712.936 Q-104.124 712.839 -103.77 712.775 Q-103.448 712.678 -103.094 712.26 Q-102.772 711.809 -102.675 711.004 Q-102.611 710.166 -102.611 708.62 Q-102.611 708.041 -102.578 707.815 Q-102.578 707.59 -102.417 707.364 Q-102.256 707.107 -101.902 707.107 M-117.876 719.86 L-139.615 721.954 L-117.876 734.965 L-117.876 719.86 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M-82.3051 700.503 Q-83.1392 700.503 -83.3872 700.436 Q-83.6352 700.346 -84.0184 699.985 L-93.8928 691.125 Q-99.3484 686.278 -104.105 686.278 Q-107.194 686.278 -109.403 687.901 Q-111.612 689.502 -111.612 692.455 Q-111.612 694.484 -110.373 696.197 Q-109.133 697.911 -106.923 698.7 Q-106.968 698.565 -106.968 698.091 Q-106.968 696.941 -106.247 696.31 Q-105.526 695.656 -104.556 695.656 Q-103.316 695.656 -102.708 696.468 Q-102.121 697.257 -102.121 698.046 Q-102.121 698.362 -102.189 698.79 Q-102.257 699.196 -102.888 699.85 Q-103.542 700.503 -104.691 700.503 Q-107.915 700.503 -110.485 698.069 Q-113.055 695.611 -113.055 691.869 Q-113.055 687.631 -110.53 684.858 Q-108.028 682.062 -104.105 682.062 Q-102.73 682.062 -101.468 682.491 Q-100.228 682.896 -99.2583 683.46 Q-98.2889 684.001 -96.7333 685.489 Q-95.1778 686.977 -94.0731 688.172 Q-92.9685 689.367 -90.6239 692.049 L-85.8671 696.941 L-85.8671 688.623 Q-85.8671 684.565 -86.2278 684.249 Q-86.8816 683.798 -90.3308 683.235 L-90.3308 682.062 L-82.3051 683.37 L-82.3051 700.503 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M866.112 18.8205 L866.112 65.8515 L875.996 65.8515 Q888.513 65.8515 894.306 60.1802 Q900.14 54.509 900.14 42.2752 Q900.14 30.1225 894.306 24.4918 Q888.513 18.8205 875.996 18.8205 L866.112 18.8205 M857.929 12.096 L874.74 12.096 Q892.321 12.096 900.545 19.4281 Q908.768 26.7198 908.768 42.2752 Q908.768 57.9117 900.504 65.2439 Q892.24 72.576 874.74 72.576 L857.929 72.576 L857.929 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M929.995 18.8205 L929.995 65.8515 L939.879 65.8515 Q952.396 65.8515 958.189 60.1802 Q964.022 54.509 964.022 42.2752 Q964.022 30.1225 958.189 24.4918 Q952.396 18.8205 939.879 18.8205 L929.995 18.8205 M921.812 12.096 L938.623 12.096 Q956.204 12.096 964.427 19.4281 Q972.651 26.7198 972.651 42.2752 Q972.651 57.9117 964.387 65.2439 Q956.123 72.576 938.623 72.576 L921.812 72.576 L921.812 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M999.832 72.576 L976.742 12.096 L985.29 12.096 L1004.45 63.0159 L1023.65 12.096 L1032.16 12.096 L1009.11 72.576 L999.832 72.576 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1040.99 12.096 L1075.75 12.096 L1075.75 18.9825 L1049.17 18.9825 L1049.17 36.8065 L1073.15 36.8065 L1073.15 43.6931 L1049.17 43.6931 L1049.17 72.576 L1040.99 72.576 L1040.99 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1101.31 20.1573 L1090.21 50.2555 L1112.45 50.2555 L1101.31 20.1573 M1096.69 12.096 L1105.97 12.096 L1129.02 72.576 L1120.51 72.576 L1115 57.061 L1087.74 57.061 L1082.23 72.576 L1073.6 72.576 L1096.69 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1164.22 12.096 L1172.4 12.096 L1172.4 72.576 L1164.22 72.576 L1164.22 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1214.65 34.1734 Q1213.4 33.4443 1211.9 33.1202 Q1210.44 32.7556 1208.66 32.7556 Q1202.34 32.7556 1198.93 36.8875 Q1195.57 40.9789 1195.57 48.6757 L1195.57 72.576 L1188.08 72.576 L1188.08 27.2059 L1195.57 27.2059 L1195.57 34.2544 Q1197.92 30.1225 1201.69 28.1376 Q1205.46 26.1121 1210.84 26.1121 Q1211.61 26.1121 1212.55 26.2337 Q1213.48 26.3147 1214.61 26.5172 L1214.65 34.1734 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1222.47 27.2059 L1229.92 27.2059 L1229.92 72.576 L1222.47 72.576 L1222.47 27.2059 M1222.47 9.54393 L1229.92 9.54393 L1229.92 18.9825 L1222.47 18.9825 L1222.47 9.54393 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1274.44 28.5427 L1274.44 35.5912 Q1271.28 33.9709 1267.88 33.1607 Q1264.48 32.3505 1260.83 32.3505 Q1255.28 32.3505 1252.49 34.0519 Q1249.73 35.7533 1249.73 39.156 Q1249.73 41.7486 1251.72 43.2475 Q1253.7 44.7058 1259.7 46.0426 L1262.25 46.6097 Q1270.19 48.3111 1273.51 51.4303 Q1276.87 54.509 1276.87 60.0587 Q1276.87 66.3781 1271.85 70.0644 Q1266.87 73.7508 1258.12 73.7508 Q1254.47 73.7508 1250.5 73.0216 Q1246.57 72.3329 1242.2 70.9151 L1242.2 63.2184 Q1246.33 65.3654 1250.34 66.4591 Q1254.35 67.5124 1258.28 67.5124 Q1263.55 67.5124 1266.38 65.73 Q1269.22 63.9071 1269.22 60.6258 Q1269.22 57.5877 1267.15 55.9673 Q1265.13 54.3469 1258.2 52.8481 L1255.61 52.2405 Q1248.68 50.7821 1245.6 47.7845 Q1242.52 44.7463 1242.52 39.4801 Q1242.52 33.0797 1247.06 29.5959 Q1251.6 26.1121 1259.94 26.1121 Q1264.07 26.1121 1267.72 26.7198 Q1271.36 27.3274 1274.44 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1360.73 16.7545 L1360.73 25.383 Q1356.6 21.5346 1351.9 19.6307 Q1347.24 17.7268 1341.97 17.7268 Q1331.6 17.7268 1326.09 24.0867 Q1320.58 30.4061 1320.58 42.3968 Q1320.58 54.3469 1326.09 60.7069 Q1331.6 67.0263 1341.97 67.0263 Q1347.24 67.0263 1351.9 65.1223 Q1356.6 63.2184 1360.73 59.3701 L1360.73 67.9175 Q1356.43 70.8341 1351.61 72.2924 Q1346.83 73.7508 1341.49 73.7508 Q1327.75 73.7508 1319.85 65.3654 Q1311.95 56.9395 1311.95 42.3968 Q1311.95 27.8135 1319.85 19.4281 Q1327.75 11.0023 1341.49 11.0023 Q1346.91 11.0023 1351.69 12.4606 Q1356.51 13.8784 1360.73 16.7545 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1373.04 9.54393 L1380.5 9.54393 L1380.5 72.576 L1373.04 72.576 L1373.04 9.54393 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1395.32 54.671 L1395.32 27.2059 L1402.78 27.2059 L1402.78 54.3874 Q1402.78 60.8284 1405.29 64.0691 Q1407.8 67.2693 1412.82 67.2693 Q1418.86 67.2693 1422.34 63.421 Q1425.87 59.5726 1425.87 52.9291 L1425.87 27.2059 L1433.32 27.2059 L1433.32 72.576 L1425.87 72.576 L1425.87 65.6084 Q1423.15 69.7404 1419.55 71.7658 Q1415.98 73.7508 1411.24 73.7508 Q1403.42 73.7508 1399.37 68.8897 Q1395.32 64.0286 1395.32 54.671 M1414.08 26.1121 L1414.08 26.1121 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1477.6 28.5427 L1477.6 35.5912 Q1474.44 33.9709 1471.03 33.1607 Q1467.63 32.3505 1463.98 32.3505 Q1458.44 32.3505 1455.64 34.0519 Q1452.89 35.7533 1452.89 39.156 Q1452.89 41.7486 1454.87 43.2475 Q1456.86 44.7058 1462.85 46.0426 L1465.4 46.6097 Q1473.34 48.3111 1476.66 51.4303 Q1480.03 54.509 1480.03 60.0587 Q1480.03 66.3781 1475 70.0644 Q1470.02 73.7508 1461.27 73.7508 Q1457.62 73.7508 1453.66 73.0216 Q1449.73 72.3329 1445.35 70.9151 L1445.35 63.2184 Q1449.48 65.3654 1453.49 66.4591 Q1457.5 67.5124 1461.43 67.5124 Q1466.7 67.5124 1469.53 65.73 Q1472.37 63.9071 1472.37 60.6258 Q1472.37 57.5877 1470.3 55.9673 Q1468.28 54.3469 1461.35 52.8481 L1458.76 52.2405 Q1451.83 50.7821 1448.75 47.7845 Q1445.67 44.7463 1445.67 39.4801 Q1445.67 33.0797 1450.21 29.5959 Q1454.75 26.1121 1463.09 26.1121 Q1467.23 26.1121 1470.87 26.7198 Q1474.52 27.3274 1477.6 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1499.27 14.324 L1499.27 27.2059 L1514.62 27.2059 L1514.62 32.9987 L1499.27 32.9987 L1499.27 57.6282 Q1499.27 63.1779 1500.77 64.7578 Q1502.31 66.3376 1506.96 66.3376 L1514.62 66.3376 L1514.62 72.576 L1506.96 72.576 Q1498.34 72.576 1495.06 69.3758 Q1491.77 66.1351 1491.77 57.6282 L1491.77 32.9987 L1486.31 32.9987 L1486.31 27.2059 L1491.77 27.2059 L1491.77 14.324 L1499.27 14.324 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1563.23 48.0275 L1563.23 51.6733 L1528.96 51.6733 Q1529.45 59.3701 1533.58 63.421 Q1537.75 67.4314 1545.17 67.4314 Q1549.46 67.4314 1553.47 66.3781 Q1557.52 65.3249 1561.49 63.2184 L1561.49 70.267 Q1557.48 71.9684 1553.27 72.8596 Q1549.05 73.7508 1544.72 73.7508 Q1533.86 73.7508 1527.5 67.4314 Q1521.18 61.1119 1521.18 50.3365 Q1521.18 39.1965 1527.18 32.6746 Q1533.21 26.1121 1543.42 26.1121 Q1552.58 26.1121 1557.88 32.0264 Q1563.23 37.9003 1563.23 48.0275 M1555.78 45.84 Q1555.7 39.7232 1552.34 36.0774 Q1549.01 32.4315 1543.5 32.4315 Q1537.27 32.4315 1533.5 35.9558 Q1529.77 39.4801 1529.2 45.8805 L1555.78 45.84 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1601.76 34.1734 Q1600.5 33.4443 1599 33.1202 Q1597.54 32.7556 1595.76 32.7556 Q1589.44 32.7556 1586.04 36.8875 Q1582.68 40.9789 1582.68 48.6757 L1582.68 72.576 L1575.18 72.576 L1575.18 27.2059 L1582.68 27.2059 L1582.68 34.2544 Q1585.03 30.1225 1588.79 28.1376 Q1592.56 26.1121 1597.95 26.1121 Q1598.72 26.1121 1599.65 26.2337 Q1600.58 26.3147 1601.72 26.5172 L1601.76 34.1734 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip870)" d="M1638.5 28.5427 L1638.5 35.5912 Q1635.34 33.9709 1631.94 33.1607 Q1628.53 32.3505 1624.89 32.3505 Q1619.34 32.3505 1616.54 34.0519 Q1613.79 35.7533 1613.79 39.156 Q1613.79 41.7486 1615.77 43.2475 Q1617.76 44.7058 1623.75 46.0426 L1626.3 46.6097 Q1634.24 48.3111 1637.57 51.4303 Q1640.93 54.509 1640.93 60.0587 Q1640.93 66.3781 1635.91 70.0644 Q1630.92 73.7508 1622.17 73.7508 Q1618.53 73.7508 1614.56 73.0216 Q1610.63 72.3329 1606.25 70.9151 L1606.25 63.2184 Q1610.38 65.3654 1614.39 66.4591 Q1618.41 67.5124 1622.33 67.5124 Q1627.6 67.5124 1630.44 65.73 Q1633.27 63.9071 1633.27 60.6258 Q1633.27 57.5877 1631.21 55.9673 Q1629.18 54.3469 1622.25 52.8481 L1619.66 52.2405 Q1612.73 50.7821 1609.66 47.7845 Q1606.58 44.7463 1606.58 39.4801 Q1606.58 33.0797 1611.11 29.5959 Q1615.65 26.1121 1624 26.1121 Q1628.13 26.1121 1631.77 26.7198 Q1635.42 27.3274 1638.5 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip873)" cx="2071.92" cy="1108.04" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="2046.53" cy="901.15" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1975.65" cy="932.966" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1963.41" cy="937.38" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1930.47" cy="735.087" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="2027.52" cy="867.82" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="2036.16" cy="1381.13" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="2032.88" cy="951.368" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1977.58" cy="625.636" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1965.81" cy="154.577" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1978.6" cy="102.584" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1884.7" cy="754.614" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1998.5" cy="964.706" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1963.1" cy="504.251" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="2139.04" cy="1121.94" r="28.8" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1456.71" cy="1422.31" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1212.19" cy="1006.35" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="992.24" cy="625.692" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1026.78" cy="700.595" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1003.89" cy="838.683" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1199.51" cy="1316.42" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1181.8" cy="979.214" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1087.44" cy="1109.87" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1052.48" cy="727.55" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1158.09" cy="945.699" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="949.563" cy="772.795" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1237.5" cy="1169.13" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1334.2" cy="1038.56" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="882.285" cy="670.659" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="1252.24" cy="1253.05" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="851.375" cy="905.046" r="28.8" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="400.826" cy="404.522" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="713.207" cy="705.204" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="621.676" cy="617.131" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="719.156" cy="571.346" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="601.291" cy="843.552" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="752.286" cy="948.7" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="582.084" cy="635.161" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="652.148" cy="688.391" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="465.801" cy="593.385" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="579.663" cy="590.948" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="724.04" cy="746.592" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="312.461" cy="488.145" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="440.689" cy="605.673" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip873)" cx="866.666" cy="941.385" r="28.8" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
</svg>
<p>This plot shows that the DDVFA modules do well at identifying the structure of the three clusters despite not achieving 100% test performance.</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">qt.qpa.xcb: could not connect to display
qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: linuxfb, minimal, offscreen, vnc, xcb.

Aborted (core dumped)
connect: Connection refused
GKS: can&#39;t connect to GKS socket application

GKS: Open failed in routine OPEN_WS
GKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/johnnychen94/DemoCards.jl">DemoCards.jl</a> and <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 11 October 2022 12:40">Tuesday 11 October 2022</span>. Using Julia version 1.8.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
