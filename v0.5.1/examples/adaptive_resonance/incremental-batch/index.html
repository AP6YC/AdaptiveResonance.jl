<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Incremental vs. Batch Example · AdaptiveResonance.jl</title><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../../democards/gridtheme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.png" alt="AdaptiveResonance.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">AdaptiveResonance.jl</a></span></div><form class="docs-search" action="../../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../../getting-started/whatisart/">Background</a></li><li><a class="tocitem" href="../../../getting-started/basic-example/">Basic Example</a></li></ul></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../../../man/guide/">Guide</a></li><li><a class="tocitem" href="../../">Examples</a></li><li><a class="tocitem" href="../../../man/modules/">Modules</a></li><li><a class="tocitem" href="../../../man/contributing/">Contributing</a></li><li><a class="tocitem" href="../../../man/full-index/">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Incremental vs. Batch Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Incremental vs. Batch Example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/AP6YC/AdaptiveResonance.jl/blob/master/docs/examples/adaptive_resonance/incremental-batch.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="incremental_batch"><a class="docs-heading-anchor" href="#incremental_batch">Incremental vs. Batch Example</a><a id="incremental_batch-1"></a><a class="docs-heading-anchor-permalink" href="#incremental_batch" title="Permalink"></a></h1><p><a href="../incremental-batch.jl"><img src="https://img.shields.io/badge/download-julia-brightgreen.svg" alt="Source code"/></a> <a href="https://nbviewer.jupyter.org/github/AP6YC/AdaptiveResonance.jl/blob/gh-pages/v0.5.1/examples/adaptive_resonance/incremental-batch.ipynb"><img src="https://img.shields.io/badge/show-nbviewer-579ACA.svg" alt="notebook"/></a> <img src="https://img.shields.io/badge/julia-1.6.0-blue.svg" alt="compat"/> <a href="https://github.com/AP6YC"><img src="https://img.shields.io/badge/Author-Sasha%20Petrenko-blue" alt="Author"/></a> <img src="https://img.shields.io/date/1638316800" alt="Update time"/></p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>All modules in <code>AdaptiveResonance.jl</code> are designed to handle incremental and batch training. In fact, ART modules are generally incremental in their implementation, so their batch methods wrap the incremental ones and handle preprocessing, etc. For example, DDVFA can be run incrementally (i.e. with one sample at a time) with custom algorithmic options and a predetermined data configuration.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In the incremental case, it is necessary to provide a data configuration if the model is not pretrained because the model has no knowledge of the boundaries and dimensionality of the data, which are necessary in the complement coding step. For more info, see the guide in the docs on <a href="../../../man/guide/#incremental_vs_batch">incremental vs. batch</a>.</p></div></div><h2 id="Data-Setup"><a class="docs-heading-anchor" href="#Data-Setup">Data Setup</a><a id="Data-Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Setup" title="Permalink"></a></h2><p>We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.</p><pre><code class="language-julia hljs">using AdaptiveResonance # ART
using MLDatasets        # Iris dataset
using MLDataUtils       # Shuffling and splitting
using Printf            # Formatted number printing</code></pre><p>We will download the Iris dataset for its small size and benchmark use for clustering algorithms.</p><pre><code class="language-julia hljs"># Get the iris dataset as a DataFrame
iris = Iris()
# Manipulate the features and labels into a matrix of features and a vector of labels
features, labels = Matrix(iris.features)&#39;, vec(Matrix{String}(iris.targets))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([5.1 4.9 … 6.2 5.9; 3.5 3.0 … 3.4 3.0; 1.4 1.4 … 5.4 5.1; 0.2 0.2 … 2.3 1.8], [&quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;, &quot;Iris-setosa&quot;  …  &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;, &quot;Iris-virginica&quot;])</code></pre><p>Because the MLDatasets package gives us Iris labels as strings, we will use the <code>MLDataUtils.convertlabel</code> method with the <code>MLLabelUtils.LabelEnc.Indices</code> type to get a list of integers representing each class:</p><pre><code class="language-julia hljs">labels = convertlabel(LabelEnc.Indices{Int}, labels)
unique(labels)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Int64}:
 1
 2
 3</code></pre><p>Next, we will create a train/test split with the <code>MLDataUtils.stratifiedobs</code> utility:</p><pre><code class="language-julia hljs">(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(([5.0 6.2 … 4.9 5.1; 3.2 2.9 … 3.1 2.5; 1.2 4.3 … 1.5 3.0; 0.2 1.3 … 0.1 1.1], [1, 2, 2, 2, 2, 3, 2, 2, 1, 3  …  2, 2, 3, 3, 2, 2, 2, 1, 1, 2]), ([7.3 5.7 … 5.2 6.6; 2.9 2.8 … 4.1 2.9; 6.3 4.1 … 1.5 4.6; 1.8 1.3 … 0.1 1.3], [3, 2, 3, 3, 1, 1, 1, 3, 2, 3  …  2, 2, 3, 2, 3, 1, 1, 3, 1, 2]))</code></pre><h2 id="Incremental-vs.-Batch"><a class="docs-heading-anchor" href="#Incremental-vs.-Batch">Incremental vs. Batch</a><a id="Incremental-vs.-Batch-1"></a><a class="docs-heading-anchor-permalink" href="#Incremental-vs.-Batch" title="Permalink"></a></h2><h3 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h3><p>Now, we can create several modules to illustrate training one in batch and one incrementaly.</p><pre><code class="language-julia hljs"># Create several modules for batch and incremental training.
# We can take advantage of the options instantiation method here to use the same options for both modules.
opts = opts_DDVFA(rho_lb=0.6, rho_ub=0.75)
art_batch = DDVFA(opts)
art_incremental = DDVFA(opts)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">DDVFA(opts_DDVFA
  rho_lb: Float64 0.6
  rho_ub: Float64 0.75
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  method: String &quot;single&quot;
  display: Bool true
  max_epoch: Int64 1
  gamma_normalization: Bool true
, opts_FuzzyART
  rho: Float64 0.75
  alpha: Float64 0.001
  beta: Float64 1.0
  gamma: Float64 3.0
  gamma_ref: Float64 1.0
  display: Bool false
  max_epochs: Int64 1
  gamma_normalization: Bool true
, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, 0.0, 0.0)</code></pre><p>For the incremental version, we must setup the data configuration in advance. In batch mode, this is done automatically based upon the provided data, but the incremental variant has not way of knowing the bounds of the individual features. We <em>could</em> preprocess the data and set the data configuration with <code>art.config = DataConfig(0, 1, 4)</code>, which translates to the data containing four features  that <em>all</em> range from 0 to 1. This would be done in scenarios where we have either done some preprocessing on the data or have prior knowledge about the bounds of individual features. However, in this example we will let the module determine the bounds with the convenience method <code>data_setup!</code>:</p><pre><code class="language-julia hljs"># Setup the data config on all of the features.
data_setup!(art_incremental.config, features)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 7.9
 4.4
 6.9
 2.5</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>We can train in batch with a simple supervised mode by passing the labels as a keyword argument.</p><pre><code class="language-julia hljs">y_hat_batch_train = train!(art_batch, X_train, y=y_train)
println(&quot;Training labels: &quot;,  size(y_hat_batch_train), &quot; &quot;, typeof(y_hat_batch_train))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Training DDVFA
0.0%┣                                              ┫ 0/105 [00:00&lt;00:-5, -0s/it]
Ep: 1, ID: 1, Cat: 0 1.0%┣▏                    ┫ 1/105 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 105, Cat: 13 100.0%┣████████████████┫ 105/105 [00:00&lt;00:00, 1.8kit/s]
Training labels: (105,) Vector{Int64}</code></pre><p>We can also train incrementally with the same method, being careful that we pass a vector features and a single integer as the labels</p><pre><code class="language-julia hljs"># Get the number of training samples
n_train = length(y_train)
# Create a container for the training output labels
y_hat_incremental_train = zeros(Int, n_train)
# Iterate over all training samples
for ix = 1:length(y_train)
    sample = X_train[:, ix]
    label = y_train[ix]
    y_hat_incremental_train[ix] = train!(art_incremental, sample, y=label)
end</code></pre><h3 id="Testing"><a class="docs-heading-anchor" href="#Testing">Testing</a><a id="Testing-1"></a><a class="docs-heading-anchor-permalink" href="#Testing" title="Permalink"></a></h3><p>We can then classify both networks and check that their performances are equivalent. For both, we will use the best-matching unit in the case of complete mismatch (see the docs on <a href="../../../man/guide/#mismatch-bmu">Mismatch vs. BMU</a>)</p><pre><code class="language-julia hljs"># Classify one model in batch mode
y_hat_batch = AdaptiveResonance.classify(art_batch, X_test, get_bmu=true)

# Classify one model incrementally
n_test = length(y_test)
y_hat_incremental = zeros(Int, n_test)
for ix = 1:n_test
    y_hat_incremental[ix] = AdaptiveResonance.classify(art_incremental, X_test[:, ix], get_bmu=true)
end

# Check the shape and type of the output labels
println(&quot;Batch testing labels: &quot;,  size(y_hat_batch), &quot; &quot;, typeof(y_hat_batch))
println(&quot;Incremental testing labels: &quot;,  size(y_hat_incremental), &quot; &quot;, typeof(y_hat_incremental))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">[ Info: Testing DDVFA
0.0%┣                                               ┫ 0/45 [00:00&lt;00:-2, -0s/it]
Ep: 1, ID: 1, Cat: 13 2.2%┣▌                    ┫ 1/45 [00:00&lt;Inf:Inf, InfGs/it]
Ep: 1, ID: 45, Cat: 13 100.0%┣████████████████████┫ 45/45 [00:00&lt;00:00, 829it/s]
Batch testing labels: (45,) Vector{Int64}
Incremental testing labels: (45,) Vector{Int64}</code></pre><p>Finally, we check the performance (number of correct classifications over total number of test samples) for both models, verifying that they produce the same results.</p><pre><code class="language-julia hljs"># Calculate performance on training data, testing data, and with get_bmu
perf_train_batch = performance(y_hat_batch_train, y_train)
perf_train_incremental = performance(y_hat_incremental_train, y_train)
perf_test_batch = performance(y_hat_batch, y_test)
perf_test_incremental = performance(y_hat_incremental, y_test)

# Format each performance number for comparison
@printf &quot;Batch training performance: %.4f\n&quot; perf_train_batch
@printf &quot;Incremental training performance: %.4f\n&quot; perf_train_incremental
@printf &quot;Batch testing performance: %.4f\n&quot; perf_test_batch
@printf &quot;Incremental testing performance: %.4f\n&quot; perf_test_incremental</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Batch training performance: 1.0000
Incremental training performance: 1.0000
Batch testing performance: 0.9333
Incremental testing performance: 0.9333</code></pre><h2 id="Visualization"><a class="docs-heading-anchor" href="#Visualization">Visualization</a><a id="Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#Visualization" title="Permalink"></a></h2><p>So we showed that the performance and behavior of modules are identical in incremental and batch modes. Great! Sadly, illustrating this point doesn&#39;t lend itself to visualization in any meaningful way. Nonetheless, we would like a pretty picture at the end of the experiment to verify that these identical solutions work in the first place. Sanity checks are meaningful in their own right, right?</p><p>To do this, we will reduce the dimensionality of the dataset to two dimensions and show in a scatter plot how the modules classify the test data into groups. This will be done with principal component analysis (PCA) to cast the points into a 2-D space while trying to preserve the relative distances between points in the higher dimension. The process isn&#39;t perfect by any means, but it suffices for visualization.</p><pre><code class="language-julia hljs"># Import visualization utilities
using Printf            # Formatted number printing
using MultivariateStats # Principal component analysis (PCA)
using Plots             # Plotting frontend

# Train a PCA model
M = fit(PCA, features; maxoutdim=2)

# Apply the PCA model to the testing set
X_test_pca = transform(M, X_test)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×45 Matrix{Float64}:
 -2.93201   -0.297808  -2.16538  …  -2.34976    2.64764   -1.0433
  0.352377  -0.347017   0.21528     -0.0418825  0.819983   0.228957</code></pre><p>Now that we have the test points cast into a 2-D set of points, we can create a scatter plot that shows how each point is categorized by the modules.</p><pre><code class="language-julia hljs"># Create a scatterplot object from the data with some additional formatting options
scatter(
    X_test_pca[1, :],       # PCA dimension 1
    X_test_pca[2, :],       # PCA dimension 2
    group = y_hat_batch,    # labels belonging to each point
    markersize = 8,         # size of scatter points
    legend = false,         # no legend
    xtickfontsize = 12,     # x-tick size
    ytickfontsize = 12,     # y-tick size
    dpi = 300,              # Set the dots-per-inch
    xlims = :round,         # Round up the x-limits to the nearest whole number
    xlabel = &quot;\$PCA_1\$&quot;,   # x-label
    ylabel = &quot;\$PCA_2\$&quot;,   # y-label
    title = (@sprintf &quot;DDVFA Iris Clusters&quot;),   # formatted title
)</code></pre><?xml version="1.0" encoding="utf-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="600" height="400" viewBox="0 0 2400 1600">
<defs>
  <clipPath id="clip530">
    <rect x="0" y="0" width="2400" height="1600"/>
  </clipPath>
</defs>
<path clip-path="url(#clip530)" d="
M0 1600 L2400 1600 L2400 0 L0 0  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip531">
    <rect x="480" y="0" width="1681" height="1600"/>
  </clipPath>
</defs>
<defs>
  <clipPath id="clip532">
    <rect x="1346" y="99" width="1008" height="1363"/>
  </clipPath>
</defs>
<path clip-path="url(#clip530)" d="
M146.102 1461.9 L2352.76 1461.9 L2352.76 62.9921 L146.102 62.9921  Z
  " fill="#ffffff" fill-rule="evenodd" fill-opacity="1"/>
<defs>
  <clipPath id="clip533">
    <rect x="146" y="62" width="2208" height="1400"/>
  </clipPath>
</defs>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,1461.9 146.102,62.9921 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  697.765,1461.9 697.765,62.9921 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1249.43,1461.9 1249.43,62.9921 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  1801.09,1461.9 1801.09,62.9921 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  2352.76,1461.9 2352.76,62.9921 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 2352.76,1461.9 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 146.102,1443 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  697.765,1461.9 697.765,1443 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1249.43,1461.9 1249.43,1443 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  1801.09,1461.9 1801.09,1443 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  2352.76,1461.9 2352.76,1443 
  "/>
<path clip-path="url(#clip530)" d="M99.4526 1520.66 L143.966 1520.66 L143.966 1526.56 L99.4526 1526.56 L99.4526 1520.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M178.376 1500.17 L160.668 1527.84 L178.376 1527.84 L178.376 1500.17 M176.535 1494.06 L185.355 1494.06 L185.355 1527.84 L192.751 1527.84 L192.751 1533.68 L185.355 1533.68 L185.355 1545.9 L178.376 1545.9 L178.376 1533.68 L154.973 1533.68 L154.973 1526.91 L176.535 1494.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M652.679 1520.66 L697.192 1520.66 L697.192 1526.56 L652.679 1526.56 L652.679 1520.66 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M718.373 1540 L742.852 1540 L742.852 1545.9 L709.935 1545.9 L709.935 1540 Q713.928 1535.86 720.803 1528.92 Q727.713 1521.94 729.484 1519.93 Q732.852 1516.14 734.171 1513.54 Q735.525 1510.9 735.525 1508.36 Q735.525 1504.23 732.609 1501.63 Q729.727 1499.02 725.074 1499.02 Q721.775 1499.02 718.095 1500.17 Q714.449 1501.32 710.282 1503.64 L710.282 1496.56 Q714.519 1494.86 718.199 1493.99 Q721.88 1493.12 724.935 1493.12 Q732.991 1493.12 737.782 1497.15 Q742.574 1501.18 742.574 1507.91 Q742.574 1511.11 741.359 1513.99 Q740.178 1516.84 737.018 1520.72 Q736.15 1521.73 731.498 1526.56 Q726.845 1531.35 718.373 1540 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1249.43 1498.68 Q1244.01 1498.68 1241.27 1504.02 Q1238.56 1509.34 1238.56 1520.03 Q1238.56 1530.69 1241.27 1536.04 Q1244.01 1541.35 1249.43 1541.35 Q1254.88 1541.35 1257.59 1536.04 Q1260.33 1530.69 1260.33 1520.03 Q1260.33 1509.34 1257.59 1504.02 Q1254.88 1498.68 1249.43 1498.68 M1249.43 1493.12 Q1258.14 1493.12 1262.73 1500.03 Q1267.35 1506.91 1267.35 1520.03 Q1267.35 1533.12 1262.73 1540.03 Q1258.14 1546.91 1249.43 1546.91 Q1240.71 1546.91 1236.1 1540.03 Q1231.51 1533.12 1231.51 1520.03 Q1231.51 1506.91 1236.1 1500.03 Q1240.71 1493.12 1249.43 1493.12 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1793.07 1540 L1817.55 1540 L1817.55 1545.9 L1784.63 1545.9 L1784.63 1540 Q1788.63 1535.86 1795.5 1528.92 Q1802.41 1521.94 1804.18 1519.93 Q1807.55 1516.14 1808.87 1513.54 Q1810.22 1510.9 1810.22 1508.36 Q1810.22 1504.23 1807.31 1501.63 Q1804.43 1499.02 1799.77 1499.02 Q1796.47 1499.02 1792.79 1500.17 Q1789.15 1501.32 1784.98 1503.64 L1784.98 1496.56 Q1789.22 1494.86 1792.9 1493.99 Q1796.58 1493.12 1799.63 1493.12 Q1807.69 1493.12 1812.48 1497.15 Q1817.27 1501.18 1817.27 1507.91 Q1817.27 1511.11 1816.06 1513.99 Q1814.88 1516.84 1811.72 1520.72 Q1810.85 1521.73 1806.2 1526.56 Q1801.54 1531.35 1793.07 1540 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M2357.27 1500.17 L2339.56 1527.84 L2357.27 1527.84 L2357.27 1500.17 M2355.43 1494.06 L2364.25 1494.06 L2364.25 1527.84 L2371.64 1527.84 L2371.64 1533.68 L2364.25 1533.68 L2364.25 1545.9 L2357.27 1545.9 L2357.27 1533.68 L2333.87 1533.68 L2333.87 1526.91 L2355.43 1494.06 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1210.86 1599.94 Q1210.86 1603.55 1208.18 1606.87 Q1205.54 1610.18 1201.23 1612.21 Q1196.94 1614.21 1192.34 1614.21 L1181.13 1614.21 L1177.04 1630.7 Q1177.01 1630.8 1176.91 1631.21 Q1176.82 1631.6 1176.82 1631.83 Q1176.82 1632.63 1177.81 1632.82 Q1178.84 1633.02 1181.13 1633.02 Q1182.61 1633.02 1182.84 1633.28 Q1182.97 1633.44 1182.97 1633.73 Q1182.97 1634.18 1182.84 1634.5 Q1182.71 1634.79 1182.45 1634.89 Q1182.23 1634.98 1182.07 1635.01 Q1181.9 1635.05 1181.65 1635.05 Q1180.97 1635.05 1179.52 1634.98 Q1178.1 1634.92 1177.36 1634.92 L1173.14 1634.85 L1164.77 1635.05 Q1163.77 1635.05 1163.77 1634.24 Q1163.77 1633.63 1164.03 1633.37 Q1164.29 1633.08 1164.58 1633.05 Q1164.87 1633.02 1165.61 1633.02 Q1167.22 1633.02 1168.18 1632.92 Q1169.15 1632.82 1169.76 1632.7 Q1170.41 1632.53 1170.73 1632.08 Q1171.08 1631.63 1171.24 1631.25 Q1171.41 1630.83 1171.63 1629.89 L1180.46 1594.47 Q1180.71 1593.4 1180.71 1593.24 Q1180.71 1592.7 1180.39 1592.5 Q1180.1 1592.28 1179.26 1592.18 Q1177.65 1592.05 1176.43 1592.05 Q1175.62 1592.05 1175.3 1592.02 Q1175.01 1591.99 1174.75 1591.83 Q1174.53 1591.63 1174.53 1591.25 Q1174.53 1590.64 1174.79 1590.38 Q1175.08 1590.09 1175.4 1590.06 Q1175.72 1589.99 1176.49 1589.99 L1197.88 1589.99 Q1204.03 1589.99 1207.44 1592.92 Q1210.86 1595.85 1210.86 1599.94 M1204.74 1598.36 Q1204.74 1592.05 1195.75 1592.05 L1189.44 1592.05 Q1187.35 1592.05 1186.83 1592.44 Q1186.32 1592.79 1185.87 1594.56 L1181.39 1612.5 L1190.7 1612.5 Q1196.94 1612.5 1200.84 1608.99 Q1202.61 1607.38 1203.68 1604.03 Q1204.74 1600.68 1204.74 1598.36 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1261.23 1589.22 L1257.07 1606.03 Q1256.78 1607.09 1256.59 1607.22 Q1256.43 1607.35 1255.91 1607.35 Q1254.91 1607.35 1254.91 1606.67 Q1254.91 1606.61 1255.01 1605.77 Q1255.11 1604.9 1255.11 1603.32 Q1255.11 1597.49 1252.27 1594.05 Q1249.47 1590.6 1244.48 1590.6 Q1240.16 1590.6 1235.82 1592.79 Q1231.5 1594.98 1228.41 1598.56 Q1226.09 1601.26 1224.38 1604.68 Q1222.71 1608.09 1221.9 1611.21 Q1221.13 1614.34 1220.78 1616.69 Q1220.42 1619.04 1220.42 1620.75 Q1220.42 1623.23 1220.94 1625.32 Q1221.48 1627.41 1222.45 1628.9 Q1223.42 1630.34 1224.64 1631.47 Q1225.9 1632.57 1227.35 1633.21 Q1228.83 1633.86 1230.31 1634.18 Q1231.79 1634.47 1233.34 1634.47 Q1239.55 1634.47 1245.48 1629.64 Q1250.18 1625.68 1252.14 1619.2 Q1252.31 1618.56 1252.98 1618.56 Q1253.79 1618.56 1253.79 1619.2 Q1253.79 1619.33 1253.63 1619.97 Q1253.46 1620.59 1252.98 1621.84 Q1252.5 1623.07 1251.76 1624.45 Q1251.02 1625.84 1249.63 1627.58 Q1248.25 1629.31 1246.54 1630.83 Q1243.64 1633.34 1239.97 1634.92 Q1236.3 1636.5 1232.27 1636.5 Q1227.25 1636.5 1223.19 1634.27 Q1219.13 1632.05 1216.75 1627.9 Q1214.4 1623.74 1214.4 1618.43 Q1214.4 1612.82 1216.98 1607.32 Q1219.55 1601.81 1223.64 1597.72 Q1227.73 1593.63 1233.14 1591.09 Q1238.55 1588.54 1243.96 1588.54 Q1246.03 1588.54 1247.86 1589.09 Q1249.7 1589.64 1250.79 1590.31 Q1251.92 1590.99 1252.92 1591.99 Q1253.92 1592.95 1254.24 1593.4 Q1254.59 1593.86 1254.91 1594.4 L1259.52 1589.35 Q1260.32 1588.54 1260.52 1588.54 Q1260.9 1588.54 1261.07 1588.77 Q1261.23 1588.99 1261.23 1589.22 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1306.35 1633.73 Q1306.35 1634.34 1306.09 1634.66 Q1305.86 1634.95 1305.64 1635.01 Q1305.45 1635.05 1305.16 1635.05 Q1304.32 1635.05 1301.42 1634.95 Q1298.52 1634.85 1297.68 1634.85 Q1296.33 1634.85 1293.56 1634.95 Q1290.79 1635.05 1289.44 1635.05 Q1288.54 1635.05 1288.54 1634.31 Q1288.54 1633.82 1288.63 1633.57 Q1288.73 1633.28 1288.99 1633.18 Q1289.28 1633.05 1289.44 1633.05 Q1289.63 1633.02 1290.12 1633.02 Q1290.76 1633.02 1291.44 1632.95 Q1292.11 1632.86 1292.95 1632.66 Q1293.79 1632.47 1294.3 1631.99 Q1294.85 1631.5 1294.85 1630.83 Q1294.85 1630.54 1294.62 1628.15 Q1294.4 1625.77 1294.11 1623 Q1293.82 1620.2 1293.79 1619.81 L1277.23 1619.81 Q1275.72 1622.42 1274.66 1624.23 Q1273.59 1626.03 1273.21 1626.64 Q1272.82 1627.25 1272.6 1627.64 Q1272.37 1628.03 1272.24 1628.25 Q1271.31 1629.96 1271.31 1630.7 Q1271.31 1632.76 1274.4 1633.02 Q1275.46 1633.02 1275.46 1633.79 Q1275.46 1634.37 1275.2 1634.69 Q1274.95 1634.98 1274.72 1635.01 Q1274.53 1635.05 1274.21 1635.05 Q1273.14 1635.05 1270.92 1634.95 Q1268.7 1634.85 1267.6 1634.85 Q1266.67 1634.85 1264.74 1634.95 Q1262.81 1635.05 1261.94 1635.05 Q1261.55 1635.05 1261.32 1634.82 Q1261.1 1634.6 1261.1 1634.31 Q1261.1 1633.86 1261.16 1633.6 Q1261.26 1633.34 1261.52 1633.21 Q1261.77 1633.08 1261.9 1633.08 Q1262.03 1633.05 1262.48 1633.02 Q1264.93 1632.86 1266.83 1631.7 Q1268.76 1630.51 1270.6 1627.45 L1293.53 1588.93 Q1293.76 1588.54 1293.92 1588.35 Q1294.08 1588.16 1294.4 1587.99 Q1294.75 1587.83 1295.27 1587.83 Q1296.07 1587.83 1296.24 1588.09 Q1296.4 1588.32 1296.49 1589.41 L1300.52 1630.63 Q1300.62 1631.5 1300.68 1631.86 Q1300.78 1632.18 1301.19 1632.53 Q1301.65 1632.86 1302.45 1632.95 Q1303.29 1633.02 1304.83 1633.02 Q1305.41 1633.02 1305.64 1633.05 Q1305.86 1633.05 1306.09 1633.21 Q1306.35 1633.37 1306.35 1633.73 M1293.59 1617.75 L1291.5 1596.01 L1278.49 1617.75 L1293.59 1617.75 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1312.95 1626.97 L1312.95 1625.53 Q1318.5 1625.53 1321.36 1622.57 Q1322.15 1622.57 1322.28 1622.75 Q1322.42 1622.93 1322.42 1623.77 L1322.42 1649.67 Q1322.42 1651.05 1323.1 1651.47 Q1323.77 1651.9 1326.73 1651.9 L1328.19 1651.9 L1328.19 1653.32 Q1326.57 1653.19 1320.71 1653.19 Q1314.84 1653.19 1313.24 1653.32 L1313.24 1651.9 L1314.71 1651.9 Q1317.62 1651.9 1318.32 1651.5 Q1319.02 1651.07 1319.02 1649.67 L1319.02 1625.75 Q1316.6 1626.97 1312.95 1626.97 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,1291.75 2352.76,1291.75 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,969.438 2352.76,969.438 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,647.128 2352.76,647.128 
  "/>
<polyline clip-path="url(#clip533)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none" points="
  146.102,324.819 2352.76,324.819 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1461.9 146.102,62.9921 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,1291.75 164.999,1291.75 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,969.438 164.999,969.438 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,647.128 164.999,647.128 
  "/>
<polyline clip-path="url(#clip530)" style="stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none" points="
  146.102,324.819 164.999,324.819 
  "/>
<path clip-path="url(#clip530)" d="M-48.8211 1292.42 L-4.30749 1292.42 L-4.30749 1298.33 L-48.8211 1298.33 L-48.8211 1292.42 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M25.8312 1270.44 Q20.4146 1270.44 17.6716 1275.79 Q14.9632 1281.1 14.9632 1291.8 Q14.9632 1302.46 17.6716 1307.81 Q20.4146 1313.12 25.8312 1313.12 Q31.2826 1313.12 33.9909 1307.81 Q36.734 1302.46 36.734 1291.8 Q36.734 1281.1 33.9909 1275.79 Q31.2826 1270.44 25.8312 1270.44 M25.8312 1264.89 Q34.5465 1264.89 39.1298 1271.8 Q43.7478 1278.67 43.7478 1291.8 Q43.7478 1304.89 39.1298 1311.8 Q34.5465 1318.67 25.8312 1318.67 Q17.116 1318.67 12.498 1311.8 Q7.91466 1304.89 7.91466 1291.8 Q7.91466 1278.67 12.498 1271.8 Q17.116 1264.89 25.8312 1264.89 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M56.0741 1308.85 L63.4005 1308.85 L63.4005 1317.67 L56.0741 1317.67 L56.0741 1308.85 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M78.7476 1265.83 L106.282 1265.83 L106.282 1271.73 L85.1712 1271.73 L85.1712 1284.44 Q86.699 1283.92 88.2267 1283.67 Q89.7545 1283.4 91.2823 1283.4 Q99.9628 1283.4 105.032 1288.15 Q110.102 1292.91 110.102 1301.04 Q110.102 1309.4 104.893 1314.06 Q99.685 1318.67 90.2059 1318.67 Q86.942 1318.67 83.5393 1318.12 Q80.1712 1317.56 76.5601 1316.45 L76.5601 1309.4 Q79.6851 1311.1 83.0184 1311.94 Q86.3517 1312.77 90.067 1312.77 Q96.0739 1312.77 99.5808 1309.61 Q103.088 1306.45 103.088 1301.04 Q103.088 1295.62 99.5808 1292.46 Q96.0739 1289.3 90.067 1289.3 Q87.2545 1289.3 84.442 1289.92 Q81.6643 1290.55 78.7476 1291.87 L78.7476 1265.83 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M24.3382 948.136 Q18.9215 948.136 16.1785 953.483 Q13.4702 958.795 13.4702 969.49 Q13.4702 980.149 16.1785 985.497 Q18.9215 990.809 24.3382 990.809 Q29.7895 990.809 32.4979 985.497 Q35.2409 980.149 35.2409 969.49 Q35.2409 958.795 32.4979 953.483 Q29.7895 948.136 24.3382 948.136 M24.3382 942.58 Q33.0534 942.58 37.6367 949.49 Q42.2548 956.365 42.2548 969.49 Q42.2548 982.58 37.6367 989.49 Q33.0534 996.365 24.3382 996.365 Q15.623 996.365 11.0049 989.49 Q6.42162 982.58 6.42162 969.49 Q6.42162 956.365 11.0049 949.49 Q15.623 942.58 24.3382 942.58 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M54.5811 986.538 L61.9074 986.538 L61.9074 995.358 L54.5811 995.358 L54.5811 986.538 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M92.185 948.136 Q86.7684 948.136 84.0254 953.483 Q81.317 958.795 81.317 969.49 Q81.317 980.149 84.0254 985.497 Q86.7684 990.809 92.185 990.809 Q97.6364 990.809 100.345 985.497 Q103.088 980.149 103.088 969.49 Q103.088 958.795 100.345 953.483 Q97.6364 948.136 92.185 948.136 M92.185 942.58 Q100.9 942.58 105.484 949.49 Q110.102 956.365 110.102 969.49 Q110.102 982.58 105.484 989.49 Q100.9 996.365 92.185 996.365 Q83.4698 996.365 78.8518 989.49 Q74.2685 982.58 74.2685 969.49 Q74.2685 956.365 78.8518 949.49 Q83.4698 942.58 92.185 942.58 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M25.8312 625.826 Q20.4146 625.826 17.6716 631.173 Q14.9632 636.486 14.9632 647.18 Q14.9632 657.84 17.6716 663.187 Q20.4146 668.5 25.8312 668.5 Q31.2826 668.5 33.9909 663.187 Q36.734 657.84 36.734 647.18 Q36.734 636.486 33.9909 631.173 Q31.2826 625.826 25.8312 625.826 M25.8312 620.271 Q34.5465 620.271 39.1298 627.18 Q43.7478 634.055 43.7478 647.18 Q43.7478 660.271 39.1298 667.18 Q34.5465 674.055 25.8312 674.055 Q17.116 674.055 12.498 667.18 Q7.91466 660.271 7.91466 647.18 Q7.91466 634.055 12.498 627.18 Q17.116 620.271 25.8312 620.271 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M56.0741 664.229 L63.4005 664.229 L63.4005 673.048 L56.0741 673.048 L56.0741 664.229 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M78.7476 621.208 L106.282 621.208 L106.282 627.111 L85.1712 627.111 L85.1712 639.819 Q86.699 639.298 88.2267 639.055 Q89.7545 638.778 91.2823 638.778 Q99.9628 638.778 105.032 643.535 Q110.102 648.291 110.102 656.416 Q110.102 664.784 104.893 669.437 Q99.685 674.055 90.2059 674.055 Q86.942 674.055 83.5393 673.5 Q80.1712 672.944 76.5601 671.833 L76.5601 664.784 Q79.6851 666.486 83.0184 667.319 Q86.3517 668.152 90.067 668.152 Q96.0739 668.152 99.5808 664.993 Q103.088 661.833 103.088 656.416 Q103.088 651 99.5808 647.84 Q96.0739 644.68 90.067 644.68 Q87.2545 644.68 84.442 645.305 Q81.6643 645.93 78.7476 647.25 L78.7476 621.208 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M10.5535 344.836 L22.0118 344.836 L22.0118 305.288 L9.5466 307.788 L9.5466 301.399 L21.9424 298.899 L28.9562 298.899 L28.9562 344.836 L40.4145 344.836 L40.4145 350.739 L10.5535 350.739 L10.5535 344.836 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M54.5811 341.92 L61.9074 341.92 L61.9074 350.739 L54.5811 350.739 L54.5811 341.92 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M92.185 303.517 Q86.7684 303.517 84.0254 308.864 Q81.317 314.177 81.317 324.871 Q81.317 335.531 84.0254 340.878 Q86.7684 346.19 92.185 346.19 Q97.6364 346.19 100.345 340.878 Q103.088 335.531 103.088 324.871 Q103.088 314.177 100.345 308.864 Q97.6364 303.517 92.185 303.517 M92.185 297.961 Q100.9 297.961 105.484 304.871 Q110.102 311.746 110.102 324.871 Q110.102 337.961 105.484 344.871 Q100.9 351.746 92.185 351.746 Q83.4698 351.746 78.8518 344.871 Q74.2685 337.961 74.2685 324.871 Q74.2685 311.746 78.8518 304.871 Q83.4698 297.961 92.185 297.961 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M-131.817 802.597 Q-128.21 802.597 -124.893 805.27 Q-121.576 807.911 -119.547 812.226 Q-117.55 816.51 -117.55 821.115 L-117.55 832.323 L-101.06 836.413 Q-100.964 836.445 -100.545 836.542 Q-100.159 836.638 -99.9332 836.638 Q-99.1281 836.638 -98.9348 835.64 Q-98.7416 834.61 -98.7416 832.323 Q-98.7416 830.841 -98.4839 830.616 Q-98.3229 830.487 -98.0331 830.487 Q-97.5822 830.487 -97.2601 830.616 Q-96.9703 830.745 -96.8736 831.002 Q-96.777 831.228 -96.7448 831.389 Q-96.7126 831.55 -96.7126 831.808 Q-96.7126 832.484 -96.777 833.933 Q-96.8414 835.35 -96.8414 836.091 L-96.9058 840.31 L-96.7126 848.683 Q-96.7126 849.682 -97.5178 849.682 Q-98.1297 849.682 -98.3873 849.424 Q-98.6772 849.167 -98.7094 848.877 Q-98.7416 848.587 -98.7416 847.846 Q-98.7416 846.236 -98.8382 845.27 Q-98.9348 844.303 -99.0636 843.692 Q-99.2247 843.047 -99.6756 842.725 Q-100.126 842.371 -100.513 842.21 Q-100.932 842.049 -101.866 841.824 L-137.292 832.999 Q-138.355 832.742 -138.516 832.742 Q-139.063 832.742 -139.257 833.064 Q-139.482 833.353 -139.579 834.191 Q-139.707 835.801 -139.707 837.025 Q-139.707 837.83 -139.74 838.152 Q-139.772 838.442 -139.933 838.7 Q-140.126 838.925 -140.513 838.925 Q-141.124 838.925 -141.382 838.667 Q-141.672 838.378 -141.704 838.056 Q-141.769 837.733 -141.769 836.961 L-141.769 815.576 Q-141.769 809.425 -138.838 806.011 Q-135.907 802.597 -131.817 802.597 M-133.395 808.716 Q-139.707 808.716 -139.707 817.701 L-139.707 824.014 Q-139.707 826.107 -139.321 826.622 Q-138.967 827.138 -137.195 827.589 L-119.257 832.065 L-119.257 822.758 Q-119.257 816.51 -122.767 812.613 Q-124.377 810.842 -127.727 809.779 Q-131.076 808.716 -133.395 808.716 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M-142.542 752.228 L-125.73 756.382 Q-124.667 756.672 -124.538 756.866 Q-124.41 757.027 -124.41 757.542 Q-124.41 758.54 -125.086 758.54 Q-125.15 758.54 -125.988 758.444 Q-126.857 758.347 -128.435 758.347 Q-134.265 758.347 -137.711 761.181 Q-141.157 763.983 -141.157 768.975 Q-141.157 773.291 -138.967 777.638 Q-136.777 781.954 -133.202 785.046 Q-130.497 787.365 -127.083 789.071 Q-123.669 790.746 -120.545 791.551 Q-117.421 792.324 -115.07 792.678 Q-112.719 793.033 -111.012 793.033 Q-108.532 793.033 -106.439 792.517 Q-104.345 791.97 -102.864 791.004 Q-101.415 790.038 -100.287 788.814 Q-99.1925 787.558 -98.5483 786.108 Q-97.9042 784.627 -97.5822 783.146 Q-97.2923 781.664 -97.2923 780.118 Q-97.2923 773.902 -102.123 767.977 Q-106.085 763.275 -112.558 761.31 Q-113.202 761.149 -113.202 760.473 Q-113.202 759.667 -112.558 759.667 Q-112.429 759.667 -111.785 759.828 Q-111.173 759.99 -109.917 760.473 Q-108.693 760.956 -107.308 761.696 Q-105.923 762.437 -104.184 763.822 Q-102.445 765.207 -100.932 766.914 Q-98.4195 769.812 -96.8414 773.484 Q-95.2633 777.155 -95.2633 781.181 Q-95.2633 786.205 -97.4856 790.263 Q-99.7078 794.321 -103.862 796.704 Q-108.017 799.055 -113.331 799.055 Q-118.935 799.055 -124.442 796.479 Q-129.949 793.902 -134.039 789.812 Q-138.129 785.722 -140.674 780.311 Q-143.218 774.901 -143.218 769.49 Q-143.218 767.429 -142.67 765.593 Q-142.123 763.758 -141.447 762.663 Q-140.77 761.535 -139.772 760.537 Q-138.806 759.539 -138.355 759.217 Q-137.904 758.862 -137.356 758.54 L-142.413 753.935 Q-143.218 753.13 -143.218 752.936 Q-143.218 752.55 -142.992 752.389 Q-142.767 752.228 -142.542 752.228 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M-98.0331 707.107 Q-97.4211 707.107 -97.0991 707.364 Q-96.8092 707.59 -96.7448 707.815 Q-96.7126 708.008 -96.7126 708.298 Q-96.7126 709.136 -96.8092 712.034 Q-96.9058 714.933 -96.9058 715.77 Q-96.9058 717.123 -96.8092 719.892 Q-96.7126 722.662 -96.7126 724.015 Q-96.7126 724.916 -97.4533 724.916 Q-97.9364 724.916 -98.1941 724.82 Q-98.4839 724.723 -98.5806 724.466 Q-98.7094 724.176 -98.7094 724.015 Q-98.7416 723.821 -98.7416 723.338 Q-98.7416 722.694 -98.806 722.018 Q-98.9026 721.342 -99.0958 720.504 Q-99.2891 719.667 -99.7722 719.152 Q-100.255 718.604 -100.932 718.604 Q-101.221 718.604 -103.605 718.83 Q-105.988 719.055 -108.758 719.345 Q-111.56 719.635 -111.946 719.667 L-111.946 736.221 Q-109.337 737.734 -107.534 738.797 Q-105.73 739.86 -105.118 740.246 Q-104.506 740.633 -104.12 740.858 Q-103.733 741.084 -103.508 741.213 Q-101.801 742.147 -101.06 742.147 Q-98.9992 742.147 -98.7416 739.055 Q-98.7416 737.992 -97.9686 737.992 Q-97.3889 737.992 -97.0669 738.25 Q-96.777 738.507 -96.7448 738.733 Q-96.7126 738.926 -96.7126 739.248 Q-96.7126 740.311 -96.8092 742.533 Q-96.9058 744.755 -96.9058 745.85 Q-96.9058 746.784 -96.8092 748.717 Q-96.7126 750.649 -96.7126 751.518 Q-96.7126 751.905 -96.9381 752.13 Q-97.1635 752.356 -97.4533 752.356 Q-97.9042 752.356 -98.1619 752.291 Q-98.4195 752.195 -98.5483 751.937 Q-98.6772 751.68 -98.6772 751.551 Q-98.7094 751.422 -98.7416 750.971 Q-98.9026 748.523 -100.062 746.623 Q-101.254 744.691 -104.313 742.855 L-142.831 719.925 Q-143.218 719.699 -143.411 719.538 Q-143.604 719.377 -143.765 719.055 Q-143.926 718.701 -143.926 718.185 Q-143.926 717.38 -143.669 717.219 Q-143.443 717.058 -142.348 716.962 L-101.125 712.936 Q-100.255 712.839 -99.901 712.775 Q-99.5789 712.678 -99.2247 712.26 Q-98.9026 711.809 -98.806 711.004 Q-98.7416 710.166 -98.7416 708.62 Q-98.7416 708.041 -98.7094 707.815 Q-98.7094 707.59 -98.5483 707.364 Q-98.3873 707.107 -98.0331 707.107 M-114.007 719.86 L-135.746 721.954 L-114.007 734.965 L-114.007 719.86 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M-78.436 700.503 Q-79.2702 700.503 -79.5182 700.436 Q-79.7662 700.346 -80.1494 699.985 L-90.0237 691.125 Q-95.4794 686.278 -100.236 686.278 Q-103.325 686.278 -105.534 687.901 Q-107.743 689.502 -107.743 692.455 Q-107.743 694.484 -106.503 696.197 Q-105.264 697.911 -103.054 698.7 Q-103.099 698.565 -103.099 698.091 Q-103.099 696.941 -102.378 696.31 Q-101.656 695.656 -100.687 695.656 Q-99.4472 695.656 -98.8385 696.468 Q-98.2523 697.257 -98.2523 698.046 Q-98.2523 698.362 -98.3199 698.79 Q-98.3876 699.196 -99.0188 699.85 Q-99.6726 700.503 -100.822 700.503 Q-104.046 700.503 -106.616 698.069 Q-109.186 695.611 -109.186 691.869 Q-109.186 687.631 -106.661 684.858 Q-104.159 682.062 -100.236 682.062 Q-98.861 682.062 -97.5985 682.491 Q-96.3586 682.896 -95.3892 683.46 Q-94.4198 684.001 -92.8643 685.489 Q-91.3087 686.977 -90.2041 688.172 Q-89.0994 689.367 -86.7548 692.049 L-81.998 696.941 L-81.998 688.623 Q-81.998 684.565 -82.3587 684.249 Q-83.0125 683.798 -86.4618 683.235 L-86.4618 682.062 L-78.436 683.37 L-78.436 700.503 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M866.112 18.8205 L866.112 65.8515 L875.996 65.8515 Q888.513 65.8515 894.306 60.1802 Q900.14 54.509 900.14 42.2752 Q900.14 30.1225 894.306 24.4918 Q888.513 18.8205 875.996 18.8205 L866.112 18.8205 M857.929 12.096 L874.74 12.096 Q892.321 12.096 900.545 19.4281 Q908.768 26.7198 908.768 42.2752 Q908.768 57.9117 900.504 65.2439 Q892.24 72.576 874.74 72.576 L857.929 72.576 L857.929 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M929.995 18.8205 L929.995 65.8515 L939.879 65.8515 Q952.396 65.8515 958.189 60.1802 Q964.022 54.509 964.022 42.2752 Q964.022 30.1225 958.189 24.4918 Q952.396 18.8205 939.879 18.8205 L929.995 18.8205 M921.812 12.096 L938.623 12.096 Q956.204 12.096 964.427 19.4281 Q972.651 26.7198 972.651 42.2752 Q972.651 57.9117 964.387 65.2439 Q956.123 72.576 938.623 72.576 L921.812 72.576 L921.812 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M999.832 72.576 L976.742 12.096 L985.29 12.096 L1004.45 63.0159 L1023.65 12.096 L1032.16 12.096 L1009.11 72.576 L999.832 72.576 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1040.99 12.096 L1075.75 12.096 L1075.75 18.9825 L1049.17 18.9825 L1049.17 36.8065 L1073.15 36.8065 L1073.15 43.6931 L1049.17 43.6931 L1049.17 72.576 L1040.99 72.576 L1040.99 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1101.31 20.1573 L1090.21 50.2555 L1112.45 50.2555 L1101.31 20.1573 M1096.69 12.096 L1105.97 12.096 L1129.02 72.576 L1120.51 72.576 L1115 57.061 L1087.74 57.061 L1082.23 72.576 L1073.6 72.576 L1096.69 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1164.22 12.096 L1172.4 12.096 L1172.4 72.576 L1164.22 72.576 L1164.22 12.096 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1214.65 34.1734 Q1213.4 33.4443 1211.9 33.1202 Q1210.44 32.7556 1208.66 32.7556 Q1202.34 32.7556 1198.93 36.8875 Q1195.57 40.9789 1195.57 48.6757 L1195.57 72.576 L1188.08 72.576 L1188.08 27.2059 L1195.57 27.2059 L1195.57 34.2544 Q1197.92 30.1225 1201.69 28.1376 Q1205.46 26.1121 1210.84 26.1121 Q1211.61 26.1121 1212.55 26.2337 Q1213.48 26.3147 1214.61 26.5172 L1214.65 34.1734 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1222.47 27.2059 L1229.92 27.2059 L1229.92 72.576 L1222.47 72.576 L1222.47 27.2059 M1222.47 9.54393 L1229.92 9.54393 L1229.92 18.9825 L1222.47 18.9825 L1222.47 9.54393 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1274.44 28.5427 L1274.44 35.5912 Q1271.28 33.9709 1267.88 33.1607 Q1264.48 32.3505 1260.83 32.3505 Q1255.28 32.3505 1252.49 34.0519 Q1249.73 35.7533 1249.73 39.156 Q1249.73 41.7486 1251.72 43.2475 Q1253.7 44.7058 1259.7 46.0426 L1262.25 46.6097 Q1270.19 48.3111 1273.51 51.4303 Q1276.87 54.509 1276.87 60.0587 Q1276.87 66.3781 1271.85 70.0644 Q1266.87 73.7508 1258.12 73.7508 Q1254.47 73.7508 1250.5 73.0216 Q1246.57 72.3329 1242.2 70.9151 L1242.2 63.2184 Q1246.33 65.3654 1250.34 66.4591 Q1254.35 67.5124 1258.28 67.5124 Q1263.55 67.5124 1266.38 65.73 Q1269.22 63.9071 1269.22 60.6258 Q1269.22 57.5877 1267.15 55.9673 Q1265.13 54.3469 1258.2 52.8481 L1255.61 52.2405 Q1248.68 50.7821 1245.6 47.7845 Q1242.52 44.7463 1242.52 39.4801 Q1242.52 33.0797 1247.06 29.5959 Q1251.6 26.1121 1259.94 26.1121 Q1264.07 26.1121 1267.72 26.7198 Q1271.36 27.3274 1274.44 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1360.73 16.7545 L1360.73 25.383 Q1356.6 21.5346 1351.9 19.6307 Q1347.24 17.7268 1341.97 17.7268 Q1331.6 17.7268 1326.09 24.0867 Q1320.58 30.4061 1320.58 42.3968 Q1320.58 54.3469 1326.09 60.7069 Q1331.6 67.0263 1341.97 67.0263 Q1347.24 67.0263 1351.9 65.1223 Q1356.6 63.2184 1360.73 59.3701 L1360.73 67.9175 Q1356.43 70.8341 1351.61 72.2924 Q1346.83 73.7508 1341.49 73.7508 Q1327.75 73.7508 1319.85 65.3654 Q1311.95 56.9395 1311.95 42.3968 Q1311.95 27.8135 1319.85 19.4281 Q1327.75 11.0023 1341.49 11.0023 Q1346.91 11.0023 1351.69 12.4606 Q1356.51 13.8784 1360.73 16.7545 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1373.04 9.54393 L1380.5 9.54393 L1380.5 72.576 L1373.04 72.576 L1373.04 9.54393 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1395.32 54.671 L1395.32 27.2059 L1402.78 27.2059 L1402.78 54.3874 Q1402.78 60.8284 1405.29 64.0691 Q1407.8 67.2693 1412.82 67.2693 Q1418.86 67.2693 1422.34 63.421 Q1425.87 59.5726 1425.87 52.9291 L1425.87 27.2059 L1433.32 27.2059 L1433.32 72.576 L1425.87 72.576 L1425.87 65.6084 Q1423.15 69.7404 1419.55 71.7658 Q1415.98 73.7508 1411.24 73.7508 Q1403.42 73.7508 1399.37 68.8897 Q1395.32 64.0286 1395.32 54.671 M1414.08 26.1121 L1414.08 26.1121 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1477.6 28.5427 L1477.6 35.5912 Q1474.44 33.9709 1471.03 33.1607 Q1467.63 32.3505 1463.98 32.3505 Q1458.44 32.3505 1455.64 34.0519 Q1452.89 35.7533 1452.89 39.156 Q1452.89 41.7486 1454.87 43.2475 Q1456.86 44.7058 1462.85 46.0426 L1465.4 46.6097 Q1473.34 48.3111 1476.66 51.4303 Q1480.03 54.509 1480.03 60.0587 Q1480.03 66.3781 1475 70.0644 Q1470.02 73.7508 1461.27 73.7508 Q1457.62 73.7508 1453.66 73.0216 Q1449.73 72.3329 1445.35 70.9151 L1445.35 63.2184 Q1449.48 65.3654 1453.49 66.4591 Q1457.5 67.5124 1461.43 67.5124 Q1466.7 67.5124 1469.53 65.73 Q1472.37 63.9071 1472.37 60.6258 Q1472.37 57.5877 1470.3 55.9673 Q1468.28 54.3469 1461.35 52.8481 L1458.76 52.2405 Q1451.83 50.7821 1448.75 47.7845 Q1445.67 44.7463 1445.67 39.4801 Q1445.67 33.0797 1450.21 29.5959 Q1454.75 26.1121 1463.09 26.1121 Q1467.23 26.1121 1470.87 26.7198 Q1474.52 27.3274 1477.6 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1499.27 14.324 L1499.27 27.2059 L1514.62 27.2059 L1514.62 32.9987 L1499.27 32.9987 L1499.27 57.6282 Q1499.27 63.1779 1500.77 64.7578 Q1502.31 66.3376 1506.96 66.3376 L1514.62 66.3376 L1514.62 72.576 L1506.96 72.576 Q1498.34 72.576 1495.06 69.3758 Q1491.77 66.1351 1491.77 57.6282 L1491.77 32.9987 L1486.31 32.9987 L1486.31 27.2059 L1491.77 27.2059 L1491.77 14.324 L1499.27 14.324 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1563.23 48.0275 L1563.23 51.6733 L1528.96 51.6733 Q1529.45 59.3701 1533.58 63.421 Q1537.75 67.4314 1545.17 67.4314 Q1549.46 67.4314 1553.47 66.3781 Q1557.52 65.3249 1561.49 63.2184 L1561.49 70.267 Q1557.48 71.9684 1553.27 72.8596 Q1549.05 73.7508 1544.72 73.7508 Q1533.86 73.7508 1527.5 67.4314 Q1521.18 61.1119 1521.18 50.3365 Q1521.18 39.1965 1527.18 32.6746 Q1533.21 26.1121 1543.42 26.1121 Q1552.58 26.1121 1557.88 32.0264 Q1563.23 37.9003 1563.23 48.0275 M1555.78 45.84 Q1555.7 39.7232 1552.34 36.0774 Q1549.01 32.4315 1543.5 32.4315 Q1537.27 32.4315 1533.5 35.9558 Q1529.77 39.4801 1529.2 45.8805 L1555.78 45.84 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1601.76 34.1734 Q1600.5 33.4443 1599 33.1202 Q1597.54 32.7556 1595.76 32.7556 Q1589.44 32.7556 1586.04 36.8875 Q1582.68 40.9789 1582.68 48.6757 L1582.68 72.576 L1575.18 72.576 L1575.18 27.2059 L1582.68 27.2059 L1582.68 34.2544 Q1585.03 30.1225 1588.79 28.1376 Q1592.56 26.1121 1597.95 26.1121 Q1598.72 26.1121 1599.65 26.2337 Q1600.58 26.3147 1601.72 26.5172 L1601.76 34.1734 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><path clip-path="url(#clip530)" d="M1638.5 28.5427 L1638.5 35.5912 Q1635.34 33.9709 1631.94 33.1607 Q1628.53 32.3505 1624.89 32.3505 Q1619.34 32.3505 1616.54 34.0519 Q1613.79 35.7533 1613.79 39.156 Q1613.79 41.7486 1615.77 43.2475 Q1617.76 44.7058 1623.75 46.0426 L1626.3 46.6097 Q1634.24 48.3111 1637.57 51.4303 Q1640.93 54.509 1640.93 60.0587 Q1640.93 66.3781 1635.91 70.0644 Q1630.92 73.7508 1622.17 73.7508 Q1618.53 73.7508 1614.56 73.0216 Q1610.63 72.3329 1606.25 70.9151 L1606.25 63.2184 Q1610.38 65.3654 1614.39 66.4591 Q1618.41 67.5124 1622.33 67.5124 Q1627.6 67.5124 1630.44 65.73 Q1633.27 63.9071 1633.27 60.6258 Q1633.27 57.5877 1631.21 55.9673 Q1629.18 54.3469 1622.25 52.8481 L1619.66 52.2405 Q1612.73 50.7821 1609.66 47.7845 Q1606.58 44.7463 1606.58 39.4801 Q1606.58 33.0797 1611.11 29.5959 Q1615.65 26.1121 1624 26.1121 Q1628.13 26.1121 1631.77 26.7198 Q1635.42 27.3274 1638.5 28.5427 Z" fill="#000000" fill-rule="evenodd" fill-opacity="1" /><circle clip-path="url(#clip533)" cx="1906.98" cy="102.584" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1978.6" cy="204.794" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1995.25" cy="895.299" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="2071.92" cy="1279.02" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1858.7" cy="684.067" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1956.22" cy="727.909" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1950.78" cy="591.51" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1949.37" cy="640.445" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1977.58" cy="763.617" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="2136.46" cy="878.15" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1950.93" cy="685.785" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1979.92" cy="763.716" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1856" cy="402.66" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1965.81" cy="260.343" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1979.73" cy="440.861" r="28" fill="#009af9" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1167.28" cy="1193.13" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1025.33" cy="1074.08" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="977.998" cy="1049.6" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1026.78" cy="843.702" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1145.93" cy="1157.42" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1302.36" cy="1406.16" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1052.48" cy="872.5" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1204.05" cy="1407.56" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1268.83" cy="1422.31" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="845.594" cy="644.427" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="1121.71" cy="1401.03" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="961.654" cy="821.848" r="28" fill="#e26f46" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="440.689" cy="742.289" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="652.148" cy="830.664" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="621.676" cy="754.53" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="400.826" cy="527.381" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="312.461" cy="616.723" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="713.207" cy="848.626" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="611.07" cy="851.725" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="724.007" cy="938.465" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="828.602" cy="1211.18" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="819.849" cy="797.071" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="653.98" cy="1110.17" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="927.022" cy="1075.48" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="918.955" cy="1359.81" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="989.495" cy="1318.71" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="941.534" cy="1023.72" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="551.098" cy="977.071" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="866.666" cy="1100.96" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
<circle clip-path="url(#clip533)" cx="601.291" cy="996.436" r="28" fill="#3da44d" fill-rule="evenodd" fill-opacity="1" stroke="#000000" stroke-opacity="1" stroke-width="3.2"/>
</svg>
<p>This plot shows that the DDVFA modules do well at identifying the structure of the three clusters despite not achieving 100% test performance.</p><pre class="documenter-example-output"><code class="nohighlight hljs ansi">qt.qpa.xcb: could not connect to display
qt.qpa.plugin: Could not load the Qt platform plugin &quot;xcb&quot; in &quot;&quot; even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: linuxfb, minimal, offscreen, vnc, xcb.

Aborted (core dumped)
connect: Connection refused
GKS: can&#39;t connect to GKS socket application

GKS: Open failed in routine OPEN_WS
GKS: GKS not in proper state. GKS must be either in the state WSOP or WSAC in routine ACTIVATE_WS</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/johnnychen94/DemoCards.jl">DemoCards.jl</a> and <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.17 on <span class="colophon-date" title="Friday 13 May 2022 01:35">Friday 13 May 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
