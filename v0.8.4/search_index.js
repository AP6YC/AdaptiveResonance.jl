var documenterSearchIndex = {"docs":
[{"location":"getting-started/basic-example/#Basic-Example","page":"Basic Example","title":"Basic Example","text":"","category":"section"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"This page demonstrates a full basic example of an AdaptiveResonance.jl workflow. In the example below, we create a dataset generated from two multivariate Gaussian distributions in two dimensions, showing how an ART module can be used in unsupervised or simple supervised modes alongside an ARTMAP module that is explicitly supervised-only.","category":"page"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"For more examples that you can run yourself in Julia notebooks, see the Examples page.","category":"page"},{"location":"getting-started/basic-example/","page":"Basic Example","title":"Basic Example","text":"# Copyright © 2021 Alexander L. Hayes\n# MIT License\n\nusing AdaptiveResonance\nusing Distributions, Random\nusing MLDataUtils\nusing Plots\n\n\"\"\"\nDemonstrates Unsupervised DDVFA, Supervised DDVFA, and (Supervised) SFAM on a toy problem\nwith two multivariate Gaussians.\n\"\"\"\n\n# Setup two multivariate Gaussians and sampling 1000 points from each.\n\nrng = MersenneTwister(1234)\ndist1 = MvNormal([0.0, 6.0], [1.0 0.0; 0.0 1.0])\ndist2 = MvNormal([4.5, 6.0], [2.0 -1.5; -1.5 2.0])\n\nN_POINTS = 1000\n\nX = hcat(rand(rng, dist1, N_POINTS), rand(rng, dist2, N_POINTS))\ny = vcat(ones(Int64, N_POINTS), zeros(Int64, N_POINTS))\n\np1 = scatter(X[1,:], X[2,:], group=y, title=\"Original Data\")\n\n(X_train, y_train), (X_test, y_test) = stratifiedobs((X, y))\n\n# Standardize data types\nX_train = convert(Matrix{Float64}, X_train)\nX_test = convert(Matrix{Float64}, X_test)\ny_train = convert(Vector{Int}, y_train)\ny_test = convert(Vector{Int}, y_test)\n\n# Unsupervised DDVFA\nart = DDVFA()\ntrain!(art, X_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np2 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Unsupervised DDVFA\")\n\n# Supervised DDVFA\nart = DDVFA()\ntrain!(art, X_train, y=y_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np3 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Supervised DDVFA\", xlabel=\"Performance: \" * string(round(performance(y_hat_test, y_test); digits=3)))\n\n# Supervised SFAM\nart = SFAM()\ntrain!(art, X_train, y_train)\ny_hat_test = AdaptiveResonance.classify(art, X_test)\np4 = scatter(X_test[1,:], X_test[2,:], group=y_hat_test, title=\"Supervised SFAM\", xlabel=\"Performance: \" * string(round(performance(y_hat_test, y_test); digits=3)))\n\n# Performance Measure + display the plots\nplot(p1, p2, p3, p4, layout=(1, 4), legend = false, xtickfontsize=6, xguidefontsize=8, titlefont=font(8))","category":"page"},{"location":"man/contributing/#Contributing","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This page serves as the contribution guide for the AdaptiveResonance.jl package. From top to bottom, the ways of contributing are:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"GitHub Issues: how to raise an issue with the project.\nJulia Development: how to download and interact with the package.\nGitFlow: how to directly contribute code to the package in an organized way on GitHub.\nDevelopment Details: how the internals of the package are currently setup if you would like to directly contribute code.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Please also see the Attribution to learn about the authors and sources of support for the project.","category":"page"},{"location":"man/contributing/#Issues","page":"Contributing","title":"Issues","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The main point of contact is the GitHub issues page for the project. This is the easiest way to contribute to the project, as any issue you find or request you have will be addressed there by the authors of the package. Depending on the issue, the authors will collaborate with you, and after making changes they will link a pull request which addresses your concern or implements your proposed changes.","category":"page"},{"location":"man/contributing/#Julia-Development","page":"Contributing","title":"Julia Development","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"As a Julia package, development follows the usual procedure:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Clone the project from GitHub\nSwitch to or create the branch that you wish work on (see GitFlow).\nStart Julia at your development folder.\nInstantiate the package (i.e., download and install the package dependencies).","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"For example, you can get the package and startup Julia with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"git clone git@github.com:AP6YC/AdaptiveResonance.jl.git\njulia --project=.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"note: Note\nIn Julia, you must activate your project in the current REPL to point to the location/scope of installed packages. The above immediately activates the project when starting up Julia, but you may also separately startup the julia and activate the package with the interactive package manager via the ] syntax:julia\njulia> ]\n(@v.10) pkg> activate .\n(AdaptiveResonance) pkg>","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"You may run the package's unit tests after the above setup in Julia with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"julia> using Pkg\njulia> Pkg.instantiate()\njulia> Pkg.test()","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"or interactively though the Julia package manager with","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"julia> ]\n(AdaptiveResonance) pkg> instantiate\n(AdaptiveResonance) pkg> test","category":"page"},{"location":"man/contributing/#GitFlow","page":"Contributing","title":"GitFlow","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The AdaptiveResonance.jl package follows the GitFlow git working model. The original post by Vincent Driessen outlines this methodology quite well, while Atlassian has a good tutorial as well. In summary:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Create a feature branch off of the develop branch with the name feature/<my-feature-name>.\nCommit your changes and push to this feature branch.\nWhen you are satisfied with your changes, initiate a GitHub pull request (PR) to merge the feature branch with develop.\nIf the unit tests pass, the feature branch will first be merged with develop and then be deleted.\nReleases will be periodically initiated from the develop branch and versioned onto the master branch.\nImmediate bug fixes circumvent this process through a hotfix branch off of master.","category":"page"},{"location":"man/contributing/#Development-Details","page":"Contributing","title":"Development Details","text":"","category":"section"},{"location":"man/contributing/#Documentation","page":"Contributing","title":"Documentation","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"These docs are currently hosted as a static site on the GitHub pages platform. They are setup to be built and served in a separate branch called gh-pages from the master/development branches of the project.","category":"page"},{"location":"man/contributing/#Package-Structure","page":"Contributing","title":"Package Structure","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The AdaptiveResonance.jl package has the following file structure:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"AdaptiveResonance\n├── .github/workflows       // GitHub: workflows for testing and documentation.\n├── docs                    // Docs: documentation for the module.\n│   └───src                 //      Documentation source files.\n├── examples                // Source: example usage scripts.\n├── src                     // Source: majority of source code.\n│   ├───ART                 //      ART-based unsupervised modules.\n│   │   ├───distributed     //      Distributed ART modules.\n│   │   └───single          //      Undistributed ART modules.\n│   └───ARTMAP              //      ARTMAP-based supervised modules.\n├── test                    // Test: Unit, integration, and environment tests.\n│   ├── adaptiveresonance   //      Tests common to the entire package.\n│   ├── art                 //      Tests for just ART modules.\n│   ├── artmap              //      Tests for just ARTMAP modules.\n│   └───data                //      CI test data.\n├── .appveyor               // Appveyor: Windows-specific coverage.\n├── .gitattributes          // Git: LFS settings, languages, etc.\n├── .gitignore              // Git: .gitignore for the whole project.\n├── CODE_OF_CONDUCT.md      // Doc: the code of conduct for contributors.\n├── CONTRIBUTING.md         // Doc: contributing guide (points to this page).\n├── LICENSE                 // Doc: the license to the project.\n├── Project.toml            // Julia: the Pkg.jl dependencies of the project.\n└── README.md               // Doc: this document.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"ART and ARTMAP algorithms are put into their own files within the src/ART/ and src/ARTMAP/ directories, respectively. Both of these directories have an \"index\" file where each module is \"included\" (i.e., src/ART/ART.jl), which is in turn \"included\" in the package module file src/AdaptiveResonance.jl.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Abstract types and common structures/methods are included at the top of the package module file. All public methods and structs (i.e., for the end user) are \"exported\" at the end of this file.","category":"page"},{"location":"man/contributing/#ART-Module-Workflow","page":"Contributing","title":"ART Module Workflow","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"To write an ART module for this project, it will require the following:","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"A train! and classify method (within the module).\nAn keyword-options struct using the Parameters.jl macro @with_kw with assertions to keep the parameters within correct ranges.\nThree constructors:\nAn empty constructor (i.e. DDVFA()).\nA keyword argument constructor (passing the kwargs to the options struct defined above).\nA constructor with the options struct passed itself.\nUse of common type aliases in method definitions.\nAn internal DataConfig for setting up the data configuration, especially with data_setup! (src/common.jl).\nAn update_iter evaluation for each iteration (src/common.jl).\nInclusion to the correct ART index file (i.e., src/ART/ART.jl).\nExports of the names for the options and types in the top-level module definition (src/AdaptiveResonance.jl).","category":"page"},{"location":"man/contributing/#DataConfig","page":"Contributing","title":"DataConfig","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"The original implementation of ART1 uses binary vectors, which have guaranteed separation between distinct vectors. Real-valued ART modules, however, face the problem of permitting vectors to be arbitrarily close to one another. Therefore, nearly every real-valued ART module uses [0, 1] normalization and complement-coding. This is reflected in the DataConfig struct in the common file src/common.jl.","category":"page"},{"location":"man/contributing/#Type-Aliases","page":"Contributing","title":"Type Aliases","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"For convenience in when defining types and function signatures, this package uses the NumericalTypeAliases.jl package and the aliases therein. The documentation for the abstract and concrete types provided by NumericalTypeAliases.jl can be found here.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"In this package, data samples are always Real-valued (with the notable exception of ART1), while class labels are integered. Furthermore, independent class labels are always Int because of the Julia native support for a given system's signed native integer type.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This project does not currently test for the support of arbitrary precision arithmetic because learning algorithms in general do not have a significant need for precision.","category":"page"},{"location":"man/contributing/#Attribution","page":"Contributing","title":"Attribution","text":"","category":"section"},{"location":"man/contributing/#Authors","page":"Contributing","title":"Authors","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This package is developed and maintained by Sasha Petrenko with sponsorship by the Applied Computational Intelligence Laboratory (ACIL). The users @aaronpeikert, @hayesall, and @markNZed have graciously contributed their time with reviews and feedback that has greatly improved the project.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"If you simply have suggestions for improvement, Sasha Petrenko (<sap625@mst.edu>) is the current developer and maintainer of the AdaptiveResonance.jl package, so please feel free to reach out with thoughts and questions.","category":"page"},{"location":"man/contributing/#Support","page":"Contributing","title":"Support","text":"","category":"section"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"This project is supported by grants from the Night Vision Electronic Sensors Directorate, the DARPA Lifelong Learning Machines (L2M) program, Teledyne Technologies, and the National Science Foundation. The material, findings, and conclusions here do not necessarily reflect the views of these entities.","category":"page"},{"location":"man/contributing/","page":"Contributing","title":"Contributing","text":"Research was sponsored by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-22-2-0209. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.","category":"page"},{"location":"man/guide/#Package-Guide","page":"Guide","title":"Package Guide","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance.jl package is built upon ART modules that contain all of the state information during training and inference. The ART modules are driven by options, which are themselves mutable keyword argument structs from the Parameters.jl package.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To work with AdaptiveResonance.jl, you should know:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"How to install the package\nART module basics\nHow to use ART module options\nART vs. ARTMAP\nART stats logging","category":"page"},{"location":"man/guide/#installation","page":"Guide","title":"Installation","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance package can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"julia> ]\n(@v.10) pkg> add AdaptiveResonance","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Alternatively, it can be added to your environment in a script with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"using Pkg\nPkg.add(\"AdaptiveResonance\")","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you wish to have the latest changes between releases, you can directly add the GitHub repo at an arbitrary branch (such as develop) as a dependency with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"julia> ]\n(@v.10) pkg> add https://github.com/AP6YC/AdaptiveResonance.jl#develop","category":"page"},{"location":"man/guide/#art_modules","page":"Guide","title":"ART Modules","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To work with ART modules, you should know:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Their basic methods\nIncremental vs. batch modes\nSupervised vs. unsupervised learning modes\nMismatch vs. Best-Matching-Unit","category":"page"},{"location":"man/guide/#methods","page":"Guide","title":"Methods","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Every ART module is equipped with several constructors, a training function train!, and a classification/inference function classify. ART models are mutable structs, and they can be instantiated with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"art = DDVFA()","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For more ways to customize instantiation, see the ART options section.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"To train and test these models, you use the train! and classify functions upon the models. Because training changes the internal parameters of the ART models and classification does not, train! uses an exclamation point while classify does not, following Julia standard usage.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, we may load data of some sort and train/test like so:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Load the data from some source with a train/test split\ntrain_x, train_y, test_x, test_y = load_some_data()\n\n# Instantiate an arbitrary ART module\nart = DDVFA()\n\n# Train the module on the training data, getting the prescribed cluster labels\ny_hat_train = train!(art, train_x)\n\n# Conduct inference\ny_hat_test = classify(art, test_x)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nBecause Julia arrays are column-major in memory, the AdaptiveResonance.jl package follows the Julia convention of assuming 2-D data arrays are in the shape of (n_features, n_samples).","category":"page"},{"location":"man/guide/#incremental_vs_batch","page":"Guide","title":"Incremental vs. Batch","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This training and testing may be done in either incremental or batch modes:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create a destination container for the incremental examples\nn_train = length(train_y)\nn_test = length(test_y)\ny_hat_train_incremental = zeros(Integer, n_train)\ny_hat_test_incremental = zeros(Integer, n_test)\n\n# Loop over all training samples\nfor i = 1:n_train\n    y_hat_train_incremental[i] = train!(art, train_x[:, i])\nend\n\n# loop over all testing samples\nfor i = 1:n_test\n    y_hat_test_incremental[i] = classify(art, test_x[:, i])\nend","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This is done through checking the dimensionality of the inputs. For example, if a matrix (i.e., 2-D array) is passed to the train! function, then the data is assumed to be (n_features, n_samples), and the module is trained on all samples. However, if the data is a vector (i.e., 1-D array), then the vector is interpreted as a single sample.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"When supervised (see supervised vs. unsupervised), the dimensions of the labels must correspond to the dimensions of the data. For example, a 2-D matrix of the data must accompany a 1-D vector of labels, while a 1-D vector of a single data sample must accompany a single integer label.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Batch and incremental modes can be used interchangably after module instantiation.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nThe first time that an ART module is trained, it infers the data parameters (e.g., feature dimensions, feature ranges, etc.) to setup the internal data configuration. This happens automatically in batch mode, but it cannot happen if the module is only trained incrementally. If you know the dimensions and minimum/maximum values of the features and want to train incrementally, you can use the function data_setup! after module instantiation, which can be used a number of ways. If you have the batch data available, you can set up with# Manually setup the data config with the data itself\ndata_setup!(art, data.train_x)If you do not have the batch data available, you can directly create a DataConfig with the minimums and maximums (inferring the number of features from the lengths of these vectors):# Get the mins and maxes vectors with some method\nmins, maxes = get_some_data_mins_maxes()\n\n# Directly update the data config\nart.config = DataConfig(mins, maxes)If all of the features share the same minimums and maximums, then you can use them as long as you specify the number of features:# Get the global minimum, maximum, and feature dimension somehow\nmin, max, dim = get_some_data_characteristics()\n\n# Directly update the data config with these global values\nart.config = DataConfig(min, max, dim)","category":"page"},{"location":"man/guide/#supervised_vs_unsupervised","page":"Guide","title":"Supervised vs. Unsupervised","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"ARTMAP modules require a supervised label argument because their formulations typically map internal cluster categories to labels:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create an arbitrary ARTMAP module\nartmap = DAM()\n\n# Conduct supervised learning\ny_hat_train = train!(artmap, train_x, train_y)\n\n# Conduct inference\ny_hat_test = classify(artmap, test_x)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"In the case of ARTMAP, the returned training labels y_hat_train will always match the training labels train_y by definition. In addition to the classification accuracy (ranging from 0 to 1), you can test that the training labels match with the function performance:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Verify that the training labels match\nperf_train = performance(y_hat_train, train_y)\n\n# Get the classification accuracy\nperf_test = performance(y_hat_test, test_y)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"However, many ART modules, though unsupervised by definition, can also be trained in a supervised way by naively mapping categories to labels (more in ART vs. ARTMAP).","category":"page"},{"location":"man/guide/#mismatch-bmu","page":"Guide","title":"Mismatch vs. Best-Matching-Unit","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"During inference, ART algorithms report the category that satisfies the match/vigilance criterion (see Background). By default, in the case that no category satisfies this criterion the module reports a mismatch as -1. In modules that support it, a keyword argument get_bmu (default is false) can be used in the classify method to get the \"best-matching unit\", which is the category that maximizes the activation. This can be interpreted as the \"next-best guess\" of the model in the case that the sample is sufficiently different from anything that the model has seen. For example,","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Conduct inference, getting the best-matching unit in case of complete mismatch\ny_hat_bmu = classify(my_art, test_x, get_bmu=true)","category":"page"},{"location":"man/guide/#art_options","page":"Guide","title":"ART Options","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This section contains:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"An overview of ART options\nA summary of all available options\nAdvanced activation, match, and update usage","category":"page"},{"location":"man/guide/#art_options_overview","page":"Guide","title":"Options Overview","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The AdaptiveResonance package is designed for maximum flexibility for scientific research, even though this may come at the cost of learning instability if misused. Because of the diversity of ART modules, the package is structured around instantiating separate modules and using them for training and inference. Due to this diversity, each module has its own options struct with keyword arguments. These options have default values driven by standards in their respective literatures, so the ART modules may be used immediately without any customization. Furthermore, these options are mutable, so they may be modified before module instantiation, before training, or even after training.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, you can get going with the default options by creating an ART module with the default constructor:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA()","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you want to change the parameters before construction, you can create an options struct, modify it, then instantiate your ART module with it:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art_opts = opts_DDVFA()\nmy_art_opts.gamma = 3\nmy_art = DDVFA(my_art_opts)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"The options are objects from the Parameters.jl project, so they can be instantiated even with keyword arguments:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art_opts = opts_DDVFA(gamma = 3)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"You can also pass these keyword arguments directly to the ART model when constructing it with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA(gamma = 3)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"You can even modify the parameters on the fly after the ART module has been instantiated by directly modifying the options within the module:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_art = DDVFA()\nmy_art.opts.gamma = 3","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Because of the @assert feature of the Parameters.jl package, each parameter is forced to lie within certain bounds by definition in the literature during options instantiation. However, it is possible to change these parameter values beyond their predefined bounds after instantiation.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"note: Note\nYou must be careful when changing option values during or after training, as it may result in some undefined behavior. Modify the ART module options after instantiation at your own risk and discretion.","category":"page"},{"location":"man/guide/#art_options_summary","page":"Guide","title":"ART Options Summary","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Though most parameters differ between each ART and ARTMAP module, they all share some quality-of-life options and parameters shared by all ART algorithms:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"display::Bool: a flag to display or suppress progress bars and logging messages during training and testing.\nmax_epochs::Int: the maximum number of epochs to train over the data, regardless if other stopping conditions have not been met yet.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Otherwise, most ART and ARTMAP modules share the following nomenclature for algorithmic parameters:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"rho::Float: ART vigilance parameter [0, 1].\nalpha::Float: Choice parameter > 0.\nbeta::Float: Learning parameter (0, 1].\nepsilon::Float: Match tracking parameter (0, 1).\nmatch::Symbol: A symbolic name of the match function used (i.e., :basic_match). Valid names are listed in MATCH_FUNCTIONS.\nactivation::Symbol: A symbolic name of the activation function used (i.e., :basic_activation). Valid names are listed in ACTIVATION_FUNCTIONS.\nupdate::Symbol: A symbolic name of the weight update function used (i.e., :basic_update). Valid names are listed in UPDATE_FUNCTIONS.","category":"page"},{"location":"man/guide/#art_activation_match_update_functions","page":"Guide","title":"ART Activation, Match, and Update Functions","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Though their implementations may vary, all ART and ARTMAP modules require the computation of a match function, and activation function, and a method of updating weights when learning. Both ART and ARTMAP modules can now swap out their activation, match, and update functions thanks to Julia's metaprogramming capabilities. This is done by setting the match, activation, or update options of the ART options struct with a symbol of the function to use, such as with","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"my_opts = opts_FuzzyART(match=:choice_by_difference, activation=:basic_activation, update=:basic_update)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"A list of all available activation, match, and update functions is provided in the ACTIVATION_FUNCTIONS, [MATCH_FUNCTIONS], and UPDATE_FUNCTIONS constants, respectively.","category":"page"},{"location":"man/guide/#art_vs_artmap","page":"Guide","title":"ART vs. ARTMAP","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"ART modules are generally unsupervised in formulation, so they do not explicitly require supervisory labels to their training examples. However, many of these modules can be formulated in the simplified ARTMAP style whereby the ART B module has a vigilance parameter of 1, directly mapping the categories of the ART A module to any provided supervisory labels.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This is done in the training stage through the optional keyword argument y=...:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create an arbitrary ART module\nart = DDVFA()\n\n# Naively prescribe supervised labels to cluster categories\ny_hat_train = train!(art, train_x, y=train_y)","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"This can also be done incrementally with the same function:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Get the number of training samples and create a results container\nn_train = length(train_y)\ny_hat_train_incremental = zeros(Int, n_train)\n\n# Train incrementally over all training samples\nfor i = 1:n_train\n    y_hat_train_incremental[i] = train!(art, train_x[:, i], y=train_y[i])\nend","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"Without provided labels, the ART modules behave as expected, incrementally creating categories when necessary during the training phase.","category":"page"},{"location":"man/guide/#art_stats","page":"Guide","title":"ART Stats Logging","text":"","category":"section"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"If you are curious about what the activation and match values were after either incremental training or classifiation, all ART modules implement basic statistics dictionaries in their stats field with the following entries:","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"T: the activation value of the most recent winning node (i.e., the best-matching unit).\nM: the match value of the most recent winning node.\nbmu: the integer index of the best-matching unit.\nmismatch: whether a mismatch occurred during the most recent training/classification iteration.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"These fields are useful if you wish to know the degree to which a sample is recognized by your ART module and agrees with its understanding of the data.","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"For example, you may train a model on some random data (rather inneffectually, but simply for illustration purposes):","category":"page"},{"location":"man/guide/","page":"Guide","title":"Guide","text":"# Create a FuzzyART module with default options\nmy_art = FuzzyART()\n# Use three feature dimensions\ndim = 3\n# Create ten random samples\nn_samples = 10\n# Create random features and integer labels\nfeatures = rand(dim, n_samples)\nlabels = rand(1:3, n_samples)\n# Train the module in simple supervised mode\ntrain!(my_art, features, y=labels)\n# See what the activation and match values were for the last sample\nT_bmu = my_art.stats[\"T\"]\nM_bmu = my_art.stats[\"M\"]\n# We can also see which node was the best-matching unit and whether mismatch occured\nbmu_index = my_art.stats[\"bmu\"]\nmismatch_flag = my_art.stats[\"mismatch\"]","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/art/ddvfa_supervised.jl\"","category":"page"},{"location":"examples/art/ddvfa_supervised/#ddvfa_supervised","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"","category":"section"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"DDVFA is an unsupervised clustering algorithm by definition, but it can be adaptived for supervised learning by mapping the module's internal categories to the true labels. ART modules such as DDVFA can also be used in simple supervised mode where provided labels are used in place of internal incremental labels for the clusters, providing a method of assessing the clustering performance when labels are available.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"(([5.6 6.0 5.0 5.0 7.0 6.7 4.8 4.3 5.8 5.9 5.6 6.7 6.1 6.3 5.1 5.1 7.4 4.9 6.3 5.0 6.4 5.9 4.9 6.2 5.4 5.2 6.4 5.8 5.2 5.7 5.6 6.9 5.5 5.2 5.0 5.0 4.4 6.7 5.7 7.7 5.1 6.1 5.7 4.8 5.8 7.7 4.9 6.4 6.0 4.7 7.1 5.9 6.1 5.4 6.5 6.4 4.7 6.2 6.8 6.3 5.5 6.8 7.7 6.3 5.8 5.8 5.7 4.9 6.7 5.0 6.3 6.4 6.0 5.1 5.4 4.4 4.6 6.7 5.5 5.0 4.8 6.6 4.8 5.5 6.3 6.9 6.7 6.0 5.6 4.9 6.0 5.5 4.4 5.2 4.6 7.6 6.3 5.7 5.7 7.3 5.1 6.5 5.1 6.7 7.9; 2.5 3.0 3.4 3.6 3.2 3.1 3.0 3.0 2.6 3.0 2.8 3.3 2.8 3.3 3.3 3.8 2.8 3.1 2.5 3.5 3.2 3.2 3.0 2.2 3.7 4.1 3.1 2.7 3.4 2.8 2.7 3.1 2.5 3.5 3.3 3.5 2.9 2.5 3.0 2.6 3.5 2.8 4.4 3.4 2.7 3.8 2.5 2.9 2.2 3.2 3.0 3.0 2.6 3.4 3.2 2.8 3.2 2.8 3.2 3.4 2.4 3.0 2.8 2.3 2.7 2.8 2.6 2.4 3.1 2.0 2.9 2.7 2.9 3.4 3.0 3.2 3.2 3.0 2.4 3.0 3.4 2.9 3.0 4.2 3.3 3.1 3.3 3.4 3.0 3.1 2.7 2.3 3.0 2.7 3.6 3.0 2.7 3.8 2.9 2.9 3.8 3.0 3.5 3.0 3.8; 3.9 4.8 1.6 1.4 4.7 5.6 1.4 1.1 4.0 5.1 4.9 5.7 4.7 4.7 1.7 1.9 6.1 1.5 5.0 1.6 4.5 4.8 1.4 4.5 1.5 1.5 5.5 4.1 1.4 4.5 4.2 4.9 4.0 1.5 1.4 1.3 1.4 5.8 4.2 6.9 1.4 4.0 1.5 1.9 5.1 6.7 4.5 4.3 5.0 1.3 5.9 4.2 5.6 1.7 5.1 5.6 1.6 4.8 5.9 5.6 3.7 5.5 6.7 4.4 3.9 5.1 3.5 3.3 4.4 3.5 5.6 5.3 4.5 1.5 4.5 1.3 1.4 5.2 3.8 1.6 1.6 4.6 1.4 1.4 6.0 5.4 5.7 4.5 4.5 1.5 5.1 4.0 1.3 3.9 1.0 6.6 4.9 1.7 4.2 6.3 1.5 5.5 1.4 5.0 6.4; 1.1 1.8 0.4 0.2 1.4 2.4 0.3 0.1 1.2 1.8 2.0 2.5 1.2 1.6 0.5 0.4 1.9 0.1 1.9 0.6 1.5 1.8 0.2 1.5 0.2 0.1 1.8 1.0 0.2 1.3 1.3 1.5 1.3 0.2 0.2 0.3 0.2 1.8 1.2 2.3 0.2 1.3 0.4 0.2 1.9 2.2 1.7 1.3 1.5 0.2 2.1 1.5 1.4 0.2 2.0 2.1 0.2 1.8 2.3 2.4 1.0 2.1 2.0 1.3 1.2 2.4 1.0 1.0 1.4 1.0 1.8 1.9 1.5 0.2 1.5 0.2 0.2 2.3 1.1 0.2 0.2 1.3 0.1 0.2 2.5 2.1 2.1 1.6 1.5 0.1 1.6 1.3 0.2 1.4 0.2 2.1 1.8 0.3 1.3 1.8 0.3 1.8 0.3 1.7 2.0], [2, 3, 1, 1, 2, 3, 1, 1, 2, 3, 3, 3, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 1, 2, 1, 1, 3, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 3, 2, 3, 1, 2, 1, 1, 3, 3, 3, 2, 3, 1, 3, 2, 3, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 3, 3, 2, 1, 2, 1, 1, 3, 2, 1, 1, 2, 1, 1, 3, 3, 3, 2, 2, 1, 2, 2, 1, 2, 1, 3, 3, 1, 2, 3, 1, 3, 1, 2, 3]), ([6.8 6.5 6.5 5.0 5.0 5.7 4.8 5.0 5.8 6.1 4.5 6.2 6.3 5.6 5.4 5.5 6.7 6.5 5.5 5.6 6.9 5.3 5.4 5.1 5.1 6.3 6.6 6.9 6.4 6.4 7.2 5.1 7.7 6.1 5.8 6.0 4.6 6.2 4.6 4.9 6.1 7.2 7.2 5.7 5.4; 2.8 3.0 3.0 3.2 3.4 2.8 3.1 2.3 2.7 3.0 2.3 3.4 2.8 3.0 3.9 3.5 3.1 2.8 2.6 2.9 3.2 3.7 3.4 3.8 3.7 2.5 3.0 3.1 3.2 2.8 3.2 2.5 3.0 2.9 4.0 2.2 3.1 2.9 3.4 3.1 3.0 3.0 3.6 2.5 3.9; 4.8 5.2 5.8 1.2 1.5 4.1 1.6 3.3 5.1 4.6 1.3 5.4 5.1 4.1 1.3 1.3 4.7 4.6 4.4 3.6 5.7 1.5 1.5 1.6 1.5 4.9 4.4 5.1 5.3 5.6 6.0 3.0 6.1 4.7 1.2 4.0 1.5 4.3 1.4 1.5 4.9 5.8 6.1 5.0 1.7; 1.4 2.0 2.2 0.2 0.2 1.3 0.2 1.0 1.9 1.4 0.3 2.3 1.5 1.3 0.4 0.2 1.5 1.5 1.2 1.3 2.3 0.2 0.4 0.2 0.4 1.5 1.4 2.3 2.3 2.2 1.8 1.1 2.3 1.4 0.2 1.0 0.2 1.3 0.3 0.1 1.8 1.6 2.5 2.0 0.4], [2, 3, 3, 1, 1, 2, 1, 2, 3, 2, 1, 3, 3, 2, 1, 1, 2, 2, 2, 2, 3, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 2, 3, 2, 1, 2, 1, 2, 1, 1, 3, 3, 3, 3, 1]))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Now, we can create our DDVFA module. We'll do so with the default contstructor, though the module itself has many options that you can alter during instantiation.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"art = DDVFA()","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.7\n  rho_ub: Float64 0.85\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.85\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We can train the model in batch mode upon the data in a simple supervised mode. We do so by passing the integer vector of labels to the training method with the simple keyword y. Just as in unsupervised training, we can extract the module's prescribed labels from the training method, which should match up to the training labels as we will see later.","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Train in simple supervised mode by passing the labels as a keyword argument.\ny_hat_train = train!(art, X_train, y=y_train)\nprintln(\"Training labels: \",  size(y_hat_train), \" \", typeof(y_hat_train))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"We can classify the testing data to see how we generalize. At the same time, we can see the effect of getting the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Classify both ways\ny_hat = AdaptiveResonance.classify(art, X_test)\ny_hat_bmu = AdaptiveResonance.classify(art, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"Testing labels: \",  size(y_hat), \" \", typeof(y_hat))\nprintln(\"Testing labels with bmu: \",  size(y_hat_bmu), \" \", typeof(y_hat_bmu))","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Testing labels: (45,) Vector{Int64}\nTesting labels with bmu: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Finally, we can calculate the performances (number correct over total) of the model upon all three regimes:","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training data\nTesting data\nTesting data with get_bmu=true","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train = performance(y_hat_train, y_train)\nperf_test = performance(y_hat, y_test)\nperf_test_bmu = performance(y_hat_bmu, y_test)\n\n# Format each performance number for comparison\n@printf \"Training performance: %.4f\\n\" perf_train\n@printf \"Testing performance: %.4f\\n\" perf_test\n@printf \"Best-matching unit testing performance: %.4f\\n\" perf_test_bmu","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"Training performance: 1.0000\nTesting performance: 1.0000\nBest-matching unit testing performance: 1.0000\n","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"","category":"page"},{"location":"examples/art/ddvfa_supervised/","page":"Supervised DDVFA Example","title":"Supervised DDVFA Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"man/modules/#modules-page","page":"Modules","title":"Modules","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This project implements a number of ART-based models with options that modulate their behavior (see the options section of the Guide)","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This page lists both the implemented models and some of their variants","category":"page"},{"location":"man/modules/#Implemented-Models","page":"Modules","title":"Implemented Models","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"This project has implementations of the following ART (unsupervised) and ARTMAP (supervised) modules:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"CurrentModule=AdaptiveResonance","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"ART\nFuzzyART: Fuzzy ART\nDVFA: Dual Vigilance Fuzzy ART\nDDVFA: Distributed Dual Vigilance Fuzzy ART\nARTMAP\nSFAM: Simplified Fuzzy ARTMAP\nFAM: Fuzzy ARTMAP","category":"page"},{"location":"man/modules/#modules-variants","page":"Modules","title":"Variants","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Each module contains many options that modulate its behavior. Some of these options are used to modulate the internals of the module, such as switching the match and activation functions, to achieve different modules that are found in the literature.","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"These variants are:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"ART\nGammaNormalizedFuzzyART: Gamma-Normalized FuzzyART\nARTMAP\nDAM: Default ARTMAP","category":"page"},{"location":"man/modules/#Gamma-Normalized-FuzzyART","page":"Modules","title":"Gamma-Normalized FuzzyART","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"A Gamma-Normalized FuzzyART is implemented as a FuzzyART module where the gamma normalization option is set on gamma_normalization=true and the kernel width parameter is set to gamma = 10 (gamma_ref is 1.0 by default). It can be created with the convenience constructor:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_gnfa = GammaNormalizedFuzzyART()","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Under the hood, this simply does","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_gnfa = FuzzyART(gamma_normalization=true)","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"which also sets the match and activation function options to match=:gamma_match and activation=:gamma_activation, respectively.","category":"page"},{"location":"man/modules/#Default-ARTMAP","page":"Modules","title":"Default ARTMAP","text":"","category":"section"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"A Default ARTMAP is implemented as a Simplified FuzzyARTMAP module where the activation function is set to Default ARTMAP's choice-by difference function via activation=:choice_by_difference. It can be created with the convenience constructor:","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_dam = DAM()","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"Under the hood, this simply does","category":"page"},{"location":"man/modules/","page":"Modules","title":"Modules","text":"my_dam = SFAM(activation=:choice_by_difference)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/art/ddvfa_unsupervised.jl\"","category":"page"},{"location":"examples/art/ddvfa_unsupervised/#ddvfa_unsupervised","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"","category":"section"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"DDVFA is an unsupervised clustering algorithm by definition, so it can be used to cluster a set of samples all at once in batch mode.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for loading some data.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Extract the features into a local variable\nfeatures = iris.features","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"4×150 Matrix{Float64}:\n 5.1  4.9  4.7  4.6  5.0  5.4  4.6  5.0  4.4  4.9  5.4  4.8  4.8  4.3  5.8  5.7  5.4  5.1  5.7  5.1  5.4  5.1  4.6  5.1  4.8  5.0  5.0  5.2  5.2  4.7  4.8  5.4  5.2  5.5  4.9  5.0  5.5  4.9  4.4  5.1  5.0  4.5  4.4  5.0  5.1  4.8  5.1  4.6  5.3  5.0  7.0  6.4  6.9  5.5  6.5  5.7  6.3  4.9  6.6  5.2  5.0  5.9  6.0  6.1  5.6  6.7  5.6  5.8  6.2  5.6  5.9  6.1  6.3  6.1  6.4  6.6  6.8  6.7  6.0  5.7  5.5  5.5  5.8  6.0  5.4  6.0  6.7  6.3  5.6  5.5  5.5  6.1  5.8  5.0  5.6  5.7  5.7  6.2  5.1  5.7  6.3  5.8  7.1  6.3  6.5  7.6  4.9  7.3  6.7  7.2  6.5  6.4  6.8  5.7  5.8  6.4  6.5  7.7  7.7  6.0  6.9  5.6  7.7  6.3  6.7  7.2  6.2  6.1  6.4  7.2  7.4  7.9  6.4  6.3  6.1  7.7  6.3  6.4  6.0  6.9  6.7  6.9  5.8  6.8  6.7  6.7  6.3  6.5  6.2  5.9\n 3.5  3.0  3.2  3.1  3.6  3.9  3.4  3.4  2.9  3.1  3.7  3.4  3.0  3.0  4.0  4.4  3.9  3.5  3.8  3.8  3.4  3.7  3.6  3.3  3.4  3.0  3.4  3.5  3.4  3.2  3.1  3.4  4.1  4.2  3.1  3.2  3.5  3.1  3.0  3.4  3.5  2.3  3.2  3.5  3.8  3.0  3.8  3.2  3.7  3.3  3.2  3.2  3.1  2.3  2.8  2.8  3.3  2.4  2.9  2.7  2.0  3.0  2.2  2.9  2.9  3.1  3.0  2.7  2.2  2.5  3.2  2.8  2.5  2.8  2.9  3.0  2.8  3.0  2.9  2.6  2.4  2.4  2.7  2.7  3.0  3.4  3.1  2.3  3.0  2.5  2.6  3.0  2.6  2.3  2.7  3.0  2.9  2.9  2.5  2.8  3.3  2.7  3.0  2.9  3.0  3.0  2.5  2.9  2.5  3.6  3.2  2.7  3.0  2.5  2.8  3.2  3.0  3.8  2.6  2.2  3.2  2.8  2.8  2.7  3.3  3.2  2.8  3.0  2.8  3.0  2.8  3.8  2.8  2.8  2.6  3.0  3.4  3.1  3.0  3.1  3.1  3.1  2.7  3.2  3.3  3.0  2.5  3.0  3.4  3.0\n 1.4  1.4  1.3  1.5  1.4  1.7  1.4  1.5  1.4  1.5  1.5  1.6  1.4  1.1  1.2  1.5  1.3  1.4  1.7  1.5  1.7  1.5  1.0  1.7  1.9  1.6  1.6  1.5  1.4  1.6  1.6  1.5  1.5  1.4  1.5  1.2  1.3  1.5  1.3  1.5  1.3  1.3  1.3  1.6  1.9  1.4  1.6  1.4  1.5  1.4  4.7  4.5  4.9  4.0  4.6  4.5  4.7  3.3  4.6  3.9  3.5  4.2  4.0  4.7  3.6  4.4  4.5  4.1  4.5  3.9  4.8  4.0  4.9  4.7  4.3  4.4  4.8  5.0  4.5  3.5  3.8  3.7  3.9  5.1  4.5  4.5  4.7  4.4  4.1  4.0  4.4  4.6  4.0  3.3  4.2  4.2  4.2  4.3  3.0  4.1  6.0  5.1  5.9  5.6  5.8  6.6  4.5  6.3  5.8  6.1  5.1  5.3  5.5  5.0  5.1  5.3  5.5  6.7  6.9  5.0  5.7  4.9  6.7  4.9  5.7  6.0  4.8  4.9  5.6  5.8  6.1  6.4  5.6  5.1  5.6  6.1  5.6  5.5  4.8  5.4  5.6  5.1  5.1  5.9  5.7  5.2  5.0  5.2  5.4  5.1\n 0.2  0.2  0.2  0.2  0.2  0.4  0.3  0.2  0.2  0.1  0.2  0.2  0.1  0.1  0.2  0.4  0.4  0.3  0.3  0.3  0.2  0.4  0.2  0.5  0.2  0.2  0.4  0.2  0.2  0.2  0.2  0.4  0.1  0.2  0.1  0.2  0.2  0.1  0.2  0.2  0.3  0.3  0.2  0.6  0.4  0.3  0.2  0.2  0.2  0.2  1.4  1.5  1.5  1.3  1.5  1.3  1.6  1.0  1.3  1.4  1.0  1.5  1.0  1.4  1.3  1.4  1.5  1.0  1.5  1.1  1.8  1.3  1.5  1.2  1.3  1.4  1.4  1.7  1.5  1.0  1.1  1.0  1.2  1.6  1.5  1.6  1.5  1.3  1.3  1.3  1.2  1.4  1.2  1.0  1.3  1.2  1.3  1.3  1.1  1.3  2.5  1.9  2.1  1.8  2.2  2.1  1.7  1.8  1.8  2.5  2.0  1.9  2.1  2.0  2.4  2.3  1.8  2.2  2.3  1.5  2.3  2.0  2.0  1.8  2.1  1.8  1.8  1.8  2.1  1.6  1.9  2.0  2.2  1.5  1.4  2.3  2.4  1.8  1.8  2.1  2.4  2.3  1.9  2.3  2.5  2.3  1.9  2.0  2.3  1.8","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Next, we will instantiate a DDVFA module. We could create an options struct for reuse with opts=opts_DDVFA(...), but for now we will use the direct keyword arguments approach.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"art = DDVFA(rho_lb=0.6, rho_ub=0.75)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"To train the module on the training data, we use train!. The train method returns the prescribed cluster labels, which are just what the algorithm believes are unique/separate cluster. This is because we are doing unsupervised learning rather than supervised learning with known labels.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"y_hat_train = train!(art, features)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"150-element Vector{Int64}:\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 2\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 4\n 3\n 4\n 4\n 3\n 4\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 4\n 3\n 3\n 3\n 3\n 4\n 3\n 5\n 3\n 5\n 3\n 5\n 5\n 3\n 5\n 5\n 5\n 3\n 3\n 5\n 3\n 3\n 3\n 5\n 5\n 5\n 3\n 5\n 3\n 5\n 3\n 5\n 5\n 3\n 3\n 5\n 5\n 5\n 5\n 5\n 3\n 3\n 5\n 5\n 3\n 3\n 5\n 5\n 5\n 3\n 5\n 5\n 5\n 3\n 3\n 5\n 3","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Though we could inspect the unique entries in the list above, we can see the number of categories directly from the art module.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"art.n_categories","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"5","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"Because DDVFA actually has FuzzyART modules for F2 nodes, each category has its own category prototypes. We can see the total number of weights in the DDVFA module by summing n_categories across all F2 nodes.","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"total_vec = [art.F2[i].n_categories for i = 1:art.n_categories]\ntotal_cat = sum(total_vec)","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"21","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"","category":"page"},{"location":"examples/art/ddvfa_unsupervised/","page":"Unsupervised DDVFA Example","title":"Unsupervised DDVFA Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/index.md\"","category":"page"},{"location":"examples/#examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"This section contains some examples using the AdaptiveResonance.jl package with topics ranging from how to the internals of package work to practical examples on different datasets.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"These examples are separated into the following sections:","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"AdaptiveResonance: examples exploring the various components of the package, such as how the options structs work and how to train incremental vs batch modes.\nART: examples using ART modules in unsupervised and simple supervised modes.\nARTMAP: examples using ARTMAP modules for supervised learning.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"examples/#AdaptiveResonance","page":"Examples","title":"AdaptiveResonance","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"These examples demonstrate different aspects of usage that are common to all modules in the package, such as incremental vs. batch learning and how to use module options.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how the data configuration object works for data preprocessing in ART modules that require it.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"ART DataConfig Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how to use incremental training methods vs. batch training for all ART modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Incremental vs. Batch Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo illustrates how to use options and modify the options for all ART and ARTMAP modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"ART Options Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/#ART","page":"Examples","title":"ART","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"All ART modules learn in an unsupervised (i.e. clustering) mode by default, but they all can accept labels in the simplified ARTMAP fashion (see the Package Guide).","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use DDVFA for simple supervised learning by clustering Iris samples and mapping the modules internal categories to the true labels.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Supervised DDVFA Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use DDVFA for unsupervised learning by clustering Iris samples.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Unsupervised DDVFA Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/#ARTMAP","page":"Examples","title":"ARTMAP","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"ARTMAP modules are supervised by definition, so they require supervised labels in the training stage. These examples demonstrate different use-cases with ARTMAP modules.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"grid-card-section\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"<div class=\"card grid-card\">\n<div class=\"grid-card-cover\">\n<div class=\"grid-card-description\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"This demo shows how to use a Simplified FuzzyARTMAP (SFAM) module to conduct supervised learning on the Iris dataset.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: card-cover-image)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n<div class=\"grid-card-text\">","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Supervised Simplified FuzzyARTMAP (SFAM) Example","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>\n</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"</div>","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/options.jl\"","category":"page"},{"location":"examples/adaptive_resonance/options/#options","page":"ART Options Example","title":"ART Options Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/options/#Overview","page":"ART Options Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"The AdaptiveResonance.jl package has several ways of handling options for ART modules. These methods are meant to give maximum flexibility to the user for sharing and interpreting options, which themselves vary between each module.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"note: Note\nFor more info on options in ART modules, see the guide in the docs on ART options.","category":"page"},{"location":"examples/adaptive_resonance/options/#ART-Options","page":"ART Options Example","title":"ART Options","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"To get a feel for the ART options system, we will inspect different options and their instantiation methods.","category":"page"},{"location":"examples/adaptive_resonance/options/#Inspection","page":"ART Options Example","title":"Inspection","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"First, we load AdaptiveResonance:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"using AdaptiveResonance","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Every ART module has a default constructor, which can be instantiated in the usual way:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a FuzzyART module with default options\nmy_fuzzyart = FuzzyART()\ntypeof(my_fuzzyart)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Within every ART module is a Parameters.jl struct named opts containing the options for the module","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Check the FuzzyART options\nmy_fuzzyart.opts","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Note that the options here have the type opts_FuzzyART. This nomenclature is used throughout the module to indicate an options type associated with an ART module. For example, the options for a DDVFA module are opts_DDVFA:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a DDVFA module and check the type of the options\nmy_ddvfa = DDVFA()\ntypeof(my_ddvfa.opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_DDVFA","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In fact, we can create an instance of these options with a default constructor:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a separate options struct\nmy_fuzzyart_opts = opts_FuzzyART()","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In addition to the default constructor, we can construct ART modules by instantiating these options and passing them to the module during construction:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Instantiate an ART module by passing our options\nmy_fuzzyart = FuzzyART(my_fuzzyart_opts)\nmy_other_fuzzyart = FuzzyART(my_fuzzyart_opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/#Specifying-Options","page":"ART Options Example","title":"Specifying Options","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now to the good stuff: because of the behavior of the Parameters.jl type, each option has a default value that we can modify during instantiation with keyword arguments:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Change some of the default FuzzyART options\nmy_fuzzyart_opts = opts_FuzzyART(\n    rho=0.6,\n    gamma_normalization=true\n)\nmy_fuzzyart = FuzzyART(my_fuzzyart_opts)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"As some syntactic sugar, we can pass these keyword arguments directly to the module during instantiation if we have no need to share option structs:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Pass these keyword arguments to the module directly\nmy_fuzzyart = FuzzyART(\n    rho=0.6,\n    gamma_normalization=true\n)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.6\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Before training, we can also instantiate the model and alter the options afterward:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"my_fuzzyart = FuzzyART()\nmy_fuzzyart.opts.rho=0.6","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"0.6","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"note: Note\nAll ART modules are designed to use this options struct internally when the parameters are needed. It is possible to change these parameters in the middle of training and evaluation, but some algorithmic instability may occur.","category":"page"},{"location":"examples/adaptive_resonance/options/#Comparison","page":"ART Options Example","title":"Comparison","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"To see the effect that changing these parameters has on the modules, we can train and test them side-by-side.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"using MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing\nusing MultivariateStats # Principal component analysis (PCA)\nusing Plots             # Plotting frontend\ngr()                    # Use the default GR backend explicitly","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Plots.GRBackend()","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"(([5.2 4.7 5.4 6.7 5.1 4.9 4.9 6.3 5.4 4.8 5.9 7.3 6.1 5.2 5.8 4.6 5.0 4.4 5.4 5.9 5.5 6.5 6.9 5.0 5.6 5.7 5.6 4.6 7.2 5.1 7.7 5.2 4.9 6.6 6.7 5.0 5.7 6.5 5.4 6.4 6.4 5.7 6.3 6.9 7.7 5.7 6.0 7.7 6.2 7.4 5.0 6.3 6.7 6.3 5.5 6.4 5.8 6.3 6.0 4.8 5.8 7.2 5.5 5.0 5.7 6.3 5.0 5.1 6.1 5.3 5.1 6.7 5.1 5.4 5.4 6.5 6.8 7.1 7.2 4.9 5.0 6.1 7.0 5.6 6.7 5.1 5.7 6.5 5.1 6.2 6.8 5.9 6.3 4.7 5.8 5.5 4.4 6.4 6.3 7.7 5.6 6.4 5.1 5.7 4.9; 4.1 3.2 3.7 3.1 3.8 2.4 3.0 2.5 3.4 3.0 3.0 2.9 3.0 3.5 2.7 3.4 3.0 3.2 3.9 3.2 2.5 3.0 3.1 3.3 2.7 3.8 2.5 3.2 3.0 2.5 2.8 2.7 3.1 3.0 3.0 2.3 4.4 3.2 3.0 2.7 3.2 2.5 2.9 3.2 3.8 3.0 2.9 3.0 2.9 2.8 3.6 3.3 3.1 2.3 4.2 2.9 2.7 2.7 3.0 3.4 2.6 3.2 2.6 3.5 2.6 3.3 3.4 3.5 3.0 3.7 3.8 3.0 3.4 3.9 3.4 3.0 2.8 3.0 3.6 3.1 3.2 2.8 3.2 3.0 3.3 3.7 2.9 3.0 3.3 2.8 3.2 3.0 3.4 3.2 2.7 2.4 2.9 2.8 2.5 2.6 3.0 3.2 3.5 2.8 2.5; 1.5 1.6 1.5 4.4 1.6 3.3 1.4 5.0 1.5 1.4 5.1 6.3 4.6 1.5 5.1 1.4 1.6 1.3 1.7 4.8 4.0 5.5 4.9 1.4 4.2 1.7 3.9 1.4 5.8 3.0 6.7 3.9 1.5 4.4 5.0 3.3 1.5 5.1 4.5 5.3 5.3 5.0 5.6 5.7 6.7 4.2 4.5 6.1 4.3 6.1 1.4 4.7 5.6 4.4 1.4 4.3 5.1 4.9 4.8 1.9 4.0 6.0 4.4 1.6 3.5 6.0 1.5 1.4 4.9 1.5 1.5 5.2 1.5 1.3 1.7 5.2 4.8 5.9 6.1 1.5 1.2 4.0 4.7 4.5 5.7 1.5 4.2 5.8 1.7 4.8 5.9 4.2 5.6 1.3 3.9 3.7 1.4 5.6 4.9 6.9 4.1 4.5 1.4 4.5 4.5; 0.1 0.2 0.2 1.4 0.2 1.0 0.2 1.9 0.4 0.1 1.8 1.8 1.4 0.2 1.9 0.3 0.2 0.2 0.4 1.8 1.3 1.8 1.5 0.2 1.3 0.3 1.1 0.2 1.6 1.1 2.0 1.4 0.1 1.4 1.7 1.0 0.4 2.0 1.5 1.9 2.3 2.0 1.8 2.3 2.2 1.2 1.5 2.3 1.3 1.9 0.2 1.6 2.4 1.3 0.2 1.3 1.9 1.8 1.8 0.2 1.2 1.8 1.2 0.6 1.0 2.5 0.2 0.3 1.8 0.2 0.3 2.3 0.2 0.4 0.2 2.0 1.4 2.1 2.5 0.1 0.2 1.3 1.4 1.5 2.1 0.4 1.3 2.2 0.5 1.8 2.3 1.5 2.4 0.2 1.2 1.0 0.2 2.1 1.5 2.3 1.3 1.5 0.2 1.3 1.7], [1, 1, 1, 2, 1, 2, 1, 3, 1, 1, 3, 3, 2, 1, 3, 1, 1, 1, 1, 2, 2, 3, 2, 1, 2, 1, 2, 1, 3, 2, 3, 2, 1, 2, 2, 2, 1, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 3, 2, 3, 3, 1, 1, 2, 2, 2, 3, 1, 2, 3, 1, 3, 3, 2, 3, 1, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 3]), ([6.4 6.1 6.7 5.5 6.2 6.0 5.8 7.6 4.3 6.9 5.8 6.4 4.6 5.2 6.7 5.6 6.2 5.6 6.3 5.0 4.6 4.4 6.1 5.1 6.1 7.9 5.5 4.8 6.0 5.5 5.0 6.0 6.7 6.0 6.6 6.5 4.9 5.8 4.8 4.5 5.0 4.8 6.8 6.9 5.7; 3.1 2.8 2.5 2.3 3.4 2.7 2.7 3.0 3.0 3.1 2.8 2.8 3.1 3.4 3.3 2.8 2.2 2.9 2.8 3.4 3.6 3.0 2.9 3.8 2.6 3.8 3.5 3.0 3.4 2.4 3.5 2.2 3.1 2.2 2.9 2.8 3.1 4.0 3.1 2.3 2.0 3.4 3.0 3.1 2.8; 5.5 4.7 5.8 4.0 5.4 5.1 4.1 6.6 1.1 5.1 5.1 5.6 1.5 1.4 5.7 4.9 4.5 3.6 5.1 1.6 1.0 1.3 4.7 1.9 5.6 6.4 1.3 1.4 4.5 3.8 1.3 5.0 4.7 4.0 4.6 4.6 1.5 1.2 1.6 1.3 3.5 1.6 5.5 5.4 4.1; 1.8 1.2 1.8 1.3 2.3 1.6 1.0 2.1 0.1 2.3 2.4 2.2 0.2 0.2 2.5 2.0 1.5 1.3 1.5 0.4 0.2 0.2 1.4 0.4 1.4 2.0 0.2 0.3 1.6 1.1 0.3 1.5 1.5 1.0 1.3 1.5 0.1 0.2 0.2 0.3 1.0 0.2 2.1 2.1 1.3], [3, 2, 3, 2, 3, 2, 2, 3, 1, 3, 3, 3, 1, 1, 3, 3, 2, 2, 3, 1, 1, 1, 2, 1, 3, 3, 1, 1, 2, 2, 1, 3, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 3, 3, 2]))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now we can create several FuzzyART modules with different options.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create two FuzzyARTs with different vigilance values and suppressing logging messages\nrho_1 = 0.5\nrho_2 = 0.7\nmy_fuzzyart_1 = FuzzyART(rho=rho_1, display=false)\nmy_fuzzyart_2 = FuzzyART(rho=rho_2, display=false)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART(opts_FuzzyART\n  rho: Float64 0.7\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool false\n  uncommitted: Bool false\n  activation: Symbol basic_activation\n  match: Symbol basic_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, Int64[], Float64[], Float64[], 0×0 ElasticArrays.ElasticMatrix{Float64, Vector{Float64}}, Int64[], 0, 0, Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Here, we will train these FuzzyART modules in simple supervised mode by passing the supervised labels as a keyword argument:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Train in simple supervised mode by passing the labels as a keyword argument.\ny_hat_train_1 = train!(my_fuzzyart_1, X_train, y=y_train)\ny_hat_train_2 = train!(my_fuzzyart_2, X_train, y=y_train)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"105-element Vector{Int64}:\n 1\n 1\n 1\n 2\n 1\n 2\n 1\n 3\n 1\n 1\n 3\n 3\n 2\n 1\n 3\n 1\n 1\n 1\n 1\n 2\n 2\n 3\n 2\n 1\n 2\n 1\n 2\n 1\n 3\n 2\n 3\n 2\n 1\n 2\n 2\n 2\n 1\n 3\n 2\n 3\n 3\n 3\n 3\n 3\n 3\n 2\n 2\n 3\n 2\n 3\n 1\n 2\n 3\n 2\n 1\n 2\n 3\n 3\n 3\n 1\n 2\n 3\n 2\n 1\n 2\n 3\n 1\n 1\n 3\n 1\n 1\n 3\n 1\n 1\n 1\n 3\n 2\n 3\n 3\n 1\n 1\n 2\n 2\n 2\n 3\n 1\n 2\n 3\n 1\n 3\n 3\n 2\n 3\n 1\n 2\n 2\n 1\n 3\n 2\n 3\n 2\n 2\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We then classify the test data with both modules:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"y_hat_1 = AdaptiveResonance.classify(my_fuzzyart_1, X_test, get_bmu=true)\ny_hat_2 = AdaptiveResonance.classify(my_fuzzyart_2, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"FuzzyART 1 labels: \",  size(y_hat_1), \" \", typeof(y_hat_1))\nprintln(\"FuzzyART 2 labels: \",  size(y_hat_2), \" \", typeof(y_hat_2))\n\n# Calculate the performance on the test data\nperf_test_1 = performance(y_hat_1, y_test)\nperf_test_2 = performance(y_hat_2, y_test)\n\n# Format each performance number for comparison\n@printf \"Testing performance rho=%.1f: %.4f\\n\" rho_1 perf_test_1\n@printf \"Testing performance rho=%.1f: %.4f\\n\" rho_2 perf_test_2","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"FuzzyART 1 labels: (45,) Vector{Int64}\nFuzzyART 2 labels: (45,) Vector{Int64}\nTesting performance rho=0.5: 0.9111\nTesting performance rho=0.7: 0.9333\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"In addition to having different performances, we can see that there is a subsequent trade-off in the number of categories used:","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Print the number of categories for each vigilance parameter\n@printf \"Number of categories rho=%.1f: %i\\n\" rho_1 my_fuzzyart_1.n_categories\n@printf \"Number of categories rho=%.1f: %i\\n\" rho_2 my_fuzzyart_2.n_categories","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Number of categories rho=0.5: 9\nNumber of categories rho=0.7: 13\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"The variation between vigilance parameter, number of categories created during learning, and testing performance/generalization is a central theme in ART-based algorithms.","category":"page"},{"location":"examples/adaptive_resonance/options/#Visualization","page":"ART Options Example","title":"Visualization","text":"","category":"section"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"Now, to visualize how the two models differ in how they partition the data, we can use principal component analysis (PCA) to compress to two plotting dimensions. PCA is a method to represent a dataset in a different number of dimensions while preserving the relative separation between datapoints. Though most datasets are not able to be effectively transformed down to two dimensions, this technique is useful to get a general sense of how well separated the classes are and how well your algorithm classifies them.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Train a PCA model to visually separate the features in two dimensions.\nM = fit(PCA, features; maxoutdim=2)\n\n# Apply the PCA model to the testing set\nX_test_pca = MultivariateStats.transform(M, X_test)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"2×45 Matrix{Float64}:\n -1.90486    -0.920503  -2.31967   -0.180967  -1.90163   -1.37874   -0.234541  -3.39688    3.2252   -1.92245   -1.58527   -2.15874    2.74644   2.63982  -2.41939   -1.1981    -0.942362   0.174864  -1.4431    2.46906   3.21586    2.98184  -0.984045  2.20883   -1.77964   -3.23234  2.62523   2.71567   -0.807205   0.0703429  2.77014   -1.29833   -1.22043   -0.262336  -1.0433    -1.08713     2.67384   2.64354   2.58846    2.85221    0.511086  2.61314    -2.16538  -2.10765   -0.297808\n  0.0480475  -0.18239   -0.245548  -0.825604   0.115877  -0.421205  -0.331922   0.547168  -0.50328   0.409271  -0.539307  -0.218326  -0.311124  0.31929   0.303504  -0.605579  -0.541822  -0.251816  -0.143801  0.137887  0.141616  -0.48025  -0.12436   0.442696  -0.501465   1.37052  0.6068   -0.242681   0.195054  -0.702538   0.271059  -0.761014   0.408035  -0.547893   0.228957   0.0753904  -0.106692  1.18619  -0.197393  -0.932865  -1.26249   0.0215206   0.21528   0.371482  -0.347017","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We can now plot the PCA'ed test set and label them according to the two FuzzyART's We will do so by creating a function for the subplots first as they will share the same format, and we dare not duplicate code. Then, we will plot those subplots side-by-side.","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"# Create a function for our subplots\nfunction fuzzyart_scatter(data, labels, rho)\n    p = scatter(\n        data[1, :],             # PCA dimension 1\n        data[2, :],             # PCA dimension 2\n        group=labels,           # labels belonging to each point\n        markersize=8,           # size of scatter points\n        xlims = [-4, 4],        # manually set the x-limits\n        title=(@sprintf \"FuzzyART \\$\\\\rho\\$ = %.1f\" rho),  # formatted title\n    )\n    return p\nend\n\n# Create the two scatterplot objects\np1 = fuzzyart_scatter(X_test_pca, y_hat_1, rho_1)\np2 = fuzzyart_scatter(X_test_pca, y_hat_2, rho_2)\n\n# Plot the two scatterplots together\nplot(\n    p1, p2,                 # scatterplot objects\n    layout = (1, 2),        # plot side-by-side\n    ##layout = [a, b],        # plot side-by-side\n    legend = false,         # no legend\n    xtickfontsize = 12,     # x-tick size\n    ytickfontsize = 12,     # y-tick size\n    xlabel = \"\\$PCA_1\\$\",   # x-label\n    ylabel = \"\\$PCA_2\\$\",   # y-label\n    dpi = 300,              # Set the dots-per-inch\n)","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip710\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip710)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip711\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip710)\" d=\"M310.676 1405.9 L1152.76 1405.9 L1152.76 123.472 L310.676 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip712\">\n    <rect x=\"310\" y=\"123\" width=\"843\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"521.196,1405.9 521.196,123.472 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"731.716,1405.9 731.716,123.472 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"942.236,1405.9 942.236,123.472 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1152.76,1405.9 1152.76,123.472 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 1152.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"521.196,1405.9 521.196,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"731.716,1405.9 731.716,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"942.236,1405.9 942.236,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1152.76,1405.9 1152.76,1387 \"/>\n<path clip-path=\"url(#clip710)\" d=\"M264.027 1464.66 L308.541 1464.66 L308.541 1470.56 L264.027 1470.56 L264.027 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M342.95 1444.17 L325.242 1471.84 L342.95 1471.84 L342.95 1444.17 M341.11 1438.06 L349.929 1438.06 L349.929 1471.84 L357.325 1471.84 L357.325 1477.68 L349.929 1477.68 L349.929 1489.9 L342.95 1489.9 L342.95 1477.68 L319.547 1477.68 L319.547 1470.91 L341.11 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M476.109 1464.66 L520.623 1464.66 L520.623 1470.56 L476.109 1470.56 L476.109 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M541.803 1484 L566.283 1484 L566.283 1489.9 L533.366 1489.9 L533.366 1484 Q537.359 1479.87 544.234 1472.92 Q551.144 1465.94 552.915 1463.93 Q556.283 1460.14 557.602 1457.54 Q558.956 1454.9 558.956 1452.37 Q558.956 1448.23 556.04 1445.63 Q553.158 1443.03 548.505 1443.03 Q545.206 1443.03 541.526 1444.17 Q537.88 1445.32 533.713 1447.64 L533.713 1440.56 Q537.949 1438.86 541.63 1437.99 Q545.31 1437.12 548.366 1437.12 Q556.421 1437.12 561.213 1441.15 Q566.005 1445.18 566.005 1451.91 Q566.005 1455.11 564.789 1457.99 Q563.609 1460.84 560.449 1464.73 Q559.581 1465.73 554.928 1470.56 Q550.276 1475.35 541.803 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M731.716 1442.68 Q726.299 1442.68 723.556 1448.03 Q720.848 1453.34 720.848 1464.03 Q720.848 1474.69 723.556 1480.04 Q726.299 1485.35 731.716 1485.35 Q737.167 1485.35 739.876 1480.04 Q742.619 1474.69 742.619 1464.03 Q742.619 1453.34 739.876 1448.03 Q737.167 1442.68 731.716 1442.68 M731.716 1437.12 Q740.431 1437.12 745.014 1444.03 Q749.633 1450.91 749.633 1464.03 Q749.633 1477.12 745.014 1484.03 Q740.431 1490.91 731.716 1490.91 Q723.001 1490.91 718.383 1484.03 Q713.799 1477.12 713.799 1464.03 Q713.799 1450.91 718.383 1444.03 Q723.001 1437.12 731.716 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M934.215 1484 L958.694 1484 L958.694 1489.9 L925.778 1489.9 L925.778 1484 Q929.771 1479.87 936.646 1472.92 Q943.555 1465.94 945.326 1463.93 Q948.694 1460.14 950.014 1457.54 Q951.368 1454.9 951.368 1452.37 Q951.368 1448.23 948.451 1445.63 Q945.569 1443.03 940.916 1443.03 Q937.618 1443.03 933.937 1444.17 Q930.292 1445.32 926.125 1447.64 L926.125 1440.56 Q930.361 1438.86 934.042 1437.99 Q937.722 1437.12 940.778 1437.12 Q948.833 1437.12 953.625 1441.15 Q958.416 1445.18 958.416 1451.91 Q958.416 1455.11 957.201 1457.99 Q956.021 1460.84 952.861 1464.73 Q951.993 1465.73 947.34 1470.56 Q942.687 1475.35 934.215 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1157.27 1444.17 L1139.56 1471.84 L1157.27 1471.84 L1157.27 1444.17 M1155.43 1438.06 L1164.25 1438.06 L1164.25 1471.84 L1171.64 1471.84 L1171.64 1477.68 L1164.25 1477.68 L1164.25 1489.9 L1157.27 1489.9 L1157.27 1477.68 L1133.87 1477.68 L1133.87 1470.91 L1155.43 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M693.145 1527.31 Q693.145 1530.92 690.472 1534.24 Q687.831 1537.55 683.515 1539.58 Q679.232 1541.58 674.626 1541.58 L663.419 1541.58 L659.329 1558.07 Q659.296 1558.17 659.2 1558.58 Q659.103 1558.97 659.103 1559.2 Q659.103 1560 660.102 1560.19 Q661.132 1560.39 663.419 1560.39 Q664.9 1560.39 665.126 1560.65 Q665.254 1560.81 665.254 1561.1 Q665.254 1561.55 665.126 1561.87 Q664.997 1562.16 664.739 1562.26 Q664.514 1562.35 664.353 1562.38 Q664.192 1562.42 663.934 1562.42 Q663.258 1562.42 661.808 1562.35 Q660.391 1562.29 659.651 1562.29 L655.432 1562.22 L647.058 1562.42 Q646.06 1562.42 646.06 1561.61 Q646.06 1561 646.317 1560.74 Q646.575 1560.45 646.865 1560.42 Q647.155 1560.39 647.896 1560.39 Q649.506 1560.39 650.472 1560.29 Q651.438 1560.19 652.05 1560.07 Q652.694 1559.9 653.016 1559.45 Q653.371 1559 653.532 1558.62 Q653.693 1558.2 653.918 1557.26 L662.742 1521.84 Q663 1520.77 663 1520.61 Q663 1520.07 662.678 1519.87 Q662.388 1519.65 661.551 1519.55 Q659.941 1519.42 658.717 1519.42 Q657.912 1519.42 657.589 1519.39 Q657.3 1519.36 657.042 1519.2 Q656.817 1519 656.817 1518.62 Q656.817 1518 657.074 1517.75 Q657.364 1517.46 657.686 1517.42 Q658.008 1517.36 658.781 1517.36 L680.166 1517.36 Q686.317 1517.36 689.731 1520.29 Q693.145 1523.22 693.145 1527.31 M687.026 1525.73 Q687.026 1519.42 678.04 1519.42 L671.728 1519.42 Q669.634 1519.42 669.119 1519.81 Q668.604 1520.16 668.153 1521.93 L663.676 1539.87 L672.984 1539.87 Q679.232 1539.87 683.129 1536.36 Q684.9 1534.75 685.963 1531.4 Q687.026 1528.05 687.026 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M743.514 1516.59 L739.359 1533.4 Q739.069 1534.46 738.876 1534.59 Q738.715 1534.72 738.2 1534.72 Q737.201 1534.72 737.201 1534.04 Q737.201 1533.98 737.298 1533.14 Q737.395 1532.27 737.395 1530.69 Q737.395 1524.86 734.561 1521.42 Q731.759 1517.97 726.767 1517.97 Q722.451 1517.97 718.103 1520.16 Q713.788 1522.35 710.696 1525.93 Q708.377 1528.63 706.67 1532.05 Q704.996 1535.46 704.19 1538.58 Q703.417 1541.71 703.063 1544.06 Q702.709 1546.41 702.709 1548.12 Q702.709 1550.6 703.224 1552.69 Q703.772 1554.78 704.738 1556.27 Q705.704 1557.71 706.928 1558.84 Q708.184 1559.94 709.633 1560.58 Q711.115 1561.22 712.596 1561.55 Q714.078 1561.84 715.623 1561.84 Q721.839 1561.84 727.765 1557.01 Q732.467 1553.04 734.432 1546.57 Q734.593 1545.93 735.269 1545.93 Q736.074 1545.93 736.074 1546.57 Q736.074 1546.7 735.913 1547.34 Q735.752 1547.96 735.269 1549.21 Q734.786 1550.44 734.045 1551.82 Q733.304 1553.21 731.92 1554.94 Q730.535 1556.68 728.828 1558.2 Q725.929 1560.71 722.258 1562.29 Q718.586 1563.87 714.561 1563.87 Q709.537 1563.87 705.479 1561.64 Q701.421 1559.42 699.037 1555.27 Q696.686 1551.11 696.686 1545.8 Q696.686 1540.19 699.263 1534.69 Q701.839 1529.18 705.93 1525.09 Q710.02 1521 715.43 1518.46 Q720.841 1515.91 726.251 1515.91 Q728.313 1515.91 730.148 1516.46 Q731.984 1517.01 733.079 1517.68 Q734.206 1518.36 735.205 1519.36 Q736.203 1520.32 736.525 1520.77 Q736.879 1521.23 737.201 1521.77 L741.807 1516.72 Q742.612 1515.91 742.805 1515.91 Q743.192 1515.91 743.353 1516.14 Q743.514 1516.36 743.514 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M788.635 1561.1 Q788.635 1561.71 788.377 1562.03 Q788.152 1562.32 787.927 1562.38 Q787.733 1562.42 787.443 1562.42 Q786.606 1562.42 783.708 1562.32 Q780.809 1562.22 779.972 1562.22 Q778.619 1562.22 775.849 1562.32 Q773.08 1562.42 771.727 1562.42 Q770.825 1562.42 770.825 1561.68 Q770.825 1561.19 770.922 1560.93 Q771.018 1560.65 771.276 1560.55 Q771.566 1560.42 771.727 1560.42 Q771.92 1560.39 772.403 1560.39 Q773.047 1560.39 773.724 1560.32 Q774.4 1560.23 775.237 1560.03 Q776.075 1559.84 776.59 1559.36 Q777.138 1558.87 777.138 1558.2 Q777.138 1557.91 776.912 1555.52 Q776.687 1553.14 776.397 1550.37 Q776.107 1547.57 776.075 1547.18 L759.521 1547.18 Q758.007 1549.79 756.944 1551.6 Q755.882 1553.4 755.495 1554.01 Q755.109 1554.62 754.883 1555.01 Q754.658 1555.4 754.529 1555.62 Q753.595 1557.33 753.595 1558.07 Q753.595 1560.13 756.687 1560.39 Q757.75 1560.39 757.75 1561.16 Q757.75 1561.74 757.492 1562.06 Q757.234 1562.35 757.009 1562.38 Q756.816 1562.42 756.494 1562.42 Q755.431 1562.42 753.209 1562.32 Q750.986 1562.22 749.891 1562.22 Q748.957 1562.22 747.025 1562.32 Q745.093 1562.42 744.223 1562.42 Q743.837 1562.42 743.611 1562.19 Q743.386 1561.97 743.386 1561.68 Q743.386 1561.22 743.45 1560.97 Q743.547 1560.71 743.805 1560.58 Q744.062 1560.45 744.191 1560.45 Q744.32 1560.42 744.771 1560.39 Q747.218 1560.23 749.118 1559.07 Q751.051 1557.88 752.887 1554.82 L775.817 1516.3 Q776.043 1515.91 776.204 1515.72 Q776.365 1515.52 776.687 1515.36 Q777.041 1515.2 777.556 1515.2 Q778.361 1515.2 778.522 1515.46 Q778.683 1515.69 778.78 1516.78 L782.806 1558 Q782.902 1558.87 782.967 1559.23 Q783.063 1559.55 783.482 1559.9 Q783.933 1560.23 784.738 1560.32 Q785.576 1560.39 787.121 1560.39 Q787.701 1560.39 787.927 1560.42 Q788.152 1560.42 788.377 1560.58 Q788.635 1560.74 788.635 1561.1 M775.882 1545.12 L773.788 1523.38 L760.777 1545.12 L775.882 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M795.238 1554.34 L795.238 1552.9 Q800.784 1552.9 803.647 1549.94 Q804.436 1549.94 804.572 1550.12 Q804.707 1550.3 804.707 1551.14 L804.707 1577.04 Q804.707 1578.42 805.383 1578.84 Q806.059 1579.27 809.013 1579.27 L810.478 1579.27 L810.478 1580.69 Q808.855 1580.56 802.993 1580.56 Q797.132 1580.56 795.531 1580.69 L795.531 1579.27 L796.997 1579.27 Q799.905 1579.27 800.604 1578.87 Q801.303 1578.44 801.303 1577.04 L801.303 1553.12 Q798.89 1554.34 795.238 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1248.99 1152.76,1248.99 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1019.25 1152.76,1019.25 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,789.506 1152.76,789.506 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,559.762 1152.76,559.762 \"/>\n<polyline clip-path=\"url(#clip712)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,330.018 1152.76,330.018 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1248.99 329.574,1248.99 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1019.25 329.574,1019.25 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,789.506 329.574,789.506 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,559.762 329.574,559.762 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,330.018 329.574,330.018 \"/>\n<path clip-path=\"url(#clip710)\" d=\"M114.26 1249.67 L158.774 1249.67 L158.774 1255.57 L114.26 1255.57 L114.26 1249.67 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M175.128 1269.01 L186.586 1269.01 L186.586 1229.46 L174.121 1231.96 L174.121 1225.57 L186.517 1223.07 L193.531 1223.07 L193.531 1269.01 L204.989 1269.01 L204.989 1274.91 L175.128 1274.91 L175.128 1269.01 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M219.155 1266.09 L226.482 1266.09 L226.482 1274.91 L219.155 1274.91 L219.155 1266.09 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M256.759 1227.69 Q251.343 1227.69 248.6 1233.04 Q245.891 1238.35 245.891 1249.05 Q245.891 1259.7 248.6 1265.05 Q251.343 1270.36 256.759 1270.36 Q262.211 1270.36 264.919 1265.05 Q267.662 1259.7 267.662 1249.05 Q267.662 1238.35 264.919 1233.04 Q262.211 1227.69 256.759 1227.69 M256.759 1222.14 Q265.475 1222.14 270.058 1229.05 Q274.676 1235.92 274.676 1249.05 Q274.676 1262.14 270.058 1269.04 Q265.475 1275.92 256.759 1275.92 Q248.044 1275.92 243.426 1269.04 Q238.843 1262.14 238.843 1249.05 Q238.843 1235.92 243.426 1229.05 Q248.044 1222.14 256.759 1222.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M115.753 1019.93 L160.267 1019.93 L160.267 1025.83 L115.753 1025.83 L115.753 1019.93 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M190.406 997.947 Q184.989 997.947 182.246 1003.29 Q179.538 1008.61 179.538 1019.3 Q179.538 1029.96 182.246 1035.31 Q184.989 1040.62 190.406 1040.62 Q195.857 1040.62 198.565 1035.31 Q201.308 1029.96 201.308 1019.3 Q201.308 1008.61 198.565 1003.29 Q195.857 997.947 190.406 997.947 M190.406 992.392 Q199.121 992.392 203.704 999.302 Q208.322 1006.18 208.322 1019.3 Q208.322 1032.39 203.704 1039.3 Q199.121 1046.18 190.406 1046.18 Q181.69 1046.18 177.072 1039.3 Q172.489 1032.39 172.489 1019.3 Q172.489 1006.18 177.072 999.302 Q181.69 992.392 190.406 992.392 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M220.648 1036.35 L227.975 1036.35 L227.975 1045.17 L220.648 1045.17 L220.648 1036.35 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M243.322 993.329 L270.857 993.329 L270.857 999.232 L249.746 999.232 L249.746 1011.94 Q251.273 1011.42 252.801 1011.18 Q254.329 1010.9 255.857 1010.9 Q264.537 1010.9 269.607 1015.66 Q274.676 1020.41 274.676 1028.54 Q274.676 1036.91 269.468 1041.56 Q264.259 1046.18 254.78 1046.18 Q251.516 1046.18 248.114 1045.62 Q244.746 1045.07 241.134 1043.95 L241.134 1036.91 Q244.259 1038.61 247.593 1039.44 Q250.926 1040.27 254.641 1040.27 Q260.648 1040.27 264.155 1037.11 Q267.662 1033.95 267.662 1028.54 Q267.662 1023.12 264.155 1019.96 Q260.648 1016.8 254.641 1016.8 Q251.829 1016.8 249.016 1017.43 Q246.239 1018.05 243.322 1019.37 L243.322 993.329 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M188.913 768.204 Q183.496 768.204 180.753 773.551 Q178.045 778.863 178.045 789.558 Q178.045 800.217 180.753 805.565 Q183.496 810.877 188.913 810.877 Q194.364 810.877 197.072 805.565 Q199.815 800.217 199.815 789.558 Q199.815 778.863 197.072 773.551 Q194.364 768.204 188.913 768.204 M188.913 762.648 Q197.628 762.648 202.211 769.558 Q206.829 776.433 206.829 789.558 Q206.829 802.648 202.211 809.558 Q197.628 816.433 188.913 816.433 Q180.197 816.433 175.579 809.558 Q170.996 802.648 170.996 789.558 Q170.996 776.433 175.579 769.558 Q180.197 762.648 188.913 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M219.155 806.606 L226.482 806.606 L226.482 815.426 L219.155 815.426 L219.155 806.606 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M256.759 768.204 Q251.343 768.204 248.6 773.551 Q245.891 778.863 245.891 789.558 Q245.891 800.217 248.6 805.565 Q251.343 810.877 256.759 810.877 Q262.211 810.877 264.919 805.565 Q267.662 800.217 267.662 789.558 Q267.662 778.863 264.919 773.551 Q262.211 768.204 256.759 768.204 M256.759 762.648 Q265.475 762.648 270.058 769.558 Q274.676 776.433 274.676 789.558 Q274.676 802.648 270.058 809.558 Q265.475 816.433 256.759 816.433 Q248.044 816.433 243.426 809.558 Q238.843 802.648 238.843 789.558 Q238.843 776.433 243.426 769.558 Q248.044 762.648 256.759 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M190.406 538.46 Q184.989 538.46 182.246 543.807 Q179.538 549.12 179.538 559.814 Q179.538 570.474 182.246 575.821 Q184.989 581.133 190.406 581.133 Q195.857 581.133 198.565 575.821 Q201.308 570.474 201.308 559.814 Q201.308 549.12 198.565 543.807 Q195.857 538.46 190.406 538.46 M190.406 532.905 Q199.121 532.905 203.704 539.814 Q208.322 546.689 208.322 559.814 Q208.322 572.904 203.704 579.814 Q199.121 586.689 190.406 586.689 Q181.69 586.689 177.072 579.814 Q172.489 572.904 172.489 559.814 Q172.489 546.689 177.072 539.814 Q181.69 532.905 190.406 532.905 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M220.648 576.863 L227.975 576.863 L227.975 585.682 L220.648 585.682 L220.648 576.863 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M243.322 533.842 L270.857 533.842 L270.857 539.745 L249.746 539.745 L249.746 552.453 Q251.273 551.932 252.801 551.689 Q254.329 551.411 255.857 551.411 Q264.537 551.411 269.607 556.168 Q274.676 560.925 274.676 569.05 Q274.676 577.418 269.468 582.071 Q264.259 586.689 254.78 586.689 Q251.516 586.689 248.114 586.133 Q244.746 585.578 241.134 584.467 L241.134 577.418 Q244.259 579.12 247.593 579.953 Q250.926 580.786 254.641 580.786 Q260.648 580.786 264.155 577.626 Q267.662 574.467 267.662 569.05 Q267.662 563.634 264.155 560.474 Q260.648 557.314 254.641 557.314 Q251.829 557.314 249.016 557.939 Q246.239 558.564 243.322 559.884 L243.322 533.842 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M175.128 350.036 L186.586 350.036 L186.586 310.487 L174.121 312.987 L174.121 306.598 L186.517 304.098 L193.531 304.098 L193.531 350.036 L204.989 350.036 L204.989 355.938 L175.128 355.938 L175.128 350.036 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M219.155 347.119 L226.482 347.119 L226.482 355.938 L219.155 355.938 L219.155 347.119 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M256.759 308.716 Q251.343 308.716 248.6 314.064 Q245.891 319.376 245.891 330.07 Q245.891 340.73 248.6 346.077 Q251.343 351.39 256.759 351.39 Q262.211 351.39 264.919 346.077 Q267.662 340.73 267.662 330.07 Q267.662 319.376 264.919 314.064 Q262.211 308.716 256.759 308.716 M256.759 303.161 Q265.475 303.161 270.058 310.071 Q274.676 316.946 274.676 330.07 Q274.676 343.161 270.058 350.07 Q265.475 356.945 256.759 356.945 Q248.044 356.945 243.426 350.07 Q238.843 343.161 238.843 330.07 Q238.843 316.946 243.426 310.071 Q248.044 303.161 256.759 303.161 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M28.8883 804.838 Q32.4954 804.838 35.8126 807.511 Q39.1298 810.152 41.1587 814.467 Q43.1555 818.751 43.1555 823.356 L43.1555 834.564 L59.6449 838.654 Q59.7415 838.686 60.1602 838.783 Q60.5467 838.879 60.7721 838.879 Q61.5772 838.879 61.7705 837.881 Q61.9637 836.85 61.9637 834.564 Q61.9637 833.082 62.2214 832.857 Q62.3824 832.728 62.6722 832.728 Q63.1231 832.728 63.4452 832.857 Q63.735 832.986 63.8317 833.243 Q63.9283 833.469 63.9605 833.63 Q63.9927 833.791 63.9927 834.048 Q63.9927 834.725 63.9283 836.174 Q63.8639 837.591 63.8639 838.332 L63.7995 842.551 L63.9927 850.924 Q63.9927 851.923 63.1875 851.923 Q62.5756 851.923 62.318 851.665 Q62.0281 851.407 61.9959 851.117 Q61.9637 850.828 61.9637 850.087 Q61.9637 848.477 61.8671 847.51 Q61.7705 846.544 61.6417 845.932 Q61.4806 845.288 61.0297 844.966 Q60.5789 844.612 60.1924 844.451 Q59.7737 844.29 58.8398 844.064 L23.4133 835.24 Q22.3505 834.982 22.1895 834.982 Q21.642 834.982 21.4487 835.304 Q21.2233 835.594 21.1267 836.432 Q20.9979 838.042 20.9979 839.266 Q20.9979 840.071 20.9657 840.393 Q20.9335 840.683 20.7724 840.94 Q20.5792 841.166 20.1927 841.166 Q19.5808 841.166 19.3232 840.908 Q19.0333 840.618 19.0011 840.296 Q18.9367 839.974 18.9367 839.201 L18.9367 817.817 Q18.9367 811.665 21.8674 808.251 Q24.7982 804.838 28.8883 804.838 M27.3102 810.957 Q20.9979 810.957 20.9979 819.942 L20.9979 826.255 Q20.9979 828.348 21.3843 828.863 Q21.7386 829.378 23.5099 829.829 L41.4486 834.306 L41.4486 824.998 Q41.4486 818.751 37.9381 814.854 Q36.3279 813.082 32.9784 812.02 Q29.629 810.957 27.3102 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M18.1637 754.469 L34.9752 758.623 Q36.038 758.913 36.1668 759.106 Q36.2956 759.267 36.2956 759.783 Q36.2956 760.781 35.6193 760.781 Q35.5549 760.781 34.7176 760.684 Q33.848 760.588 32.2699 760.588 Q26.4407 760.588 22.9946 763.422 Q19.5486 766.224 19.5486 771.216 Q19.5486 775.531 21.7386 779.879 Q23.9286 784.195 27.5034 787.286 Q30.2087 789.605 33.6226 791.312 Q37.0364 792.987 40.1604 793.792 Q43.2843 794.565 45.6353 794.919 Q47.9864 795.273 49.6933 795.273 Q52.1731 795.273 54.2665 794.758 Q56.3599 794.211 57.8414 793.244 Q59.2906 792.278 60.4178 791.055 Q61.5128 789.798 62.157 788.349 Q62.8011 786.868 63.1231 785.386 Q63.413 783.905 63.413 782.359 Q63.413 776.143 58.5821 770.217 Q54.6208 765.515 48.1474 763.551 Q47.5033 763.39 47.5033 762.713 Q47.5033 761.908 48.1474 761.908 Q48.2762 761.908 48.9203 762.069 Q49.5323 762.23 50.7883 762.713 Q52.0121 763.196 53.397 763.937 Q54.7818 764.678 56.5209 766.063 Q58.26 767.448 59.7737 769.155 Q62.2858 772.053 63.8639 775.725 Q65.442 779.396 65.442 783.422 Q65.442 788.446 63.2197 792.504 Q60.9975 796.562 56.843 798.945 Q52.6884 801.296 47.3745 801.296 Q41.7706 801.296 36.2634 798.719 Q30.7562 796.143 26.6661 792.053 Q22.576 787.963 20.0317 782.552 Q17.4874 777.142 17.4874 771.731 Q17.4874 769.67 18.0349 767.834 Q18.5824 765.998 19.2587 764.903 Q19.9351 763.776 20.9335 762.778 Q21.8996 761.779 22.3505 761.457 Q22.8014 761.103 23.3489 760.781 L18.2926 756.176 Q17.4874 755.37 17.4874 755.177 Q17.4874 754.791 17.7129 754.63 Q17.9383 754.469 18.1637 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M62.6722 709.347 Q63.2842 709.347 63.6062 709.605 Q63.8961 709.83 63.9605 710.056 Q63.9927 710.249 63.9927 710.539 Q63.9927 711.376 63.8961 714.275 Q63.7995 717.173 63.7995 718.011 Q63.7995 719.363 63.8961 722.133 Q63.9927 724.903 63.9927 726.255 Q63.9927 727.157 63.252 727.157 Q62.7689 727.157 62.5112 727.061 Q62.2214 726.964 62.1247 726.706 Q61.9959 726.416 61.9959 726.255 Q61.9637 726.062 61.9637 725.579 Q61.9637 724.935 61.8993 724.259 Q61.8027 723.582 61.6095 722.745 Q61.4162 721.908 60.9331 721.392 Q60.45 720.845 59.7737 720.845 Q59.4839 720.845 57.1006 721.07 Q54.7174 721.296 51.9477 721.586 Q49.1458 721.875 48.7593 721.908 L48.7593 738.461 Q51.368 739.975 53.1715 741.038 Q54.975 742.101 55.587 742.487 Q56.1989 742.874 56.5853 743.099 Q56.9718 743.325 57.1973 743.453 Q58.9042 744.387 59.6449 744.387 Q61.7061 744.387 61.9637 741.296 Q61.9637 740.233 62.7367 740.233 Q63.3164 740.233 63.6384 740.49 Q63.9283 740.748 63.9605 740.973 Q63.9927 741.167 63.9927 741.489 Q63.9927 742.552 63.8961 744.774 Q63.7995 746.996 63.7995 748.091 Q63.7995 749.025 63.8961 750.957 Q63.9927 752.89 63.9927 753.759 Q63.9927 754.146 63.7672 754.371 Q63.5418 754.597 63.252 754.597 Q62.8011 754.597 62.5434 754.532 Q62.2858 754.436 62.157 754.178 Q62.0281 753.92 62.0281 753.791 Q61.9959 753.663 61.9637 753.212 Q61.8027 750.764 60.6433 748.864 Q59.4517 746.932 56.3921 745.096 L17.8739 722.165 Q17.4874 721.94 17.2942 721.779 Q17.101 721.618 16.9399 721.296 Q16.7789 720.941 16.7789 720.426 Q16.7789 719.621 17.0365 719.46 Q17.262 719.299 18.357 719.202 L59.5805 715.177 Q60.45 715.08 60.8043 715.016 Q61.1264 714.919 61.4806 714.5 Q61.8027 714.049 61.8993 713.244 Q61.9637 712.407 61.9637 710.861 Q61.9637 710.281 61.9959 710.056 Q61.9959 709.83 62.157 709.605 Q62.318 709.347 62.6722 709.347 M46.6981 722.101 L24.9592 724.194 L46.6981 737.205 L46.6981 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M82.2693 702.744 Q81.4351 702.744 81.1871 702.676 Q80.9391 702.586 80.5559 702.226 L70.6816 693.366 Q65.2259 688.519 60.4691 688.519 Q57.3806 688.519 55.1712 690.142 Q52.9619 691.743 52.9619 694.696 Q52.9619 696.725 54.2018 698.438 Q55.4418 700.151 57.6511 700.941 Q57.606 700.805 57.606 700.332 Q57.606 699.182 58.3274 698.551 Q59.0488 697.897 60.0182 697.897 Q61.2581 697.897 61.8668 698.709 Q62.453 699.498 62.453 700.287 Q62.453 700.602 62.3854 701.031 Q62.3177 701.437 61.6865 702.09 Q61.0327 702.744 59.883 702.744 Q56.6592 702.744 54.0891 700.309 Q51.5191 697.852 51.5191 694.11 Q51.5191 689.871 54.044 687.098 Q56.5464 684.303 60.4691 684.303 Q61.8443 684.303 63.1068 684.731 Q64.3467 685.137 65.3161 685.701 Q66.2855 686.242 67.841 687.73 Q69.3966 689.218 70.5012 690.412 Q71.6059 691.607 73.9505 694.29 L78.7073 699.182 L78.7073 690.863 Q78.7073 686.805 78.3466 686.49 Q77.6928 686.039 74.2436 685.475 L74.2436 684.303 L82.2693 685.611 L82.2693 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M382.158 3.35044 L416.915 3.35044 L416.915 10.237 L390.341 10.237 L390.341 28.061 L414.322 28.061 L414.322 34.9475 L390.341 34.9475 L390.341 63.8304 L382.158 63.8304 L382.158 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M424.247 45.9254 L424.247 18.4603 L431.7 18.4603 L431.7 45.6419 Q431.7 52.0828 434.212 55.3235 Q436.724 58.5238 441.747 58.5238 Q447.783 58.5238 451.266 54.6754 Q454.791 50.827 454.791 44.1836 L454.791 18.4603 L462.244 18.4603 L462.244 63.8304 L454.791 63.8304 L454.791 56.8629 Q452.077 60.9948 448.471 63.0203 Q444.906 65.0052 440.167 65.0052 Q432.349 65.0052 428.298 60.1441 Q424.247 55.283 424.247 45.9254 M443.002 17.3666 L443.002 17.3666 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M474.356 18.4603 L509.761 18.4603 L509.761 25.2658 L481.729 57.8756 L509.761 57.8756 L509.761 63.8304 L473.344 63.8304 L473.344 57.0249 L501.376 24.4151 L474.356 24.4151 L474.356 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M517.904 18.4603 L553.309 18.4603 L553.309 25.2658 L525.276 57.8756 L553.309 57.8756 L553.309 63.8304 L516.891 63.8304 L516.891 57.0249 L544.923 24.4151 L517.904 24.4151 L517.904 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M583.569 68.0434 Q580.409 76.1452 577.411 78.6162 Q574.414 81.0873 569.391 81.0873 L563.436 81.0873 L563.436 74.8489 L567.811 74.8489 Q570.89 74.8489 572.591 73.3906 Q574.292 71.9322 576.358 66.504 L577.695 63.1013 L559.344 18.4603 L567.244 18.4603 L581.422 53.9462 L595.6 18.4603 L603.499 18.4603 L583.569 68.0434 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M634.327 11.4117 L623.227 41.51 L645.467 41.51 L634.327 11.4117 M629.709 3.35044 L638.985 3.35044 L662.035 63.8304 L653.528 63.8304 L648.019 48.3155 L620.756 48.3155 L615.247 63.8304 L606.619 63.8304 L629.709 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M699.546 35.4741 Q702.179 36.3653 704.65 39.282 Q707.162 42.1986 709.674 47.3027 L717.978 63.8304 L709.187 63.8304 L701.45 48.3155 Q698.453 42.2391 695.617 40.2542 Q692.822 38.2692 687.961 38.2692 L679.049 38.2692 L679.049 63.8304 L670.866 63.8304 L670.866 3.35044 L689.338 3.35044 Q699.708 3.35044 704.812 7.68491 Q709.917 12.0194 709.917 20.7693 Q709.917 26.4811 707.243 30.2484 Q704.61 34.0158 699.546 35.4741 M679.049 10.0749 L679.049 31.5447 L689.338 31.5447 Q695.252 31.5447 698.25 28.8306 Q701.288 26.076 701.288 20.7693 Q701.288 15.4626 698.25 12.789 Q695.252 10.0749 689.338 10.0749 L679.049 10.0749 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M714.089 3.35044 L765.252 3.35044 L765.252 10.237 L743.782 10.237 L743.782 63.8304 L735.559 63.8304 L735.559 10.237 L714.089 10.237 L714.089 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M831.017 40.4256 Q831.017 46.492 827.902 52.1895 Q824.828 57.887 819.991 61.3301 Q815.195 64.7732 810.358 64.7732 Q804.907 64.7732 802.078 59.1167 Q796.955 79.6523 796.668 80.1852 Q795.479 81.9477 793.758 81.9477 Q792.692 81.9477 792.036 81.2919 Q791.38 80.677 791.38 79.6933 Q791.421 79.3654 791.667 78.3406 L799.865 45.3443 Q801.751 37.6793 807.448 32.2277 Q813.187 26.7351 819.335 26.7351 Q824.213 26.7351 827.615 30.3832 Q831.017 34.0312 831.017 40.4256 M824.991 36.8185 Q824.991 32.7196 823.352 30.6701 Q821.712 28.5797 819.171 28.5797 Q816.835 28.5797 814.006 30.4652 Q811.219 32.3507 808.76 36.5316 Q807.448 38.9499 806.505 41.9422 Q805.563 44.9344 803.718 52.3125 Q803.062 55.2637 803.062 55.4276 Q803.062 55.7555 803.226 56.4934 Q803.431 57.2312 803.923 58.3789 Q804.456 59.4856 805.194 60.4693 Q805.931 61.4531 807.284 62.1909 Q808.637 62.8877 810.276 62.8877 Q812.818 62.8877 815.523 60.8382 Q818.269 58.7478 820.278 54.9358 Q821.958 51.8616 823.475 46.0821 Q824.991 40.2616 824.991 36.8185 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M869.493 26.157 L921.425 26.157 L921.425 32.9625 L869.493 32.9625 L869.493 26.157 M869.493 42.6847 L921.425 42.6847 L921.425 49.5713 L869.493 49.5713 L869.493 42.6847 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M982.959 8.73814 Q976.639 8.73814 973.439 14.9765 Q970.279 21.1744 970.279 33.6512 Q970.279 46.0875 973.439 52.3259 Q976.639 58.5238 982.959 58.5238 Q989.318 58.5238 992.478 52.3259 Q995.678 46.0875 995.678 33.6512 Q995.678 21.1744 992.478 14.9765 Q989.318 8.73814 982.959 8.73814 M982.959 2.25669 Q993.126 2.25669 998.473 10.318 Q1003.86 18.3388 1003.86 33.6512 Q1003.86 48.9231 998.473 56.9844 Q993.126 65.0052 982.959 65.0052 Q972.791 65.0052 967.403 56.9844 Q962.056 48.9231 962.056 33.6512 Q962.056 18.3388 967.403 10.318 Q972.791 2.25669 982.959 2.25669 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1018.24 53.5411 L1026.79 53.5411 L1026.79 63.8304 L1018.24 63.8304 L1018.24 53.5411 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1044.69 3.35044 L1076.82 3.35044 L1076.82 10.237 L1052.19 10.237 L1052.19 25.0633 Q1053.97 24.4556 1055.75 24.1721 Q1057.54 23.848 1059.32 23.848 Q1069.45 23.848 1075.36 29.3978 Q1081.27 34.9475 1081.27 44.4266 Q1081.27 54.1893 1075.2 59.6175 Q1069.12 65.0052 1058.06 65.0052 Q1054.25 65.0052 1050.28 64.3571 Q1046.36 63.7089 1042.14 62.4126 L1042.14 54.1893 Q1045.79 56.1742 1049.68 57.1464 Q1053.57 58.1187 1057.9 58.1187 Q1064.91 58.1187 1069 54.4323 Q1073.09 50.746 1073.09 44.4266 Q1073.09 38.1072 1069 34.4209 Q1064.91 30.7346 1057.9 30.7346 Q1054.62 30.7346 1051.34 31.4637 Q1048.1 32.1929 1044.69 33.7322 L1044.69 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip712)\" cx=\"1071.2\" cy=\"1020.76\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1020.81\" cy=\"932.463\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1009.58\" cy=\"642.796\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"991.609\" cy=\"726.148\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1070.22\" cy=\"724.435\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1045.58\" cy=\"1010.17\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"964.218\" cy=\"586.092\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1008.05\" cy=\"510.689\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1017.57\" cy=\"901.015\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1023.3\" cy=\"664.957\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1013.16\" cy=\"838.529\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1009.98\" cy=\"244.464\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1004.18\" cy=\"880.205\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1031.94\" cy=\"1218.15\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"1006.78\" cy=\"779.617\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"634.824\" cy=\"873.312\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"712.667\" cy=\"1168.86\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"707.028\" cy=\"942.02\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"632.523\" cy=\"1038.47\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"750.122\" cy=\"905.212\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"579.815\" cy=\"855.581\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"628.135\" cy=\"846.648\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"544.391\" cy=\"1019.92\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"646.749\" cy=\"699.881\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"739.12\" cy=\"1112.31\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"595.054\" cy=\"1139.18\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"603.254\" cy=\"602.019\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"704.102\" cy=\"1041.26\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"621.898\" cy=\"684.303\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"617.284\" cy=\"754.865\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"785.513\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"700.369\" cy=\"948.955\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"531.21\" cy=\"767.428\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"487.547\" cy=\"902.332\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"531.55\" cy=\"736.262\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"586.59\" cy=\"983.044\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"374.16\" cy=\"538.089\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"529.359\" cy=\"601.451\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"564.851\" cy=\"1037.31\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"504.487\" cy=\"889.823\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"477.051\" cy=\"650.049\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"605.604\" cy=\"1067.76\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"391.48\" cy=\"159.767\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"503.788\" cy=\"690.587\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip712)\" cx=\"509.864\" cy=\"618.814\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<path clip-path=\"url(#clip710)\" d=\"M1510.68 1405.9 L2352.76 1405.9 L2352.76 123.472 L1510.68 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip713\">\n    <rect x=\"1510\" y=\"123\" width=\"843\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1405.9 1510.68,123.472 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1721.2,1405.9 1721.2,123.472 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1931.72,1405.9 1931.72,123.472 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2142.24,1405.9 2142.24,123.472 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2352.76,1405.9 2352.76,123.472 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 2352.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 1510.68,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1721.2,1405.9 1721.2,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1931.72,1405.9 1931.72,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2142.24,1405.9 2142.24,1387 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2352.76,1405.9 2352.76,1387 \"/>\n<path clip-path=\"url(#clip710)\" d=\"M1464.03 1464.66 L1508.54 1464.66 L1508.54 1470.56 L1464.03 1470.56 L1464.03 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1542.95 1444.17 L1525.24 1471.84 L1542.95 1471.84 L1542.95 1444.17 M1541.11 1438.06 L1549.93 1438.06 L1549.93 1471.84 L1557.33 1471.84 L1557.33 1477.68 L1549.93 1477.68 L1549.93 1489.9 L1542.95 1489.9 L1542.95 1477.68 L1519.55 1477.68 L1519.55 1470.91 L1541.11 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1676.11 1464.66 L1720.62 1464.66 L1720.62 1470.56 L1676.11 1470.56 L1676.11 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1741.8 1484 L1766.28 1484 L1766.28 1489.9 L1733.37 1489.9 L1733.37 1484 Q1737.36 1479.87 1744.23 1472.92 Q1751.14 1465.94 1752.91 1463.93 Q1756.28 1460.14 1757.6 1457.54 Q1758.96 1454.9 1758.96 1452.37 Q1758.96 1448.23 1756.04 1445.63 Q1753.16 1443.03 1748.5 1443.03 Q1745.21 1443.03 1741.53 1444.17 Q1737.88 1445.32 1733.71 1447.64 L1733.71 1440.56 Q1737.95 1438.86 1741.63 1437.99 Q1745.31 1437.12 1748.37 1437.12 Q1756.42 1437.12 1761.21 1441.15 Q1766 1445.18 1766 1451.91 Q1766 1455.11 1764.79 1457.99 Q1763.61 1460.84 1760.45 1464.73 Q1759.58 1465.73 1754.93 1470.56 Q1750.28 1475.35 1741.8 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1931.72 1442.68 Q1926.3 1442.68 1923.56 1448.03 Q1920.85 1453.34 1920.85 1464.03 Q1920.85 1474.69 1923.56 1480.04 Q1926.3 1485.35 1931.72 1485.35 Q1937.17 1485.35 1939.88 1480.04 Q1942.62 1474.69 1942.62 1464.03 Q1942.62 1453.34 1939.88 1448.03 Q1937.17 1442.68 1931.72 1442.68 M1931.72 1437.12 Q1940.43 1437.12 1945.01 1444.03 Q1949.63 1450.91 1949.63 1464.03 Q1949.63 1477.12 1945.01 1484.03 Q1940.43 1490.91 1931.72 1490.91 Q1923 1490.91 1918.38 1484.03 Q1913.8 1477.12 1913.8 1464.03 Q1913.8 1450.91 1918.38 1444.03 Q1923 1437.12 1931.72 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2134.22 1484 L2158.69 1484 L2158.69 1489.9 L2125.78 1489.9 L2125.78 1484 Q2129.77 1479.87 2136.65 1472.92 Q2143.56 1465.94 2145.33 1463.93 Q2148.69 1460.14 2150.01 1457.54 Q2151.37 1454.9 2151.37 1452.37 Q2151.37 1448.23 2148.45 1445.63 Q2145.57 1443.03 2140.92 1443.03 Q2137.62 1443.03 2133.94 1444.17 Q2130.29 1445.32 2126.12 1447.64 L2126.12 1440.56 Q2130.36 1438.86 2134.04 1437.99 Q2137.72 1437.12 2140.78 1437.12 Q2148.83 1437.12 2153.62 1441.15 Q2158.42 1445.18 2158.42 1451.91 Q2158.42 1455.11 2157.2 1457.99 Q2156.02 1460.84 2152.86 1464.73 Q2151.99 1465.73 2147.34 1470.56 Q2142.69 1475.35 2134.22 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2357.27 1444.17 L2339.56 1471.84 L2357.27 1471.84 L2357.27 1444.17 M2355.43 1438.06 L2364.25 1438.06 L2364.25 1471.84 L2371.64 1471.84 L2371.64 1477.68 L2364.25 1477.68 L2364.25 1489.9 L2357.27 1489.9 L2357.27 1477.68 L2333.87 1477.68 L2333.87 1470.91 L2355.43 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1893.14 1527.31 Q1893.14 1530.92 1890.47 1534.24 Q1887.83 1537.55 1883.52 1539.58 Q1879.23 1541.58 1874.63 1541.58 L1863.42 1541.58 L1859.33 1558.07 Q1859.3 1558.17 1859.2 1558.58 Q1859.1 1558.97 1859.1 1559.2 Q1859.1 1560 1860.1 1560.19 Q1861.13 1560.39 1863.42 1560.39 Q1864.9 1560.39 1865.13 1560.65 Q1865.25 1560.81 1865.25 1561.1 Q1865.25 1561.55 1865.13 1561.87 Q1865 1562.16 1864.74 1562.26 Q1864.51 1562.35 1864.35 1562.38 Q1864.19 1562.42 1863.93 1562.42 Q1863.26 1562.42 1861.81 1562.35 Q1860.39 1562.29 1859.65 1562.29 L1855.43 1562.22 L1847.06 1562.42 Q1846.06 1562.42 1846.06 1561.61 Q1846.06 1561 1846.32 1560.74 Q1846.58 1560.45 1846.86 1560.42 Q1847.15 1560.39 1847.9 1560.39 Q1849.51 1560.39 1850.47 1560.29 Q1851.44 1560.19 1852.05 1560.07 Q1852.69 1559.9 1853.02 1559.45 Q1853.37 1559 1853.53 1558.62 Q1853.69 1558.2 1853.92 1557.26 L1862.74 1521.84 Q1863 1520.77 1863 1520.61 Q1863 1520.07 1862.68 1519.87 Q1862.39 1519.65 1861.55 1519.55 Q1859.94 1519.42 1858.72 1519.42 Q1857.91 1519.42 1857.59 1519.39 Q1857.3 1519.36 1857.04 1519.2 Q1856.82 1519 1856.82 1518.62 Q1856.82 1518 1857.07 1517.75 Q1857.36 1517.46 1857.69 1517.42 Q1858.01 1517.36 1858.78 1517.36 L1880.17 1517.36 Q1886.32 1517.36 1889.73 1520.29 Q1893.14 1523.22 1893.14 1527.31 M1887.03 1525.73 Q1887.03 1519.42 1878.04 1519.42 L1871.73 1519.42 Q1869.63 1519.42 1869.12 1519.81 Q1868.6 1520.16 1868.15 1521.93 L1863.68 1539.87 L1872.98 1539.87 Q1879.23 1539.87 1883.13 1536.36 Q1884.9 1534.75 1885.96 1531.4 Q1887.03 1528.05 1887.03 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1943.51 1516.59 L1939.36 1533.4 Q1939.07 1534.46 1938.88 1534.59 Q1938.72 1534.72 1938.2 1534.72 Q1937.2 1534.72 1937.2 1534.04 Q1937.2 1533.98 1937.3 1533.14 Q1937.39 1532.27 1937.39 1530.69 Q1937.39 1524.86 1934.56 1521.42 Q1931.76 1517.97 1926.77 1517.97 Q1922.45 1517.97 1918.1 1520.16 Q1913.79 1522.35 1910.7 1525.93 Q1908.38 1528.63 1906.67 1532.05 Q1905 1535.46 1904.19 1538.58 Q1903.42 1541.71 1903.06 1544.06 Q1902.71 1546.41 1902.71 1548.12 Q1902.71 1550.6 1903.22 1552.69 Q1903.77 1554.78 1904.74 1556.27 Q1905.7 1557.71 1906.93 1558.84 Q1908.18 1559.94 1909.63 1560.58 Q1911.11 1561.22 1912.6 1561.55 Q1914.08 1561.84 1915.62 1561.84 Q1921.84 1561.84 1927.77 1557.01 Q1932.47 1553.04 1934.43 1546.57 Q1934.59 1545.93 1935.27 1545.93 Q1936.07 1545.93 1936.07 1546.57 Q1936.07 1546.7 1935.91 1547.34 Q1935.75 1547.96 1935.27 1549.21 Q1934.79 1550.44 1934.05 1551.82 Q1933.3 1553.21 1931.92 1554.94 Q1930.53 1556.68 1928.83 1558.2 Q1925.93 1560.71 1922.26 1562.29 Q1918.59 1563.87 1914.56 1563.87 Q1909.54 1563.87 1905.48 1561.64 Q1901.42 1559.42 1899.04 1555.27 Q1896.69 1551.11 1896.69 1545.8 Q1896.69 1540.19 1899.26 1534.69 Q1901.84 1529.18 1905.93 1525.09 Q1910.02 1521 1915.43 1518.46 Q1920.84 1515.91 1926.25 1515.91 Q1928.31 1515.91 1930.15 1516.46 Q1931.98 1517.01 1933.08 1517.68 Q1934.21 1518.36 1935.2 1519.36 Q1936.2 1520.32 1936.53 1520.77 Q1936.88 1521.23 1937.2 1521.77 L1941.81 1516.72 Q1942.61 1515.91 1942.81 1515.91 Q1943.19 1515.91 1943.35 1516.14 Q1943.51 1516.36 1943.51 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1988.64 1561.1 Q1988.64 1561.71 1988.38 1562.03 Q1988.15 1562.32 1987.93 1562.38 Q1987.73 1562.42 1987.44 1562.42 Q1986.61 1562.42 1983.71 1562.32 Q1980.81 1562.22 1979.97 1562.22 Q1978.62 1562.22 1975.85 1562.32 Q1973.08 1562.42 1971.73 1562.42 Q1970.83 1562.42 1970.83 1561.68 Q1970.83 1561.19 1970.92 1560.93 Q1971.02 1560.65 1971.28 1560.55 Q1971.57 1560.42 1971.73 1560.42 Q1971.92 1560.39 1972.4 1560.39 Q1973.05 1560.39 1973.72 1560.32 Q1974.4 1560.23 1975.24 1560.03 Q1976.07 1559.84 1976.59 1559.36 Q1977.14 1558.87 1977.14 1558.2 Q1977.14 1557.91 1976.91 1555.52 Q1976.69 1553.14 1976.4 1550.37 Q1976.11 1547.57 1976.07 1547.18 L1959.52 1547.18 Q1958.01 1549.79 1956.94 1551.6 Q1955.88 1553.4 1955.5 1554.01 Q1955.11 1554.62 1954.88 1555.01 Q1954.66 1555.4 1954.53 1555.62 Q1953.6 1557.33 1953.6 1558.07 Q1953.6 1560.13 1956.69 1560.39 Q1957.75 1560.39 1957.75 1561.16 Q1957.75 1561.74 1957.49 1562.06 Q1957.23 1562.35 1957.01 1562.38 Q1956.82 1562.42 1956.49 1562.42 Q1955.43 1562.42 1953.21 1562.32 Q1950.99 1562.22 1949.89 1562.22 Q1948.96 1562.22 1947.03 1562.32 Q1945.09 1562.42 1944.22 1562.42 Q1943.84 1562.42 1943.61 1562.19 Q1943.39 1561.97 1943.39 1561.68 Q1943.39 1561.22 1943.45 1560.97 Q1943.55 1560.71 1943.8 1560.58 Q1944.06 1560.45 1944.19 1560.45 Q1944.32 1560.42 1944.77 1560.39 Q1947.22 1560.23 1949.12 1559.07 Q1951.05 1557.88 1952.89 1554.82 L1975.82 1516.3 Q1976.04 1515.91 1976.2 1515.72 Q1976.36 1515.52 1976.69 1515.36 Q1977.04 1515.2 1977.56 1515.2 Q1978.36 1515.2 1978.52 1515.46 Q1978.68 1515.69 1978.78 1516.78 L1982.81 1558 Q1982.9 1558.87 1982.97 1559.23 Q1983.06 1559.55 1983.48 1559.9 Q1983.93 1560.23 1984.74 1560.32 Q1985.58 1560.39 1987.12 1560.39 Q1987.7 1560.39 1987.93 1560.42 Q1988.15 1560.42 1988.38 1560.58 Q1988.64 1560.74 1988.64 1561.1 M1975.88 1545.12 L1973.79 1523.38 L1960.78 1545.12 L1975.88 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1995.24 1554.34 L1995.24 1552.9 Q2000.78 1552.9 2003.65 1549.94 Q2004.44 1549.94 2004.57 1550.12 Q2004.71 1550.3 2004.71 1551.14 L2004.71 1577.04 Q2004.71 1578.42 2005.38 1578.84 Q2006.06 1579.27 2009.01 1579.27 L2010.48 1579.27 L2010.48 1580.69 Q2008.85 1580.56 2002.99 1580.56 Q1997.13 1580.56 1995.53 1580.69 L1995.53 1579.27 L1997 1579.27 Q1999.9 1579.27 2000.6 1578.87 Q2001.3 1578.44 2001.3 1577.04 L2001.3 1553.12 Q1998.89 1554.34 1995.24 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1248.99 2352.76,1248.99 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,1019.25 2352.76,1019.25 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,789.506 2352.76,789.506 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,559.762 2352.76,559.762 \"/>\n<polyline clip-path=\"url(#clip713)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1510.68,330.018 2352.76,330.018 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1405.9 1510.68,123.472 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1248.99 1529.57,1248.99 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,1019.25 1529.57,1019.25 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,789.506 1529.57,789.506 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,559.762 1529.57,559.762 \"/>\n<polyline clip-path=\"url(#clip710)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1510.68,330.018 1529.57,330.018 \"/>\n<path clip-path=\"url(#clip710)\" d=\"M1314.26 1249.67 L1358.77 1249.67 L1358.77 1255.57 L1314.26 1255.57 L1314.26 1249.67 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1375.13 1269.01 L1386.59 1269.01 L1386.59 1229.46 L1374.12 1231.96 L1374.12 1225.57 L1386.52 1223.07 L1393.53 1223.07 L1393.53 1269.01 L1404.99 1269.01 L1404.99 1274.91 L1375.13 1274.91 L1375.13 1269.01 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1419.16 1266.09 L1426.48 1266.09 L1426.48 1274.91 L1419.16 1274.91 L1419.16 1266.09 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1456.76 1227.69 Q1451.34 1227.69 1448.6 1233.04 Q1445.89 1238.35 1445.89 1249.05 Q1445.89 1259.7 1448.6 1265.05 Q1451.34 1270.36 1456.76 1270.36 Q1462.21 1270.36 1464.92 1265.05 Q1467.66 1259.7 1467.66 1249.05 Q1467.66 1238.35 1464.92 1233.04 Q1462.21 1227.69 1456.76 1227.69 M1456.76 1222.14 Q1465.47 1222.14 1470.06 1229.05 Q1474.68 1235.92 1474.68 1249.05 Q1474.68 1262.14 1470.06 1269.04 Q1465.47 1275.92 1456.76 1275.92 Q1448.04 1275.92 1443.43 1269.04 Q1438.84 1262.14 1438.84 1249.05 Q1438.84 1235.92 1443.43 1229.05 Q1448.04 1222.14 1456.76 1222.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1315.75 1019.93 L1360.27 1019.93 L1360.27 1025.83 L1315.75 1025.83 L1315.75 1019.93 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1390.41 997.947 Q1384.99 997.947 1382.25 1003.29 Q1379.54 1008.61 1379.54 1019.3 Q1379.54 1029.96 1382.25 1035.31 Q1384.99 1040.62 1390.41 1040.62 Q1395.86 1040.62 1398.57 1035.31 Q1401.31 1029.96 1401.31 1019.3 Q1401.31 1008.61 1398.57 1003.29 Q1395.86 997.947 1390.41 997.947 M1390.41 992.392 Q1399.12 992.392 1403.7 999.302 Q1408.32 1006.18 1408.32 1019.3 Q1408.32 1032.39 1403.7 1039.3 Q1399.12 1046.18 1390.41 1046.18 Q1381.69 1046.18 1377.07 1039.3 Q1372.49 1032.39 1372.49 1019.3 Q1372.49 1006.18 1377.07 999.302 Q1381.69 992.392 1390.41 992.392 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1420.65 1036.35 L1427.97 1036.35 L1427.97 1045.17 L1420.65 1045.17 L1420.65 1036.35 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1443.32 993.329 L1470.86 993.329 L1470.86 999.232 L1449.75 999.232 L1449.75 1011.94 Q1451.27 1011.42 1452.8 1011.18 Q1454.33 1010.9 1455.86 1010.9 Q1464.54 1010.9 1469.61 1015.66 Q1474.68 1020.41 1474.68 1028.54 Q1474.68 1036.91 1469.47 1041.56 Q1464.26 1046.18 1454.78 1046.18 Q1451.52 1046.18 1448.11 1045.62 Q1444.75 1045.07 1441.13 1043.95 L1441.13 1036.91 Q1444.26 1038.61 1447.59 1039.44 Q1450.93 1040.27 1454.64 1040.27 Q1460.65 1040.27 1464.16 1037.11 Q1467.66 1033.95 1467.66 1028.54 Q1467.66 1023.12 1464.16 1019.96 Q1460.65 1016.8 1454.64 1016.8 Q1451.83 1016.8 1449.02 1017.43 Q1446.24 1018.05 1443.32 1019.37 L1443.32 993.329 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1388.91 768.204 Q1383.5 768.204 1380.75 773.551 Q1378.04 778.863 1378.04 789.558 Q1378.04 800.217 1380.75 805.565 Q1383.5 810.877 1388.91 810.877 Q1394.36 810.877 1397.07 805.565 Q1399.82 800.217 1399.82 789.558 Q1399.82 778.863 1397.07 773.551 Q1394.36 768.204 1388.91 768.204 M1388.91 762.648 Q1397.63 762.648 1402.21 769.558 Q1406.83 776.433 1406.83 789.558 Q1406.83 802.648 1402.21 809.558 Q1397.63 816.433 1388.91 816.433 Q1380.2 816.433 1375.58 809.558 Q1371 802.648 1371 789.558 Q1371 776.433 1375.58 769.558 Q1380.2 762.648 1388.91 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1419.16 806.606 L1426.48 806.606 L1426.48 815.426 L1419.16 815.426 L1419.16 806.606 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1456.76 768.204 Q1451.34 768.204 1448.6 773.551 Q1445.89 778.863 1445.89 789.558 Q1445.89 800.217 1448.6 805.565 Q1451.34 810.877 1456.76 810.877 Q1462.21 810.877 1464.92 805.565 Q1467.66 800.217 1467.66 789.558 Q1467.66 778.863 1464.92 773.551 Q1462.21 768.204 1456.76 768.204 M1456.76 762.648 Q1465.47 762.648 1470.06 769.558 Q1474.68 776.433 1474.68 789.558 Q1474.68 802.648 1470.06 809.558 Q1465.47 816.433 1456.76 816.433 Q1448.04 816.433 1443.43 809.558 Q1438.84 802.648 1438.84 789.558 Q1438.84 776.433 1443.43 769.558 Q1448.04 762.648 1456.76 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1390.41 538.46 Q1384.99 538.46 1382.25 543.807 Q1379.54 549.12 1379.54 559.814 Q1379.54 570.474 1382.25 575.821 Q1384.99 581.133 1390.41 581.133 Q1395.86 581.133 1398.57 575.821 Q1401.31 570.474 1401.31 559.814 Q1401.31 549.12 1398.57 543.807 Q1395.86 538.46 1390.41 538.46 M1390.41 532.905 Q1399.12 532.905 1403.7 539.814 Q1408.32 546.689 1408.32 559.814 Q1408.32 572.904 1403.7 579.814 Q1399.12 586.689 1390.41 586.689 Q1381.69 586.689 1377.07 579.814 Q1372.49 572.904 1372.49 559.814 Q1372.49 546.689 1377.07 539.814 Q1381.69 532.905 1390.41 532.905 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1420.65 576.863 L1427.97 576.863 L1427.97 585.682 L1420.65 585.682 L1420.65 576.863 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1443.32 533.842 L1470.86 533.842 L1470.86 539.745 L1449.75 539.745 L1449.75 552.453 Q1451.27 551.932 1452.8 551.689 Q1454.33 551.411 1455.86 551.411 Q1464.54 551.411 1469.61 556.168 Q1474.68 560.925 1474.68 569.05 Q1474.68 577.418 1469.47 582.071 Q1464.26 586.689 1454.78 586.689 Q1451.52 586.689 1448.11 586.133 Q1444.75 585.578 1441.13 584.467 L1441.13 577.418 Q1444.26 579.12 1447.59 579.953 Q1450.93 580.786 1454.64 580.786 Q1460.65 580.786 1464.16 577.626 Q1467.66 574.467 1467.66 569.05 Q1467.66 563.634 1464.16 560.474 Q1460.65 557.314 1454.64 557.314 Q1451.83 557.314 1449.02 557.939 Q1446.24 558.564 1443.32 559.884 L1443.32 533.842 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1375.13 350.036 L1386.59 350.036 L1386.59 310.487 L1374.12 312.987 L1374.12 306.598 L1386.52 304.098 L1393.53 304.098 L1393.53 350.036 L1404.99 350.036 L1404.99 355.938 L1375.13 355.938 L1375.13 350.036 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1419.16 347.119 L1426.48 347.119 L1426.48 355.938 L1419.16 355.938 L1419.16 347.119 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1456.76 308.716 Q1451.34 308.716 1448.6 314.064 Q1445.89 319.376 1445.89 330.07 Q1445.89 340.73 1448.6 346.077 Q1451.34 351.39 1456.76 351.39 Q1462.21 351.39 1464.92 346.077 Q1467.66 340.73 1467.66 330.07 Q1467.66 319.376 1464.92 314.064 Q1462.21 308.716 1456.76 308.716 M1456.76 303.161 Q1465.47 303.161 1470.06 310.071 Q1474.68 316.946 1474.68 330.07 Q1474.68 343.161 1470.06 350.07 Q1465.47 356.945 1456.76 356.945 Q1448.04 356.945 1443.43 350.07 Q1438.84 343.161 1438.84 330.07 Q1438.84 316.946 1443.43 310.071 Q1448.04 303.161 1456.76 303.161 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1228.89 804.838 Q1232.5 804.838 1235.81 807.511 Q1239.13 810.152 1241.16 814.467 Q1243.16 818.751 1243.16 823.356 L1243.16 834.564 L1259.64 838.654 Q1259.74 838.686 1260.16 838.783 Q1260.55 838.879 1260.77 838.879 Q1261.58 838.879 1261.77 837.881 Q1261.96 836.85 1261.96 834.564 Q1261.96 833.082 1262.22 832.857 Q1262.38 832.728 1262.67 832.728 Q1263.12 832.728 1263.45 832.857 Q1263.74 832.986 1263.83 833.243 Q1263.93 833.469 1263.96 833.63 Q1263.99 833.791 1263.99 834.048 Q1263.99 834.725 1263.93 836.174 Q1263.86 837.591 1263.86 838.332 L1263.8 842.551 L1263.99 850.924 Q1263.99 851.923 1263.19 851.923 Q1262.58 851.923 1262.32 851.665 Q1262.03 851.407 1262 851.117 Q1261.96 850.828 1261.96 850.087 Q1261.96 848.477 1261.87 847.51 Q1261.77 846.544 1261.64 845.932 Q1261.48 845.288 1261.03 844.966 Q1260.58 844.612 1260.19 844.451 Q1259.77 844.29 1258.84 844.064 L1223.41 835.24 Q1222.35 834.982 1222.19 834.982 Q1221.64 834.982 1221.45 835.304 Q1221.22 835.594 1221.13 836.432 Q1221 838.042 1221 839.266 Q1221 840.071 1220.97 840.393 Q1220.93 840.683 1220.77 840.94 Q1220.58 841.166 1220.19 841.166 Q1219.58 841.166 1219.32 840.908 Q1219.03 840.618 1219 840.296 Q1218.94 839.974 1218.94 839.201 L1218.94 817.817 Q1218.94 811.665 1221.87 808.251 Q1224.8 804.838 1228.89 804.838 M1227.31 810.957 Q1221 810.957 1221 819.942 L1221 826.255 Q1221 828.348 1221.38 828.863 Q1221.74 829.378 1223.51 829.829 L1241.45 834.306 L1241.45 824.998 Q1241.45 818.751 1237.94 814.854 Q1236.33 813.082 1232.98 812.02 Q1229.63 810.957 1227.31 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1218.16 754.469 L1234.98 758.623 Q1236.04 758.913 1236.17 759.106 Q1236.3 759.267 1236.3 759.783 Q1236.3 760.781 1235.62 760.781 Q1235.55 760.781 1234.72 760.684 Q1233.85 760.588 1232.27 760.588 Q1226.44 760.588 1222.99 763.422 Q1219.55 766.224 1219.55 771.216 Q1219.55 775.531 1221.74 779.879 Q1223.93 784.195 1227.5 787.286 Q1230.21 789.605 1233.62 791.312 Q1237.04 792.987 1240.16 793.792 Q1243.28 794.565 1245.64 794.919 Q1247.99 795.273 1249.69 795.273 Q1252.17 795.273 1254.27 794.758 Q1256.36 794.211 1257.84 793.244 Q1259.29 792.278 1260.42 791.055 Q1261.51 789.798 1262.16 788.349 Q1262.8 786.868 1263.12 785.386 Q1263.41 783.905 1263.41 782.359 Q1263.41 776.143 1258.58 770.217 Q1254.62 765.515 1248.15 763.551 Q1247.5 763.39 1247.5 762.713 Q1247.5 761.908 1248.15 761.908 Q1248.28 761.908 1248.92 762.069 Q1249.53 762.23 1250.79 762.713 Q1252.01 763.196 1253.4 763.937 Q1254.78 764.678 1256.52 766.063 Q1258.26 767.448 1259.77 769.155 Q1262.29 772.053 1263.86 775.725 Q1265.44 779.396 1265.44 783.422 Q1265.44 788.446 1263.22 792.504 Q1261 796.562 1256.84 798.945 Q1252.69 801.296 1247.37 801.296 Q1241.77 801.296 1236.26 798.719 Q1230.76 796.143 1226.67 792.053 Q1222.58 787.963 1220.03 782.552 Q1217.49 777.142 1217.49 771.731 Q1217.49 769.67 1218.03 767.834 Q1218.58 765.998 1219.26 764.903 Q1219.94 763.776 1220.93 762.778 Q1221.9 761.779 1222.35 761.457 Q1222.8 761.103 1223.35 760.781 L1218.29 756.176 Q1217.49 755.37 1217.49 755.177 Q1217.49 754.791 1217.71 754.63 Q1217.94 754.469 1218.16 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1262.67 709.347 Q1263.28 709.347 1263.61 709.605 Q1263.9 709.83 1263.96 710.056 Q1263.99 710.249 1263.99 710.539 Q1263.99 711.376 1263.9 714.275 Q1263.8 717.173 1263.8 718.011 Q1263.8 719.363 1263.9 722.133 Q1263.99 724.903 1263.99 726.255 Q1263.99 727.157 1263.25 727.157 Q1262.77 727.157 1262.51 727.061 Q1262.22 726.964 1262.12 726.706 Q1262 726.416 1262 726.255 Q1261.96 726.062 1261.96 725.579 Q1261.96 724.935 1261.9 724.259 Q1261.8 723.582 1261.61 722.745 Q1261.42 721.908 1260.93 721.392 Q1260.45 720.845 1259.77 720.845 Q1259.48 720.845 1257.1 721.07 Q1254.72 721.296 1251.95 721.586 Q1249.15 721.875 1248.76 721.908 L1248.76 738.461 Q1251.37 739.975 1253.17 741.038 Q1254.98 742.101 1255.59 742.487 Q1256.2 742.874 1256.59 743.099 Q1256.97 743.325 1257.2 743.453 Q1258.9 744.387 1259.64 744.387 Q1261.71 744.387 1261.96 741.296 Q1261.96 740.233 1262.74 740.233 Q1263.32 740.233 1263.64 740.49 Q1263.93 740.748 1263.96 740.973 Q1263.99 741.167 1263.99 741.489 Q1263.99 742.552 1263.9 744.774 Q1263.8 746.996 1263.8 748.091 Q1263.8 749.025 1263.9 750.957 Q1263.99 752.89 1263.99 753.759 Q1263.99 754.146 1263.77 754.371 Q1263.54 754.597 1263.25 754.597 Q1262.8 754.597 1262.54 754.532 Q1262.29 754.436 1262.16 754.178 Q1262.03 753.92 1262.03 753.791 Q1262 753.663 1261.96 753.212 Q1261.8 750.764 1260.64 748.864 Q1259.45 746.932 1256.39 745.096 L1217.87 722.165 Q1217.49 721.94 1217.29 721.779 Q1217.1 721.618 1216.94 721.296 Q1216.78 720.941 1216.78 720.426 Q1216.78 719.621 1217.04 719.46 Q1217.26 719.299 1218.36 719.202 L1259.58 715.177 Q1260.45 715.08 1260.8 715.016 Q1261.13 714.919 1261.48 714.5 Q1261.8 714.049 1261.9 713.244 Q1261.96 712.407 1261.96 710.861 Q1261.96 710.281 1262 710.056 Q1262 709.83 1262.16 709.605 Q1262.32 709.347 1262.67 709.347 M1246.7 722.101 L1224.96 724.194 L1246.7 737.205 L1246.7 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1282.27 702.744 Q1281.44 702.744 1281.19 702.676 Q1280.94 702.586 1280.56 702.226 L1270.68 693.366 Q1265.23 688.519 1260.47 688.519 Q1257.38 688.519 1255.17 690.142 Q1252.96 691.743 1252.96 694.696 Q1252.96 696.725 1254.2 698.438 Q1255.44 700.151 1257.65 700.941 Q1257.61 700.805 1257.61 700.332 Q1257.61 699.182 1258.33 698.551 Q1259.05 697.897 1260.02 697.897 Q1261.26 697.897 1261.87 698.709 Q1262.45 699.498 1262.45 700.287 Q1262.45 700.602 1262.39 701.031 Q1262.32 701.437 1261.69 702.09 Q1261.03 702.744 1259.88 702.744 Q1256.66 702.744 1254.09 700.309 Q1251.52 697.852 1251.52 694.11 Q1251.52 689.871 1254.04 687.098 Q1256.55 684.303 1260.47 684.303 Q1261.84 684.303 1263.11 684.731 Q1264.35 685.137 1265.32 685.701 Q1266.29 686.242 1267.84 687.73 Q1269.4 689.218 1270.5 690.412 Q1271.61 691.607 1273.95 694.29 L1278.71 699.182 L1278.71 690.863 Q1278.71 686.805 1278.35 686.49 Q1277.69 686.039 1274.24 685.475 L1274.24 684.303 L1282.27 685.611 L1282.27 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1582.08 3.35044 L1616.83 3.35044 L1616.83 10.237 L1590.26 10.237 L1590.26 28.061 L1614.24 28.061 L1614.24 34.9475 L1590.26 34.9475 L1590.26 63.8304 L1582.08 63.8304 L1582.08 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1624.17 45.9254 L1624.17 18.4603 L1631.62 18.4603 L1631.62 45.6419 Q1631.62 52.0828 1634.13 55.3235 Q1636.64 58.5238 1641.67 58.5238 Q1647.7 58.5238 1651.19 54.6754 Q1654.71 50.827 1654.71 44.1836 L1654.71 18.4603 L1662.16 18.4603 L1662.16 63.8304 L1654.71 63.8304 L1654.71 56.8629 Q1652 60.9948 1648.39 63.0203 Q1644.83 65.0052 1640.09 65.0052 Q1632.27 65.0052 1628.22 60.1441 Q1624.17 55.283 1624.17 45.9254 M1642.92 17.3666 L1642.92 17.3666 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1674.28 18.4603 L1709.68 18.4603 L1709.68 25.2658 L1681.65 57.8756 L1709.68 57.8756 L1709.68 63.8304 L1673.26 63.8304 L1673.26 57.0249 L1701.3 24.4151 L1674.28 24.4151 L1674.28 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1717.82 18.4603 L1753.23 18.4603 L1753.23 25.2658 L1725.2 57.8756 L1753.23 57.8756 L1753.23 63.8304 L1716.81 63.8304 L1716.81 57.0249 L1744.84 24.4151 L1717.82 24.4151 L1717.82 18.4603 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1783.49 68.0434 Q1780.33 76.1452 1777.33 78.6162 Q1774.33 81.0873 1769.31 81.0873 L1763.35 81.0873 L1763.35 74.8489 L1767.73 74.8489 Q1770.81 74.8489 1772.51 73.3906 Q1774.21 71.9322 1776.28 66.504 L1777.61 63.1013 L1759.26 18.4603 L1767.16 18.4603 L1781.34 53.9462 L1795.52 18.4603 L1803.42 18.4603 L1783.49 68.0434 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1834.25 11.4117 L1823.15 41.51 L1845.39 41.51 L1834.25 11.4117 M1829.63 3.35044 L1838.9 3.35044 L1861.95 63.8304 L1853.45 63.8304 L1847.94 48.3155 L1820.68 48.3155 L1815.17 63.8304 L1806.54 63.8304 L1829.63 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1899.47 35.4741 Q1902.1 36.3653 1904.57 39.282 Q1907.08 42.1986 1909.59 47.3027 L1917.9 63.8304 L1909.11 63.8304 L1901.37 48.3155 Q1898.37 42.2391 1895.54 40.2542 Q1892.74 38.2692 1887.88 38.2692 L1878.97 38.2692 L1878.97 63.8304 L1870.78 63.8304 L1870.78 3.35044 L1889.26 3.35044 Q1899.63 3.35044 1904.73 7.68491 Q1909.84 12.0194 1909.84 20.7693 Q1909.84 26.4811 1907.16 30.2484 Q1904.53 34.0158 1899.47 35.4741 M1878.97 10.0749 L1878.97 31.5447 L1889.26 31.5447 Q1895.17 31.5447 1898.17 28.8306 Q1901.21 26.076 1901.21 20.7693 Q1901.21 15.4626 1898.17 12.789 Q1895.17 10.0749 1889.26 10.0749 L1878.97 10.0749 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M1914.01 3.35044 L1965.17 3.35044 L1965.17 10.237 L1943.7 10.237 L1943.7 63.8304 L1935.48 63.8304 L1935.48 10.237 L1914.01 10.237 L1914.01 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2030.94 40.4256 Q2030.94 46.492 2027.82 52.1895 Q2024.75 57.887 2019.91 61.3301 Q2015.11 64.7732 2010.28 64.7732 Q2004.83 64.7732 2002 59.1167 Q1996.87 79.6523 1996.59 80.1852 Q1995.4 81.9477 1993.68 81.9477 Q1992.61 81.9477 1991.96 81.2919 Q1991.3 80.677 1991.3 79.6933 Q1991.34 79.3654 1991.59 78.3406 L1999.78 45.3443 Q2001.67 37.6793 2007.37 32.2277 Q2013.11 26.7351 2019.25 26.7351 Q2024.13 26.7351 2027.53 30.3832 Q2030.94 34.0312 2030.94 40.4256 M2024.91 36.8185 Q2024.91 32.7196 2023.27 30.6701 Q2021.63 28.5797 2019.09 28.5797 Q2016.75 28.5797 2013.93 30.4652 Q2011.14 32.3507 2008.68 36.5316 Q2007.37 38.9499 2006.42 41.9422 Q2005.48 44.9344 2003.64 52.3125 Q2002.98 55.2637 2002.98 55.4276 Q2002.98 55.7555 2003.15 56.4934 Q2003.35 57.2312 2003.84 58.3789 Q2004.37 59.4856 2005.11 60.4693 Q2005.85 61.4531 2007.2 62.1909 Q2008.56 62.8877 2010.2 62.8877 Q2012.74 62.8877 2015.44 60.8382 Q2018.19 58.7478 2020.2 54.9358 Q2021.88 51.8616 2023.39 46.0821 Q2024.91 40.2616 2024.91 36.8185 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2069.41 26.157 L2121.34 26.157 L2121.34 32.9625 L2069.41 32.9625 L2069.41 26.157 M2069.41 42.6847 L2121.34 42.6847 L2121.34 49.5713 L2069.41 49.5713 L2069.41 42.6847 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2182.88 8.73814 Q2176.56 8.73814 2173.36 14.9765 Q2170.2 21.1744 2170.2 33.6512 Q2170.2 46.0875 2173.36 52.3259 Q2176.56 58.5238 2182.88 58.5238 Q2189.24 58.5238 2192.4 52.3259 Q2195.6 46.0875 2195.6 33.6512 Q2195.6 21.1744 2192.4 14.9765 Q2189.24 8.73814 2182.88 8.73814 M2182.88 2.25669 Q2193.05 2.25669 2198.39 10.318 Q2203.78 18.3388 2203.78 33.6512 Q2203.78 48.9231 2198.39 56.9844 Q2193.05 65.0052 2182.88 65.0052 Q2172.71 65.0052 2167.32 56.9844 Q2161.97 48.9231 2161.97 33.6512 Q2161.97 18.3388 2167.32 10.318 Q2172.71 2.25669 2182.88 2.25669 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2218.16 53.5411 L2226.71 53.5411 L2226.71 63.8304 L2218.16 63.8304 L2218.16 53.5411 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip710)\" d=\"M2242.47 3.35044 L2281.35 3.35044 L2281.35 6.83422 L2259.4 63.8304 L2250.85 63.8304 L2271.51 10.237 L2242.47 10.237 L2242.47 3.35044 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip713)\" cx=\"2271.2\" cy=\"1020.76\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2220.81\" cy=\"932.463\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2209.58\" cy=\"642.796\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2191.61\" cy=\"726.148\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2270.22\" cy=\"724.435\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2245.58\" cy=\"1010.17\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2164.22\" cy=\"586.092\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2208.05\" cy=\"510.689\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2217.57\" cy=\"901.015\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2223.3\" cy=\"664.957\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2213.16\" cy=\"838.529\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2209.98\" cy=\"244.464\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2204.18\" cy=\"880.205\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2231.94\" cy=\"1218.15\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"2206.78\" cy=\"779.617\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1834.82\" cy=\"873.312\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1912.67\" cy=\"1168.86\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1907.03\" cy=\"942.02\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1832.52\" cy=\"1038.47\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1950.12\" cy=\"905.212\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1779.81\" cy=\"855.581\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1828.14\" cy=\"846.648\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1846.75\" cy=\"699.881\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1939.12\" cy=\"1112.31\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1795.05\" cy=\"1139.18\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1803.25\" cy=\"602.019\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1904.1\" cy=\"1041.26\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1821.9\" cy=\"684.303\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1817.28\" cy=\"754.865\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1985.51\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1900.37\" cy=\"948.955\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1731.21\" cy=\"767.428\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1687.55\" cy=\"902.332\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1731.55\" cy=\"736.262\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1786.59\" cy=\"983.044\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1574.16\" cy=\"538.089\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1729.36\" cy=\"601.451\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1764.85\" cy=\"1037.31\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1704.49\" cy=\"889.823\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1677.05\" cy=\"650.049\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1805.6\" cy=\"1067.76\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1744.39\" cy=\"1019.92\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1591.48\" cy=\"159.767\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1703.79\" cy=\"690.587\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip713)\" cx=\"1709.86\" cy=\"618.814\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n</svg>\n","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"We can see that the two different vigilance values result in similar resutls on the whole, though they differ in how they classify certain samples that straddle the border between","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"\"assets/options-cover.png\"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/options/","page":"ART Options Example","title":"ART Options Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/data_config.jl\"","category":"page"},{"location":"examples/adaptive_resonance/data_config/#data_config","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Overview","page":"ART DataConfig Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"In their derivations, ART modules have some special requirements when it comes to their input features. FuzzyART in particular, and subsequently its derivatives, has a requirement that the inputs be bounded and complement coded. This is due to some consequences such as weight decay that occur when using real-valued patterns rather than binary ones (and hence operations like fuzzy membership).","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Preprocessing of the features occurs as follows:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"The features are linearly normalized from 0 to 1 with respect to each feature with linear_normalization. This is done according to some known bounds that each feature has.\nThe features are then complement coded, meaning that the feature vector is appended to its 1-complement (i.e., x rightarrow leftx 1-xright) with complement_code.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"This preprocessing has the ultimate consequence that the input features must be bounded. This many not be a problem in some offline applications with a fixed dataset, but in others where the bounds are not known, techniques such as sigmoidal limiting are often used to place an artificial limit.","category":"page"},{"location":"examples/adaptive_resonance/data_config/#DataConfig","page":"ART DataConfig Example","title":"DataConfig","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Regardless, this process requires some a-priori knowledge about the minimums and maximums that each feature can have, which is stored as a preprocessing configuration. This preprocessing configuration is saved in every ART module as a DataConfig object called config, which we can see is uninitialized at first:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Load the library\nusing AdaptiveResonance\n\n# Create a new ART module and inspect its uninitialized data config `config`\nart = FuzzyART()\nart.config","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(false, Float64[], Float64[], 0, 0)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We see that the type of art.config is DataConfig. We can see what the internal elements of this struct are with fieldnames:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"fieldnames(AdaptiveResonance.DataConfig)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"(:setup, :mins, :maxs, :dim, :dim_comp)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We see that the dataconfig has a boolean setup flag, minimum and maximum feature vectors, dimensionality of the data, and the complement coded dimensionality (twice the size of the original dimension).","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Automatic-Configuration","page":"ART DataConfig Example","title":"Automatic Configuration","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"In batch training mode, the minimums and maximums are detected automatically; the minimum and maximum values for every feature are saved and used for the preprocessing step at every subsequent iteration.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Load data\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"note: Note\nThis automatic detection of feature characteristics only occurs if the config is not already setup. If it is setup beforehand, then that config is used instead.","category":"page"},{"location":"examples/adaptive_resonance/data_config/#Manual-Configuration","page":"ART DataConfig Example","title":"Manual Configuration","text":"","category":"section"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"As mentioned before, we may not always have the luxury of having a representative dataset in advance. Alternatively, we may know the bounds of the features but wish to run incrementally rather than in batch. In these cases, we can setup the config the various DataConfig constructors.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"For example, if the features are all bounded from -1 to 1, we have to also specify the original dimension of the data in DataConfig(min, max, dim):","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Reinitialize the FuzzyART module\nart = FuzzyART()\n# Tell the module that we have 20 features all ranging from -1 to 1\nart.config = DataConfig(-1, 1, 20)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(true, [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 20, 40)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"If the features differ in their ranges, we can specify with DataConfig(mins, maxs):","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"# Assume some minimum and maximum values for each feature\nmins = [-1,-2,-1.5]\nmaxs = [3, 2, 1]\nart.config = DataConfig(mins, maxs)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"DataConfig(true, [-1.0, -2.0, -1.5], [3.0, 2.0, 1.0], 3, 6)","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"Here, we don't need to specify the feature dimensionality because it is inferred from the length of the range values.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"note: Note\nAfter the first training run, the weights of the network are set to the size of the complement coded dimension. If you wish to change the dimension of the features, you will need to create a new network.","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/data_config/","page":"ART DataConfig Example","title":"ART DataConfig Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/artmap/sfam_iris.jl\"","category":"page"},{"location":"examples/artmap/sfam_iris/#sfam_iris","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"","category":"section"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"SFAM is a supervised algorithm by definition, so we use it to map a set of features to a set of supervisory labels. We will do so by training and testing on the ubiquitous Iris dataset and seeing how well the SFAM module generalizes the data.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Get the iris dataset as a DataFrame\niris = Iris()\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = Matrix(iris.features)', vec(Matrix{String}(iris.targets))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], [\"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\"])","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, labels)\nunique(labels)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"(([5.6 5.6 4.8 5.4 4.6 5.4 5.6 4.7 6.9 7.2 5.6 6.0 5.0 5.2 6.3 5.0 6.2 4.5 6.9 7.9 6.3 5.4 5.4 5.3 5.9 6.3 6.4 5.7 5.0 6.5 5.2 6.1 6.7 5.5 5.8 7.7 5.1 6.2 6.1 5.5 7.2 5.8 5.4 6.3 5.1 6.3 6.0 4.4 5.0 5.1 6.8 6.1 6.3 5.0 6.7 5.6 5.8 7.7 5.7 5.6 6.0 6.9 6.0 5.8 6.7 5.1 6.2 4.8 5.9 7.4 5.1 4.6 6.5 6.3 6.5 6.5 6.7 7.1 4.4 6.6 6.9 6.3 6.6 4.8 5.1 7.7 7.7 4.9 4.6 5.5 4.9 5.2 4.7 6.4 5.7 4.8 7.6 6.4 5.8 5.1 4.8 5.1 5.8 5.4 7.0; 2.5 2.8 3.0 3.7 3.6 3.4 2.7 3.2 3.1 3.6 3.0 3.0 3.5 2.7 3.4 3.0 2.8 2.3 3.1 3.8 2.7 3.4 3.0 3.7 3.0 2.8 2.7 2.8 3.4 3.2 3.4 2.9 3.1 2.3 2.7 3.0 3.5 2.2 2.6 2.5 3.0 2.7 3.9 2.5 3.5 2.3 3.4 3.2 3.6 3.8 3.0 2.8 3.3 2.3 3.1 3.0 2.8 2.8 2.6 2.9 2.2 3.1 2.7 2.6 2.5 2.5 3.4 3.4 3.2 2.8 3.3 3.4 3.0 2.5 2.8 3.0 3.0 3.0 3.0 2.9 3.2 2.9 3.0 3.4 3.4 2.6 3.8 3.1 3.2 2.6 3.1 3.5 3.2 3.1 2.8 3.0 3.0 3.2 2.7 3.8 3.1 3.8 4.0 3.9 3.2; 3.9 4.9 1.4 1.5 1.0 1.5 4.2 1.6 5.1 6.1 4.1 4.8 1.3 3.9 5.6 1.6 4.8 1.3 4.9 6.4 4.9 1.7 4.5 1.5 5.1 5.1 5.3 4.1 1.6 5.1 1.4 4.7 4.4 4.0 5.1 6.1 1.4 4.5 5.6 4.0 5.8 5.1 1.7 4.9 1.4 4.4 4.5 1.3 1.4 1.9 5.5 4.7 4.7 3.3 4.7 4.5 5.1 6.7 3.5 3.6 5.0 5.4 5.1 4.0 5.8 3.0 5.4 1.9 4.8 6.1 1.7 1.4 5.2 5.0 4.6 5.5 5.0 5.9 1.3 4.6 5.7 5.6 4.4 1.6 1.5 6.9 6.7 1.5 1.4 4.4 1.5 1.5 1.3 5.5 4.5 1.4 6.6 4.5 4.1 1.6 1.6 1.5 1.2 1.3 4.7; 1.1 2.0 0.1 0.2 0.2 0.4 1.3 0.2 2.3 2.5 1.3 1.8 0.3 1.4 2.4 0.2 1.8 0.3 1.5 2.0 1.8 0.2 1.5 0.2 1.8 1.5 1.9 1.3 0.4 2.0 0.2 1.4 1.4 1.3 1.9 2.3 0.2 1.5 1.4 1.3 1.6 1.9 0.4 1.5 0.3 1.3 1.6 0.2 0.2 0.4 2.1 1.2 1.6 1.0 1.5 1.5 2.4 2.0 1.0 1.3 1.5 2.1 1.6 1.2 1.8 1.1 2.3 0.2 1.8 1.9 0.5 0.3 2.0 1.9 1.5 1.8 1.7 2.1 0.2 1.3 2.3 1.8 1.4 0.2 0.2 2.3 2.2 0.1 0.2 1.2 0.1 0.2 0.2 1.8 1.3 0.3 2.1 1.5 1.0 0.2 0.2 0.3 0.2 0.4 1.4], [2, 3, 1, 1, 1, 1, 2, 1, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 3, 1, 2, 1, 3, 3, 3, 2, 1, 3, 1, 2, 2, 2, 3, 3, 1, 2, 3, 2, 3, 3, 1, 2, 1, 2, 2, 1, 1, 1, 3, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 1, 2, 3, 1, 1, 3, 3, 2, 3, 2, 3, 1, 2, 3, 3, 2, 1, 1, 3, 3, 1, 1, 2, 1, 1, 1, 3, 2, 1, 3, 2, 2, 1, 1, 1, 1, 1, 2]), ([6.3 5.1 5.0 5.0 7.2 6.4 6.7 5.9 5.5 6.1 6.8 5.5 6.4 6.0 6.7 5.0 5.7 6.2 4.9 4.6 6.1 6.0 5.7 5.7 6.8 5.2 7.3 5.8 5.7 4.4 6.5 6.7 4.3 6.1 5.5 5.5 4.9 4.9 5.0 6.4 5.7 6.7 5.0 6.4 4.9; 3.3 3.7 3.4 3.5 3.2 2.8 3.3 3.0 2.4 3.0 2.8 4.2 2.9 2.9 3.0 3.2 4.4 2.9 3.1 3.1 3.0 2.2 2.5 3.0 3.2 4.1 2.9 2.7 2.9 2.9 3.0 3.1 3.0 2.8 3.5 2.4 2.4 3.0 2.0 3.2 3.8 3.3 3.3 2.8 2.5; 6.0 1.5 1.5 1.6 6.0 5.6 5.7 4.2 3.7 4.6 4.8 1.4 4.3 4.5 5.2 1.2 1.5 4.3 1.5 1.5 4.9 4.0 5.0 4.2 5.9 1.5 6.3 3.9 4.2 1.4 5.8 5.6 1.1 4.0 1.3 3.8 3.3 1.4 3.5 5.3 1.7 5.7 1.4 5.6 4.5; 2.5 0.4 0.2 0.6 1.8 2.1 2.1 1.5 1.0 1.4 1.4 0.2 1.3 1.5 2.3 0.2 0.4 1.3 0.1 0.2 1.8 1.0 2.0 1.2 2.3 0.1 1.8 1.2 1.3 0.2 2.2 2.4 0.1 1.3 0.2 1.1 1.0 0.2 1.0 2.3 0.3 2.5 0.2 2.2 1.7], [3, 1, 1, 1, 3, 3, 3, 2, 2, 2, 2, 1, 2, 2, 3, 1, 1, 2, 1, 1, 3, 2, 3, 2, 3, 1, 3, 2, 2, 1, 3, 3, 1, 2, 1, 2, 2, 1, 2, 3, 1, 3, 1, 3, 3]))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Now, we can create our SFAM module. We'll do so with the default contstructor, though the module itself has many options that can be altered during instantiation.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Create the SFAM module\nart = SFAM()\n\n# Change the match tracking parameter after instantiation\nart.opts.epsilon = 1e-2","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"0.01","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We can train the model in batch mode upon the data and supervisory labels. We do so by directly passing the integer vector of labels to the training method. Just as in other modules, we can extract the SFAM's prescribed labels from the training method, which should match up to the training labels as we will see later.","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Train in supervised mode by directly passing the labels.\ny_hat_train = train!(art, X_train, y_train)\nprintln(\"Training labels: \",  size(y_hat_train), \" \", typeof(y_hat_train))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"We can classify the testing data to see how we generalize. At the same time, we can see the effect of getting the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Classify both ways\ny_hat = AdaptiveResonance.classify(art, X_test)\ny_hat_bmu = AdaptiveResonance.classify(art, X_test, get_bmu=true)\n\n# Check the shape and type of the output labels\nprintln(\"Testing labels: \",  size(y_hat), \" \", typeof(y_hat))\nprintln(\"Testing labels with bmu: \",  size(y_hat_bmu), \" \", typeof(y_hat_bmu))","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Testing labels: (45,) Vector{Int64}\nTesting labels with bmu: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Finally, we can calculate the performances (number correct over total) of the model upon all three regimes:","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training data\nTesting data\nTesting data with get_bmu=true","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train = performance(y_hat_train, y_train)\nperf_test = performance(y_hat, y_test)\nperf_test_bmu = performance(y_hat_bmu, y_test)\n\n# Format each performance number for comparison\n@printf \"Training performance: %.4f\\n\" perf_train\n@printf \"Testing performance: %.4f\\n\" perf_test\n@printf \"Best-matching unit testing performance: %.4f\\n\" perf_test_bmu","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"Training performance: 1.0000\nTesting performance: 0.9333\nBest-matching unit testing performance: 0.9333\n","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"","category":"page"},{"location":"examples/artmap/sfam_iris/","page":"Supervised Simplified FuzzyARTMAP (SFAM) Example","title":"Supervised Simplified FuzzyARTMAP (SFAM) Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"getting-started/whatisart/#Background","page":"Background","title":"Background","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"This page provides a theoretical overview of Adaptive Resonance Theory and what this project aims to accomplish.","category":"page"},{"location":"getting-started/whatisart/#What-is-Adaptive-Resonance-Theory?","page":"Background","title":"What is Adaptive Resonance Theory?","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Adaptive Resonance Theory (commonly abbreviated to ART) is both a neurological theory and a family of neurogenitive neural network models for machine learning.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART began as a neurocognitive theory of how fields of cells can continuously learn stable representations, and it evolved into the basis for a myriad of practical machine learning algorithms. Pioneered by Stephen Grossberg and Gail Carpenter, the field has had contributions across many years and from many disciplines, resulting in a plethora of engineering applications and theoretical advancements that have enabled ART-based algorithms to compete with many other modern learning and clustering algorithms.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Because of the high degree of interplay between the neurocognitive theory and the engineering models born of it, the term ART is frequently used to refer to both in the modern day (for better or for worse).","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Stephen Grossberg's has recently released a book summarizing the work of him, his wife and colleague Gail Carpenter, and his other colleagues on Adaptive Resonance Theory in his book Conscious Brain, Resonant Mind.","category":"page"},{"location":"getting-started/whatisart/#ART-Basics","page":"Background","title":"ART Basics","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"(Image: art)","category":"page"},{"location":"getting-started/whatisart/#ART-Dynamics","page":"Background","title":"ART Dynamics","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Nearly every ART model shares a basic set of dynamics:","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART models typically have two layers/fields denoted F1 and F2.\nThe F1 field is the feature representation field.  Most often, it is simply the input feature sample itself (after some necessary preprocessing).\nThe F2 field is the category representation field.  With some exceptions, each node in the F2 field generally represents its own category.  This is most easily understood as a weight vector representing a prototype for a class or centroid of a cluster.\nAn activation function is used to find the order of categories \"most activated\" for a given sample in F1.\nIn order of highest activation, a match function is used to compute the agreement between the sample and the categories.\nIf the match function for a category evaluates to a value above a threshold known as the vigilance parameter (rho), the weights of that category may be updated according to a learning rule.\nIf there is complete mismatch across all categories, then a new categories is created according to some instantiation rule.","category":"page"},{"location":"getting-started/whatisart/#ART-Considerations","page":"Background","title":"ART Considerations","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"In addition to the dynamics typical of an ART model, you must know:","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"ART models are inherently designed for unsupervised learning (i.e., learning in the absense of supervisory labels for samples).  This is also known as clustering.\nART models are capable of supervised learning and reinforcement learning through some redesign and/or combination of ART models.  For example, ARTMAP models are combinations of two ART models in a special way, one learning feature-to-category mappings and another learning category-to-label mappingss.  ART modules are used for reinforcement learning by representing the mappings between state, value, and action spaces with ART dynamics.\nAlmost all ART models face the problem of the appropriate selection of the vigilance parameter, which may depend in its optimality according to the problem.\nBeing a class of neurogenitive neural network models, ART models gain the ability for theoretically infinite capacity along with the problem of \"category proliferation,\" which is the undesirable increase in the number of categories as the model continues to learn, leading to increasing computational time.  In contrast, while the evaluation time of a fixed architecture deep neural network is always exactly the same, there exist upper bounds in their representational capacity.\nNearly every ART model requires feature normalization (i.e., feature elements lying within 01) and a process known as complement coding where the feature vector is appended to its vector complement 1-barx. This is because real-numbered vectors can be arbitrarily close to one another, hindering learning performance, which requires a degree of contrast enhancement between samples to ensure their separation.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"To learn about their implementations, nearly every practical ART model is listed in a recent ART survey paper by Leonardo Enzo Brito da Silva.","category":"page"},{"location":"getting-started/whatisart/#History-and-Development","page":"Background","title":"History and Development","text":"","category":"section"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"At a high level, ART began with a neural network model known as the Grossberg Network named after Stephen Grossberg. This network treats the firing of neurons in frequency domain as basic shunting models, which are recurrently connected to increase their own activity while suppressing the activities of others nearby (i.e., on-center, off-surround). Using this shunting model, Grossberg shows that autonomous, associative learning can occur with what are known as instar networks.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"By representing categories as a field of instar networks, new categories could be optimally learned by the instantiation of new neurons. However, it was shown that the learning stability of Grossberg Networks degrades as the number of represented categories increases. Discoveries in the neurocognitive theory and breakthroughs in their implementation led to the introduction of a recurrent connections between the two fields of the network to stabilize the learning. These breakthroughs were based upon the discovery that autonomous learning depends on the interplay and agreement between perception and expectation, frequently referred to as bottom-up and top-down processes. Furthermore, it is resonance between these states in the frequency domain that gives rise to conscious experiences and that permit adaptive weights to change, leading to the phenomea of attention and learning. The theory has many explanatory consequences in psychology, such as why attention is required for learning, but its consequences in the engineering models are that it stabilizes learning in cooperative-competitive dynamics, such as interconnected fields of neurons, which are most often chaotic.","category":"page"},{"location":"getting-started/whatisart/","page":"Background","title":"Background","text":"Chapters 18 and 19 of the book by Neural Network Design by Hagan, Demuth, Beale, and De Jesus provide a good theoretical basis for learning how these network models were eventually implemented into the first binary-vector implementation of ART1.","category":"page"},{"location":"man/dev-index/#dev-main-index","page":"Internals","title":"Developer Index","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"This page lists the types and functions that are internal to the AdaptiveResonance.jl package. Because they are not part of the public API, these names might change relatively frequently between versions and so should not be relied upon.","category":"page"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"All internal names are listed in the Index, and each of these entries link to the docstrings in the Docs section.","category":"page"},{"location":"man/dev-index/#Index","page":"Internals","title":"Index","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"This section contains a list of internal names that link to their corresponding Documentation.","category":"page"},{"location":"man/dev-index/#dev-index-methods","page":"Internals","title":"Methods","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:function]","category":"page"},{"location":"man/dev-index/#dev-index-types","page":"Internals","title":"Types","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:type]","category":"page"},{"location":"man/dev-index/#dev-index-types-2","page":"Internals","title":"Constants","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Pages   = [\"dev-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:constant]","category":"page"},{"location":"man/dev-index/#dev-index-docs","page":"Internals","title":"Docs","text":"","category":"section"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Documentation for all internal names are listed below.","category":"page"},{"location":"man/dev-index/","page":"Internals","title":"Internals","text":"Modules = [AdaptiveResonance]\nPublic = false","category":"page"},{"location":"man/dev-index/#AdaptiveResonance.ACTIVATION_FUNCTIONS_DOCS","page":"Internals","title":"AdaptiveResonance.ACTIVATION_FUNCTIONS_DOCS","text":"ACTIVATIONFUNCTIONSDOCS\n\nDescription\n\nCommon docstring for listing available activation functions.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ARTIterator","page":"Internals","title":"AdaptiveResonance.ARTIterator","text":"ARTIterator\n\nDescription\n\nAcceptable iterators for ART module training and inference\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ART_DIM","page":"Internals","title":"AdaptiveResonance.ART_DIM","text":"ART_DIM\n\nDescription\n\nAdaptiveResonance.jl convention for which 2-D dimension contains the feature dimension.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ART_SAMPLES","page":"Internals","title":"AdaptiveResonance.ART_SAMPLES","text":"ART_SAMPLES\n\nDescription\n\nAdaptiveResonance.jl convention for which 2-D dimension contains the number of samples.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.MATCH_FUNCTIONS_DOCS","page":"Internals","title":"AdaptiveResonance.MATCH_FUNCTIONS_DOCS","text":"MATCHFUNCTIONSDOCS\n\nDescription\n\nCommon docstring for listing available match functions.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARGS_MATRIX_REPLACE","page":"Internals","title":"AdaptiveResonance._ARGS_MATRIX_REPLACE","text":"ARGSMATRIX_REPLACE\n\nDescription\n\nCommon docstring: shared arguments string for functions updating a column in a matrix.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_ART","page":"Internals","title":"AdaptiveResonance._ARG_ART","text":"ARGART\n\nDescription\n\nCommon docstring: shared argument docstring for ART module arguments.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_ART_X_W","page":"Internals","title":"AdaptiveResonance._ARG_ART_X_W","text":"ARGARTXW\n\nDescription\n\nCommon docstring: shared arguments string for methods using an ART module, sample 'x', and weight vector 'W'.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_INDEX","page":"Internals","title":"AdaptiveResonance._ARG_INDEX","text":"ARGINDEX\n\nDescription\n\nCommon docstring: shared argument docstring for the index of the weight column.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_W","page":"Internals","title":"AdaptiveResonance._ARG_W","text":"ARGW\n\nDescription\n\nCommon docstring: shared argument docstring for the weight vector.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._ARG_X","page":"Internals","title":"AdaptiveResonance._ARG_X","text":"ARGX\n\nDescription\n\nCommon docstring: shared argument docstring for the input sample of features.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._COMMON_DOC","page":"Internals","title":"AdaptiveResonance._COMMON_DOC","text":"COMMONDOC\n\nDescription\n\nDocstring prefix denoting that the constant is used as a common docstring element for other docstrings.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance._OPTS_DOCSTRING","page":"Internals","title":"AdaptiveResonance._OPTS_DOCSTRING","text":"OPTSDOCSTRING\n\nDescription\n\nCommon docstring: shared options docstring, inserted at the end of opts_<...> structs.\n\n\n\n\n\n","category":"constant"},{"location":"man/dev-index/#AdaptiveResonance.ARTMatrix","page":"Internals","title":"AdaptiveResonance.ARTMatrix","text":"ARTMatrix\n\nDescription\n\nThe type of matrix used by the AdaptiveResonance.jl package, used to configure matrix growth behavior.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ARTStats","page":"Internals","title":"AdaptiveResonance.ARTStats","text":"ARTStats\n\nDescription\n\nDefinition of the ART module statistics dictionary, used to generate and store various logs during training and testing.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.ARTVector","page":"Internals","title":"AdaptiveResonance.ARTVector","text":"ARTVector\n\nDescription\n\nThe type of vector used by the AdaptiveResonance.jl package, used to configure vector growth behvior.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.AbstractFuzzyART","page":"Internals","title":"AdaptiveResonance.AbstractFuzzyART","text":"abstract type AbstractFuzzyART <: ART\n\nSummary\n\nAbstract supertype of FuzzyART modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.MergeART","page":"Internals","title":"AdaptiveResonance.MergeART","text":"mutable struct MergeART <: ART\n\nSummary\n\nMergeART module struct.\n\nFor module options, see AdaptiveResonance.opts_MergeART.\n\nReferences\n\nL. E. Brito da Silva, I. Elnabarawy, and D. C. Wunsch, 'Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence,' Neural Networks, vol. 121, pp. 208-228, 2020, doi: 10.1016/j.neunet.2019.08.033.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DDVFA: DDVFA options struct.\n\nsubopts::opts_FuzzyART: FuzzyART options struct used for all F2 nodes.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nF2::Vector{FuzzyART}: List of F2 nodes (themselves FuzzyART modules).\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of total categories.\n\nepoch::Int64: Current training epoch.\n\nT::Vector: DDVFA activation values.\n\nM::Vector: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.opts_MergeART","page":"Internals","title":"AdaptiveResonance.opts_MergeART","text":"mutable struct opts_MergeART <: ARTOpts\n\nSummary\n\nMergeART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.7\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.85\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nsimilarity::Symbol: Similarity method (activation and match): similarity ∈ [:single, :average, :complete, :median, :weighted, :centroid].  Default: :single\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.  Default: true\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :gamma_activation\nmatch::Symbol: Selected match function.  Default: :gamma_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/dev-index/#AdaptiveResonance.W_norm-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.W_norm","text":"W_norm(W::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nLow-level common function for computing the 1-norm of just the weight vector.\n\nArguments\n\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nW_norm(W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:30.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.accommodate_vector!-Union{Tuple{T}, Tuple{Vector{T}, Integer}} where T","page":"Internals","title":"AdaptiveResonance.accommodate_vector!","text":"accommodate_vector!(vec::Array{T, 1}, goal_len::Integer)\n\n\nSummary\n\nExtends a vector to a goal length with zeros of its element type to accommodate in-place updates.\n\nArguments\n\nvec::Vector{T}: a vector of arbitrary element type.\ngoal_len::Integer: the length that the vector should be.\n\nMethod List / Definition Locations\n\naccommodate_vector!(vec, goal_len)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.activation_match!-Tuple{AdaptiveResonance.AbstractFuzzyART, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.activation_match!","text":"activation_match!(\n    art::AdaptiveResonance.AbstractFuzzyART,\n    x::AbstractVector{T} where T<:Real\n)\n\n\nSummary\n\nComputes the activation and match functions of the ART module against sample x.\n\nArguments\n\nart::AbstractFuzzyART: the single FuzzyART module to compute the activation and match values for all weights.\nx::RealVector: the sample to compute the activation and match functions against.\n\nExamples\n\njulia> my_FuzzyART = FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\njulia> x = rand(3, 10)\njulia> train!(my_FuzzyART, x)\njulia> activation_match!(my_FuzzyART, x[:, 1])\n\nMethod List / Definition Locations\n\nactivation_match!(art, x)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:51.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer, Vararg{Any}}","page":"Internals","title":"AdaptiveResonance.art_activation","text":"art_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer,\n    args...\n) -> Any\n\n\nSummary\n\nEvaluates the activation function of the ART/ARTMAP module on the sample 'x' with weight 'W'.\n\nPasses additional arguments for low-level optimizations using function dispatch.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_activation(art, x, index, args)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:140.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_learn-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.art_learn","text":"art_learn(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> Any\n\n\nSummary\n\nEvaluates the ART module's learning/update method.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_learn(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:161.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.art_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer, Vararg{Any}}","page":"Internals","title":"AdaptiveResonance.art_match","text":"art_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer,\n    args...\n) -> Any\n\n\nSummary\n\nEvaluates the match function of the ART/ARTMAP module on sample 'x' with weight 'W'.\n\nPasses additional arguments for low-level optimizations using function dispatch.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nindex::Integer: the index of the weight column to use.\n\nMethod List / Definition Locations\n\nart_match(art, x, index, args)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:126.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.average-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.average","text":"average(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nAverage linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\naverage(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:479.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_activation","text":"basic_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nSimplified FuzzyARTMAP activation function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_activation(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:59.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_match","text":"basic_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nBasic match function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_match(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.basic_update-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.basic_update","text":"basic_update(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nBasic weight update function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nbasic_update(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:149.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.build_art_stats-Tuple{}","page":"Internals","title":"AdaptiveResonance.build_art_stats","text":"build_art_stats() -> Dict{String, Any}\n\n\nSummary\n\nInitializes an ARTStats dictionary with zero entries.\n\nMethod List / Definition Locations\n\nbuild_art_stats()\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:138.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.centroid-Tuple{FuzzyART, AbstractVector{T} where T<:Real, Bool}","page":"Internals","title":"AdaptiveResonance.centroid","text":"centroid(\n    F2::FuzzyART,\n    sample::AbstractVector{T} where T<:Real,\n    activation::Bool\n) -> Any\n\n\nSummary\n\nCentroid linkage DDVFA similarity function.\n\nArguments:\n\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nsample::RealVector: the sample to use for computing the linkage to the F2 module.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\ncentroid(F2, sample, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:526.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.choice_by_difference-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.choice_by_difference","text":"choice_by_difference(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nDefault ARTMAP's choice-by-difference activation function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nchoice_by_difference(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:109.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.color_to_gray-Union{Tuple{Array{T, 3}}, Tuple{T}} where T<:AbstractFloat","page":"Internals","title":"AdaptiveResonance.color_to_gray","text":"color_to_gray(image::Array{T<:AbstractFloat, 3}) -> Matrix\n\n\nSummary\n\nARTSCENE Stage 1: Color-to-gray image transformation.\n\nMethod List / Definition Locations\n\ncolor_to_gray(image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:23.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.competition_kernel-Tuple{Integer, Integer}","page":"Internals","title":"AdaptiveResonance.competition_kernel","text":"competition_kernel(l::Integer, k::Integer; sign) -> Any\n\n\nSummary\n\nCompetition kernel for ARTSCENE: Stage 5.\n\nMethod List / Definition Locations\n\ncompetition_kernel(l, k; sign)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:195.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.complete-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.complete","text":"complete(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nComplete linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\ncomplete(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:488.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_insensitive_oriented_filtering-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_insensitive_oriented_filtering","text":"contrast_insensitive_oriented_filtering(\n    y::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 4: Contrast-insensitive oriented filtering.\n\nMethod List / Definition Locations\n\ncontrast_insensitive_oriented_filtering(y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:182.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_normalization-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_normalization","text":"contrast_normalization(\n    image::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 2: Constrast normalization.\n\nMethod List / Definition Locations\n\ncontrast_normalization(image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:65.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.contrast_sensitive_oriented_filtering-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.contrast_sensitive_oriented_filtering","text":"contrast_sensitive_oriented_filtering(\n    image::AbstractArray{T} where T<:Real,\n    x::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 3: Contrast-sensitive oriented filtering.\n\nMethod List / Definition Locations\n\ncontrast_sensitive_oriented_filtering(image, x)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:151.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{ARTModule, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"Summary\n\nCreates a category for the ARTModule module, expanding the weights and incrementing the category labels.\n\nArguments\n\nart::ARTModule: the ARTModule module to add a category to.\nx::RealVector: the sample to use for adding a category.\ny::Integer: the new label for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, sample, label)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:396.\n\ncreate_category!(art, x, y; new_cluster)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:237.\n\ncreate_category!(art, x, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:269.\n\ncreate_category!(art, x, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:205.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{DDVFA, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"create_category!(\n    art::DDVFA,\n    sample::AbstractVector{T} where T<:Real,\n    label::Integer\n) -> Vector{FuzzyART}\n\n\nSummary\n\nCreate a new category by appending and initializing a new FuzzyART node to F2.\n\nArguments\n\nart::DDVFA: the DDVFA module to create a new FuzzyART category in.\nsample::RealVector: the sample to use for instantiating the new category.\nlabel::Integer: the new label to use for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, sample, label)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:396.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.create_category!-Tuple{DVFA, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.create_category!","text":"create_category!(\n    art::DVFA,\n    x::AbstractVector{T} where T<:Real,\n    y::Integer;\n    new_cluster\n) -> Vector{Int64}\n\n\nSummary\n\nCreates a new category for the DVFA modules.\n\nArguments\n\nart::DVFA: the DVFA module to add a category to.\nx::RealVector: the sample to use for adding a category.\ny::Integer: the new label for the new category.\n\nMethod List / Definition Locations\n\ncreate_category!(art, x, y; new_cluster)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:237.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_x-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.ddt_x","text":"ddt_x(\n    x::AbstractArray{T} where T<:Real,\n    image::AbstractArray{T} where T<:Real,\n    sigma_s::AbstractArray{T} where T<:Real\n) -> SharedArrays.SharedArray{Float64, 3}\n\n\nSummary\n\nTime rate of change of LGN network (ARTSCENE Stage 2).\n\nMethod List / Definition Locations\n\nddt_x(x, image, sigma_s)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_y-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.ddt_y","text":"ddt_y(\n    y::AbstractArray{T} where T<:Real,\n    X_plus::AbstractArray{T} where T<:Real,\n    X_minus::AbstractArray{T} where T<:Real,\n    alpha::Real\n) -> SharedArrays.SharedArray{Float64, 4}\n\n\nSummary\n\nShunting equation for ARTSCENE Stage 3.\n\nMethod List / Definition Locations\n\nddt_y(y, X_plus, X_minus, alpha)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:112.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.ddt_z-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.ddt_z","text":"ddt_z(\n    z::AbstractArray{T} where T<:Real\n) -> SharedArrays.SharedArray{Float64, 4}\n\n\nSummary\n\nTime rate of change for ARTSCENE: Stage 5.\n\nMethod List / Definition Locations\n\nddt_z(z)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:211.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.element_min-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.element_min","text":"element_min(\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nReturns the element-wise minimum between sample x and weight W.\n\nArguments\n\nx::RealVector: the input sample.\nW::RealVector: the weight vector to compare the sample against.\n\nMethod List / Definition Locations\n\nelement_min(x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:178.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_activation-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.gamma_activation","text":"gamma_activation(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nGamma-normalized activation funtion.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\ngamma_activation(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:100.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.gamma_match","text":"gamma_match(\n    art::ARTModule,\n    _::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real,\n    gamma_act::Real\n) -> Any\n\n\nSummary\n\nGamma-normalized match function, passing a precomputed gamma activation value.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\ngamma_act::Real: the precomputed gamma activation value.\n\nMethod List / Definition Locations\n\ngamma_match(art, _, W, gamma_act)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:91.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.gamma_match","text":"gamma_match(\n    art::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nGamma-normalized match function, recomputing the gamma activation value.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\ngamma_match(art, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:81.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.gamma_match_sub-Tuple{ARTModule, AbstractVector{T} where T<:Real, Real}","page":"Internals","title":"AdaptiveResonance.gamma_match_sub","text":"gamma_match_sub(\n    art::ARTModule,\n    W::AbstractVector{T} where T<:Real,\n    gamma_act::Real\n) -> Any\n\n\nSummary\n\nLow-level subroutine for the gamma match function with a precomputed gamma activation.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nW::RealVector: the weight vector to use.\ngamma_act::Real: the precomputed gamma activation value.\n\nMethod List / Definition Locations\n\ngamma_match_sub(art, W, gamma_act)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:72.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_data_shape-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_data_shape","text":"get_data_shape(\n    data::AbstractMatrix{T} where T<:Real\n) -> Tuple{Any, Any}\n\n\nSummary\n\nReturns the (dim, n_samples) of the provided 2-D data matrix, enforcing the ART package convention.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the feature dimension and number of samples from.\n\nMethod List / Definition Locations\n\nget_data_shape(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:249.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_dim-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_dim","text":"get_dim(data::AbstractMatrix{T} where T<:Real) -> Any\n\n\nSummary\n\nReturns the dimension of the data, enforcint the (dim, n_samples) convention of the package.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the feature dimension of.\n\nMethod List / Definition Locations\n\nget_dim(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:227.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_iterator-Tuple{ARTOpts, Integer}","page":"Internals","title":"AdaptiveResonance.get_iterator","text":"get_iterator(opts::ARTOpts, n_samples::Integer) -> Any\n\n\nSummary\n\nCreates an iterator object according to the ART/ARTMAP modules display settings for batch iteration.\n\nArguments\n\nopts::ARTOpts: the ART/ARTMAP module's options containing display settings.\nn_samples::Integer: the number of iterations to create the iterator for.\n\nMethod List / Definition Locations\n\nget_iterator(opts, n_samples)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:417.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_samples-Tuple{AbstractMatrix{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.get_n_samples","text":"get_n_samples(data::AbstractMatrix{T} where T<:Real) -> Any\n\n\nSummary\n\nReturns the number of samples, enforcing the convention of the package.\n\nArguments\n\ndata::RealMatrix: the 2-D data to infer the number of samples from.\n\nMethod List / Definition Locations\n\nget_n_samples(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:238.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_weights-Tuple{DDVFA}","page":"Internals","title":"AdaptiveResonance.get_n_weights","text":"get_n_weights(art::DDVFA) -> Int64\n\n\nSummary\n\nConvenience function; return the sum total number of weights in the DDVFA module.\n\nMethod List / Definition Locations\n\nget_n_weights(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:567.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_n_weights_vec-Tuple{DDVFA}","page":"Internals","title":"AdaptiveResonance.get_n_weights_vec","text":"get_n_weights_vec(art::DDVFA) -> Vector{Int64}\n\n\nSummary\n\nConvenience function; return the number of weights in each category as a vector.\n\nArguments\n\nart::DDVFA: the DDVFA module to get all of the weights from as a list.\n\nMethod List / Definition Locations\n\nget_n_weights_vec(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:560.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.get_sample-Tuple{AbstractMatrix{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.get_sample","text":"get_sample(\n    x::AbstractMatrix{T} where T<:Real,\n    i::Integer\n) -> Any\n\n\nSummary\n\nReturns a sample from data array x at sample location i. This function implements the convention that columns are samples while rows are features within samples.\n\nArguments\n\nx::RealMatrix: the batch of data to grab a sample from.\ni::Integer: the index to get the sample from.\n\nMethod List / Definition Locations\n\nget_sample(x, i)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:453.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_classify!-Tuple{AbstractArray{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_classify!","text":"init_classify!(\n    x::AbstractArray{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\nInitializes the classification loop for batch inference.\n\nArguments\n\nx::RealArray: the data that is used for inference.\nart::ARTModule: the ART/ARTMAP module that will be used for inference.\npreprocessed::Bool: required flag for if the data has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_classify!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:519.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_train!-Tuple{AbstractMatrix{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_train!","text":"init_train!(\n    x::AbstractMatrix{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\nInitializes the training loop for batch learning.\n\nArguments\n\nx::RealMatrix: the data that is used for training.\nart::ARTModule: the ART/ARTMAP that will be trained.\npreprocessed::Bool: required flag for if the data has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_train!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:501.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.init_train!-Tuple{AbstractVector{T} where T<:Real, ARTModule, Bool}","page":"Internals","title":"AdaptiveResonance.init_train!","text":"init_train!(\n    x::AbstractVector{T} where T<:Real,\n    art::ARTModule,\n    preprocessed::Bool\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nInitializes the module for training in a single iteration.\n\nThe purpose of this function is mainly to handle the conditions of complement coding. Fails if the module was incorrectly set up or if the module was not setup and the data was not preprocessed.\n\nArguments\n\nx::RealVector: the sample used for initialization.\nart::ARTModule: the ART/ARTMAP module that will be trained on the sample.\npreprocessed::Bool: a required flag for if the sample has already been complement coded and normalized.\n\nMethod List / Definition Locations\n\ninit_train!(x, art, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:470.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.initialize!-Tuple{ART, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.initialize!","text":"Summary\n\nInitializes the ART module for training with sample 'x' and optional label 'y', setting up the data configuration and instantiating the first category.\n\nThis function is used during the first training iteration when the ART module is empty.\n\nArguments\n\nart::ART: the ART module to initialize.\nx::RealVector: the sample to use for initialization.\ny::Integer=0: the optional new label for the first weight of the ART module. If not specified, defaults the new label to 1.\n\nExamples\n\njulia> my_FuzzyART = FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\njulia> initialize!(my_FuzzyART, [1, 2, 3, 4])\n\n\n# Method List / Definition Locations\n\n\njulia initialize!(art, x; y) ```\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:22.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.initialize!-Tuple{ARTMAP, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.initialize!","text":"Summary\n\nInitializes the supervised ARTMAP module for training with sample 'x' and label 'y', setting up the data configuration and instantiating the first category.\n\nArguments\n\nart::ARTMAP: the ARTMAP module to initialize.\nx::RealVector: the sample to use for initialization.\ny::Integer: the initial supervised label.\n\nExamples\n\njulia> my_sfam = SFAM()\nSFAM\n    opts: opts_SFAM\n    ...\njulia> initialize!(my_SFAM, [1, 2, 3, 4])\n\n\n# Method List / Definition Locations\n\n\njulia initialize!(art, x, y) ```\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:197.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.learn!-Tuple{AdaptiveResonance.AbstractFuzzyART, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.learn!","text":"learn!(\n    art::AdaptiveResonance.AbstractFuzzyART,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n)\n\n\nSummary\n\nIn place learning function.\n\nArguments\n\nart::AbstractFuzzyART: the FuzzyART module to update.\nx::RealVector: the sample to learn from.\nindex::Integer: the index of the FuzzyART weight to update.\n\nMethod List / Definition Locations\n\nlearn!(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/common.jl:74.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.learn!-Tuple{SFAM, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.learn!","text":"learn!(\n    art::SFAM,\n    x::AbstractVector{T} where T<:Real,\n    index::Integer\n)\n\n\nSummary\n\nIn-place learning function.\n\nMethod List / Definition Locations\n\nlearn!(art, x, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:341.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.log_art_stats!-Tuple{ARTModule, Integer, Bool}","page":"Internals","title":"AdaptiveResonance.log_art_stats!","text":"log_art_stats!(art::ARTModule, bmu::Integer, mismatch::Bool)\n\n\nSummary\n\nLogs common statistics of an ART module after a training/classification iteration.\n\nArguments\n\nart::ARTModule: the ART module that just underwent training/classification.\nbmu::Integer: the best-matching unit integer index.\nmismatch::Bool: flag of whether there was a mismatch in this iteration.\n\nMethod List / Definition Locations\n\nlog_art_stats!(art, bmu, mismatch)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:160.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.median-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.median","text":"median(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nMedian linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\nmedian(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:497.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.orientation_competition-Tuple{AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.orientation_competition","text":"orientation_competition(\n    z::AbstractArray{T} where T<:Real\n) -> Any\n\n\nSummary\n\nARTSCENE Stage 5: Orientation competition at the same position.\n\nMethod List / Definition Locations\n\norientation_competition(z)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:236.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.oriented_kernel-Tuple{Integer, Integer, Integer, Integer, Integer, Real, Real}","page":"Internals","title":"AdaptiveResonance.oriented_kernel","text":"oriented_kernel(\n    i::Integer,\n    j::Integer,\n    p::Integer,\n    q::Integer,\n    k::Integer,\n    sigma_h::Real,\n    sigma_v::Real;\n    sign\n) -> Any\n\n\nSummary\n\nOriented, elongated, spatially offset kernel G for ARTSCENE Stage 3.\n\nMethod List / Definition Locations\n\noriented_kernel(i, j, p, q, k, sigma_h, sigma_v; sign)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:90.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.patch_orientation_color-Tuple{AbstractArray{T} where T<:Real, AbstractArray{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.patch_orientation_color","text":"patch_orientation_color(\n    z::AbstractArray{T} where T<:Real,\n    image::AbstractArray{T} where T<:Real\n) -> Tuple{Any, Array{Float64, 3}}\n\n\nSummary\n\nARTSCENE Stage 6: Create patch feature vectors.\n\nMethod List / Definition Locations\n\npatch_orientation_color(z, image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:257.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.replace_mat_index!-Tuple{AbstractMatrix{T} where T<:Real, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.replace_mat_index!","text":"replace_mat_index!(\n    mat::AbstractMatrix{T} where T<:Real,\n    vec::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nReplaces a matrix element with a vector at the column index.\n\nThis function dispatches to the low-level replacement strategy.\n\nArguments\n\nmat::RealMatrix: the matrix to update with a replaced column vector.\nvec::RealVector: the vector to put in the matrix at the column index.\nindex::Integer: the column index to put the vector.\n\nMethod List / Definition Locations\n\nreplace_mat_index!(mat, vec, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:19.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.set_threshold!-Tuple{ARTModule}","page":"Internals","title":"AdaptiveResonance.set_threshold!","text":"Summary\n\nSets the match threshold of the ART/ARTMAP module as a function of the vigilance parameter.\n\nDepending on selected ART/ARTMAP module and its options, this may be a function of other parameters as well.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module for setting a new threshold.\n\nMethod List / Definition Locations\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:254.\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:223.\n\nset_threshold!(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:258.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.similarity-Tuple{Symbol, FuzzyART, AbstractVector{T} where T<:Real, Bool}","page":"Internals","title":"AdaptiveResonance.similarity","text":"similarity(\n    method::Symbol,\n    F2::FuzzyART,\n    sample::AbstractVector{T} where T<:Real,\n    activation::Bool\n) -> Any\n\n\nSummary\n\nCompute the similarity metric depending on method with explicit comparisons for the field name.\n\nArguments\n\nmethod::Symbol: the linkage method to use.\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nsample::RealVector: the sample to use for computing the linkage to the F2 module.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\nsimilarity(method, F2, sample, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:438.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.single-Tuple{AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.single","text":"single(field::AbstractVector{T} where T<:Real) -> Any\n\n\nSummary\n\nSingle linkage DDVFA similarity function.\n\nArguments\n\nfield::RealVector: the DDVFA FuzzyART F2 node field (F2.T or F2.M) to compute the linkage for.\n\nMethod List / Definition Locations\n\nsingle(field)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:470.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.stopping_conditions-Tuple{ARTModule}","page":"Internals","title":"AdaptiveResonance.stopping_conditions","text":"stopping_conditions(art::ARTModule) -> Any\n\n\nSummary\n\nChecks the stopping conditions for an ART module.\n\nArguments\n\nart::ART: the ART module to check stopping conditions for.\n\nMethod List / Definition Locations\n\nstopping_conditions(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:589.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.surround_kernel-NTuple{5, Integer}","page":"Internals","title":"AdaptiveResonance.surround_kernel","text":"surround_kernel(\n    i::Integer,\n    j::Integer,\n    p::Integer,\n    q::Integer,\n    scale::Integer\n) -> Any\n\n\nSummary\n\nSurround kernel S function for ARTSCENE Stage 2.\n\nMethod List / Definition Locations\n\nsurround_kernel(i, j, p, q, scale)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:32.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.unnormalized_match-Tuple{ARTModule, AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.unnormalized_match","text":"unnormalized_match(\n    _::ARTModule,\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nUnnormalized match function.\n\nArguments\n\nart::ARTModule: the ARTModule module.\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nunnormalized_match(_, x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:49.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.unsafe_replace_mat_index!-Tuple{AbstractMatrix{T} where T<:Real, AbstractVector{T} where T<:Real, Integer}","page":"Internals","title":"AdaptiveResonance.unsafe_replace_mat_index!","text":"unsafe_replace_mat_index!(\n    mat::AbstractMatrix{T} where T<:Real,\n    vec::AbstractVector{T} where T<:Real,\n    index::Integer\n) -> AbstractVector{T} where T<:Real\n\n\nSummary\n\nLow-level function for unsafely replacing a matrix column with a given vector.\n\nArguments\n\nmat::RealMatrix: the matrix to update with a replaced column vector.\nvec::RealVector: the vector to put in the matrix at the column index.\nindex::Integer: the column index to put the vector.\n\nMethod List / Definition Locations\n\nunsafe_replace_mat_index!(mat, vec, index)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/subroutines.jl:28.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.update_iter-Tuple{ARTModule, Union{ProgressBars.ProgressBar, UnitRange}, Integer}","page":"Internals","title":"AdaptiveResonance.update_iter","text":"update_iter(\n    art::ARTModule,\n    iter::Union{ProgressBars.ProgressBar, UnitRange},\n    i::Integer\n) -> Union{Nothing, String}\n\n\nSummary\n\nUpdates the iteration of the ART/ARTMAP module, training or inference, according to its display settings.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module being iterated upon.\niter::ARTIterator: the iterator object used in the training/inference loop.\ni::Integer: the iteration during training/inference that the iterator should be updated to.\n\nMethod List / Definition Locations\n\nupdate_iter(art, iter, i)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:436.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.weighted-Tuple{FuzzyART, Bool}","page":"Internals","title":"AdaptiveResonance.weighted","text":"weighted(F2::FuzzyART, activation::Bool) -> Float64\n\n\nSummary\n\nWeighted linkage DDVFA similarity function.\n\nArguments:\n\nF2::FuzzyART: the DDVFA FuzzyART F2 node to compute the linkage method within.\nactivation::Bool: flag to use the activation function. False uses the match function.\n\nMethod List / Definition Locations\n\nweighted(F2, activation)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:508.\n\n\n\n\n\n","category":"method"},{"location":"man/dev-index/#AdaptiveResonance.x_W_min_norm-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Internals","title":"AdaptiveResonance.x_W_min_norm","text":"x_W_min_norm(\n    x::AbstractVector{T} where T<:Real,\n    W::AbstractVector{T} where T<:Real\n) -> Any\n\n\nSummary\n\nLow-level common function for computing the 1-norm of the element minimum of a sample and weights.\n\nArguments\n\nx::RealVector: the sample vector to use.\nW::RealVector: the weight vector to use.\n\nMethod List / Definition Locations\n\nx_W_min_norm(x, W)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/symbols.jl:19.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#main-index","page":"Index","title":"Index","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This page lists the core methods and types of the AdaptiveResonance.jl package. The Modules section lists the modules exported by the package including the AdaptiveResonance module itself. The Methods section lists the public methods for the package that use the modules in Types. Each of these entries link to the docstrings in the Docs section.","category":"page"},{"location":"man/full-index/","page":"Index","title":"Index","text":"ART modules document their internal working parameters and references, while their hyperparameters/options are documented under their corresponding option structs opts_....","category":"page"},{"location":"man/full-index/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This section enumerates the names exported by the package, each of which links to its corresponding Documentation.","category":"page"},{"location":"man/full-index/#index-modules","page":"Index","title":"Modules","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:module]","category":"page"},{"location":"man/full-index/#index-methods","page":"Index","title":"Methods","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:function]","category":"page"},{"location":"man/full-index/#index-types","page":"Index","title":"Types","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:type]","category":"page"},{"location":"man/full-index/#index-constants","page":"Index","title":"Constants","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Pages   = [\"full-index.md\"]\nModules = [AdaptiveResonance]\nOrder = [:constant]","category":"page"},{"location":"man/full-index/#index-docs","page":"Index","title":"Docs","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"This section lists the documentation for every exported name of the AdaptiveResonance.jl package.","category":"page"},{"location":"man/full-index/#index-modules-docs","page":"Index","title":"Modules","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:module]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.AdaptiveResonance","page":"Index","title":"AdaptiveResonance.AdaptiveResonance","text":"Main module for AdaptiveResonance.jl, a Julia package of adaptive resonance theory algorithms.\n\nThis module exports all of the ART modules, options, and utilities used by the AdaptiveResonance.jl package. For full usage, see the official guide at https://ap6yc.github.io/AdaptiveResonance.jl/dev/man/guide/.\n\nBasic Usage\n\nInstall and import the package in a script with\n\nusing Pkg\nPkg.add(\"AdaptiveResonance\")\nusing AdaptiveResonance\n\nthen create an ART module with default options\n\nmy_art = DDVFA()\n\nor custom options via keyword arguments\n\nmy_art = DDVFA(rho_ub=0.45, rho_ub=0.7)\n\nTrain all models with train! and conduct inference with classify. In batch, samples are interpreted in the Julia column-major fashion with dimensions (n_dim, n_samples) (i.e., columns are samples).\n\nTrain unsupervised ART modules incrementally or in batch with optional labels as a keyword argument y\n\n# Load your data somehow\nsamples, labels = load_some_data()\n\n# Unsupervised batch\ntrain!(my_art, samples)\n\n# Supervised batch\ntrain!(my_art, samples, y=labels)\n\n# Unsupervised incremental\nfor ix in eachindex(labels)\n    train!(my_art, samples[:, ix])\nend\n\n# Supervised incremental\nfor ix in eachindex(labels)\n    train!(my_art, samples[:, ix], y=labels[ix])\nend\n\nTrain supervised ARTMAP with positional arguments\n\nmy_artmap = SFAM()\ntrain!(my_artmap, samples, labels)\n\nWith either module, conduct inference with classify(art, samples)\n\n# Batch inference\ny_hat = classify(my_art, test_samples)\n\n# Incremental inference\nfor ix in eachindex(test_labels)\n    y_hat[ix] = classify(my_artmap, test_samples[:, ix])\nend\n\nImports\n\nThe following names are imported by the package as dependencies:\n\nBase\nCore\nDistributed\nDocStringExtensions\nElasticArrays\nLogging\nNumericalTypeAliases\nParameters\nPkg\nProgressBars\nSharedArrays\n\nExports\n\nThe following names are exported and available when using the package:\n\nACTIVATION_FUNCTIONS\nADAPTIVERESONANCE_MODULES\nADAPTIVERESONANCE_VERSION\nART\nARTMAP\nARTMAP_MODULES\nARTModule\nARTOpts\nART_MODULES\nDAM\nDDVFA\nDDVFA_METHODS\nDVFA\nDataConfig\nFAM\nFuzzyART\nGammaNormalizedFuzzyART\nMATCH_FUNCTIONS\nSFAM\nUPDATE_FUNCTIONS\nartscene_filter\nclassify\ncomplement_code\ndata_setup!\nget_W\nget_data_characteristics\nlinear_normalization\nopts_DAM\nopts_DDVFA\nopts_DVFA\nopts_FAM\nopts_FuzzyART\nopts_GammaNormalizedFuzzyART\nopts_SFAM\nperformance\ntrain!\n\n\n\n\n\n","category":"module"},{"location":"man/full-index/#index-functions-docs","page":"Index","title":"Functions","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:function]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.DAM-Tuple{opts_SFAM}","page":"Index","title":"AdaptiveResonance.DAM","text":"DAM(opts::opts_SFAM) -> SFAM\n\n\nSummary\n\nImplements a Default ARTMAP module with specified options.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nArguments\n\nopts::opts_SFAM: the Simplified FuzzyARTMAP options (see AdaptiveResonance.opts_SFAM).\n\nMethod List / Definition Locations\n\nDAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:41.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DAM-Tuple{}","page":"Index","title":"AdaptiveResonance.DAM","text":"DAM(; kwargs...) -> SFAM\n\n\nSummary\n\nConstructs a Default ARTMAP module using a SFAM module using Default ARTMAP's choice-by-difference activation function.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nArguments\n\nkwargs: keyword arguments of Simplified FuzzyARTMAP options (see AdaptiveResonance.opts_SFAM)\n\nReferences:\n\nG. P. Amis and G. A. Carpenter, 'Default ARTMAP 2,' IEEE Int. Conf. Neural Networks - Conf. Proc., vol. 2, no. September 2007, pp. 777-782, Mar. 2007, doi: 10.1109/IJCNN.2007.4371056.\n\nMethod List / Definition Locations\n\nDAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:29.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.GammaNormalizedFuzzyART-Tuple{opts_FuzzyART}","page":"Index","title":"AdaptiveResonance.GammaNormalizedFuzzyART","text":"GammaNormalizedFuzzyART(opts::opts_FuzzyART)\n\n\nSummary\n\nImplements a Gamma-Normalized FuzzyART module with specified options.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nArguments\n\nopts::opts_FuzzyART: the Fuzzy ART options (see AdaptiveResonance.opts_FuzzyART).\n\nMethod List / Definition Locations\n\nGammaNormalizedFuzzyART(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:39.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.GammaNormalizedFuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.GammaNormalizedFuzzyART","text":"GammaNormalizedFuzzyART(; kwargs...) -> FuzzyART\n\n\nSummary\n\nConstructs a Gamma-Normalized FuzzyART module as a variant of FuzzyART by using the gamma_normalization option.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nArguments\n\nkwargs: keyword arguments of FuzzyART options (see AdaptiveResonance.opts_FuzzyART)\n\nMethod List / Definition Locations\n\nGammaNormalizedFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:26.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.artscene_filter-Union{Tuple{Array{T, 3}}, Tuple{T}} where T<:AbstractFloat","page":"Index","title":"AdaptiveResonance.artscene_filter","text":"artscene_filter(\n    raw_image::Array{T<:AbstractFloat, 3}\n) -> Tuple{Array{Float64, 4}, Array{Float64, 3}}\n\n\nSummary\n\nProcess the full artscene filter toolchain on an image.\n\nArguments\n\nraw_image::Array{Real, 3}: the raw RGB image to process with the ARTSCENE filter.\n\nMethod List / Definition Locations\n\nartscene_filter(raw_image)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/ARTSCENE.jl:294.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.classify-Tuple{ARTModule, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.classify","text":"classify(\n    art::ARTModule,\n    x::AbstractMatrix{T} where T<:Real;\n    preprocessed,\n    get_bmu\n) -> Any\n\n\nSummary\n\nPredict categories of 'x' using the ART model.\n\nReturns predicted categories 'y_hat.'\n\nArguments\n\nart::ARTModule: ART or ARTMAP module to use for batch inference.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\npreprocessed::Bool=false: flag, if the data has already been complement coded or not.\nget_bmu::Bool=false, flag, if the model should return the best-matching-unit label in the case of total mismatch.\n\nExamples\n\njulia> my_DDVFA = DDVFA()\nDDVFA\n    opts: opts_DDVFA\n    ...\njulia> x, y = load_data()\njulia> train!(my_DDVFA, x)\njulia> y_hat = classify(my_DDVFA, y)\n\nMethod List / Definition Locations\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:554.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.classify-Tuple{ARTModule, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.classify","text":"Summary\n\nPredict categories of a single sample of features 'x' using the ART model.\n\nReturns predicted category 'y_hat.'\n\nArguments\n\nart::ARTModule: ART or ARTMAP module to use for batch inference.\nx::RealVector: the single sample of features to classify.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\nget_bmu::Bool=false: optional, flag if the model should return the best-matching-unit label in the case of total mismatch.\n\nMethod List / Definition Locations\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:335.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:337.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:370.\n\nclassify(art, x; preprocessed, get_bmu)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:293.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.complement_code-Tuple{AbstractArray{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.complement_code","text":"complement_code(\n    data::AbstractArray{T} where T<:Real;\n    config\n) -> Any\n\n\nSummary\n\nNormalizes the data x to [0, 1] and returns the augmented vector [x, 1 - x].\n\nArguments\n\ndata::RealArray: the 1-D or 2-D data to be complement coded.\nconfig::DataConfig=DataConfig(): the data configuration for the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\ncomplement_code(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:402.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.data_setup!-Tuple{ARTModule, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.data_setup!","text":"data_setup!(\n    art::ARTModule,\n    data::AbstractMatrix{T} where T<:Real\n)\n\n\nSummary\n\nConvenience method for setting up the DataConfig of an ART module in advance.\n\nArguments\n\nart::ARTModule: the ART/ARTMAP module to manually configure the data config for.\ndata::RealArray: the 2-D batch of data used to create the data config.\n\nMethod List / Definition Locations\n\ndata_setup!(art, data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:295.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.data_setup!-Tuple{DataConfig, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.data_setup!","text":"data_setup!(\n    config::DataConfig,\n    data::AbstractMatrix{T} where T<:Real\n)\n\n\nSummary\n\nSets up the data config for the ART module before training.\n\nThis function crucially gets the original and complement-coded dimensions of the data, and it infers the bounds of the data (minimums and maximums) by the largest and smallest values along each feature dimension.\n\nArguments\n\nconfig::DataConfig: the ART/ARTMAP module's data configuration object.\ndata::RealMatrix: the 2-D batch of data to use for creating the data configuration.\n\nMethod List / Definition Locations\n\ndata_setup!(config, data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:268.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.get_W-Tuple{DDVFA}","page":"Index","title":"AdaptiveResonance.get_W","text":"get_W(art::DDVFA) -> Vector\n\n\nSummary\n\nConvenience function; return a concatenated array of all DDVFA weights.\n\nArguments\n\nart::DDVFA: the DDVFA module to get all of the weights from as a list.\n\nMethod List / Definition Locations\n\nget_W(art)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:549.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.get_data_characteristics-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.get_data_characteristics","text":"get_data_characteristics(\n    data::AbstractMatrix{T} where T<:Real;\n    config\n) -> NTuple{4, Any}\n\n\nSummary\n\nGet the characteristics of the data, taking account if a data config is passed.\n\nIf no DataConfig is passed, then the data characteristics come from the array itself. Otherwise, use the config for the statistics of the data and the data array for the number of samples.\n\nArguments\n\ndata::RealMatrix: the 2-D data to be complement coded.\nconfig::DataConfig=DataConfig(): the data configuration for the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nget_data_characteristics(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:310.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.linear_normalization-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.linear_normalization","text":"linear_normalization(\n    data::AbstractMatrix{T} where T<:Real;\n    config\n) -> Any\n\n\nSummary\n\nNormalize the data to the range [0, 1] along each feature.\n\nArguments\n\ndata::RealMatrix: the 2-D batch of data to normalize.\nconfig::DataConfig=DataConfig(): the data configuration from the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nlinear_normalization(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:369.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.linear_normalization-Tuple{AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.linear_normalization","text":"linear_normalization(\n    data::AbstractVector{T} where T<:Real;\n    config\n) -> Vector{Float64}\n\n\nSummary\n\nNormalize the data to the range [0, 1] along each feature.\n\nArguments\n\ndata::RealVector: the 1-D sample of data to normalize.\nconfig::DataConfig=DataConfig(): the data configuration from the ART/ARTMAP module.\n\nMethod List / Definition Locations\n\nlinear_normalization(data; config)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:339.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_DAM-Tuple{}","page":"Index","title":"AdaptiveResonance.opts_DAM","text":"opts_DAM(; kwargs...) -> opts_SFAM\n\n\nSummary\n\nImplements a Default ARTMAP module's options.\n\nDefault ARTMAP is a variant of SFAM, using the AdaptiveResonance.opts_SFAM options. This constructor sets the activation to :choice_by_difference in addition to the keyword argument options you provide.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nMethod List / Definition Locations\n\nopts_DAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/variants.jl:52.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_GammaNormalizedFuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.opts_GammaNormalizedFuzzyART","text":"opts_GammaNormalizedFuzzyART(; kwargs...)\n\n\nSummary\n\nImplements a Gamma-Normalized FuzzyART module's options.\n\nGammaNormalizedFuzzyART is a variant of FuzzyART, using the AdaptiveResonance.opts_FuzzyART options. This constructor passes gamma_normalization=true, which internally uses match=:gamma_match and activation=:gamma_activation in addition to the keyword argument options you provide.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nMethod List / Definition Locations\n\nopts_GammaNormalizedFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/variants.jl:50.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.performance-Tuple{AbstractVector{T} where T<:Integer, AbstractVector{T} where T<:Integer}","page":"Index","title":"AdaptiveResonance.performance","text":"performance(\n    y_hat::AbstractVector{T} where T<:Integer,\n    y::AbstractVector{T} where T<:Integer\n) -> Any\n\n\nSummary\n\nConvenience function to get the categorization performance of y_hat against y.\n\nArguments\n\ny_hat::IntegerVector: the estimated labels.\ny::IntegerVector: the true labels.\n\nMethod List / Definition Locations\n\nperformance(y_hat, y)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:200.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!","page":"Index","title":"AdaptiveResonance.train!","text":"train!(\n    art::ARTMAP,\n    x::AbstractMatrix{T} where T<:Real,\n    y::AbstractVector{T} where T<:Integer\n) -> Any\ntrain!(\n    art::ARTMAP,\n    x::AbstractMatrix{T} where T<:Real,\n    y::AbstractVector{T} where T<:Integer,\n    preprocessed::Bool\n) -> Any\n\n\nSummary\n\ntrain!(art::ARTMAP, x::RealMatrix, y::IntegerVector, preprocessed::Bool=false)\n\nTrain the ARTMAP model on a batch of data 'x' with supervisory labels 'y.'\n\nArguments\n\nart::ARTMAP: the supervised ARTMAP model to train.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\ny::IntegerVector: labels for supervisory training.\npreprocessed::Bool=false: flag, if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x, y)\ntrain!(art, x, y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/common.jl:23.\n\n\n\n\n\n","category":"function"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ART, AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.train!","text":"train!(\n    art::ART,\n    x::AbstractMatrix{T} where T<:Real;\n    y,\n    preprocessed\n) -> Any\n\n\nSummary\n\nTrain the ART model on a batch of data 'x' with optional supervisory labels 'y.'\n\nArguments\n\nart::ART: the unsupervised ART model to train.\nx::RealMatrix: the 2-D dataset containing columns of samples with rows of features.\ny::IntegerVector=Int[]: optional, labels for simple supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/common.jl:21.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ART, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.train!","text":"Summary\n\nTrain the ART model on a single sample of features 'x' with an optional supervisory label.\n\nArguments\n\nart::ART: the unsupervised ART model to train.\nx::RealVector: the single sample feature vector to train upon.\ny::Integer=0: optional, a label for simple supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:266.\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:260.\n\ntrain!(art, x; y, preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:292.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.train!-Tuple{ARTMAP, AbstractVector{T} where T<:Real, Integer}","page":"Index","title":"AdaptiveResonance.train!","text":"Summary\n\nTrain the supervised ARTMAP model on a single sample of features 'x' with supervisory label 'y'.\n\nArguments\n\nart::ARTMAP: the supervised ART model to train.\nx::RealVector: the single sample feature vector to train upon.\ny::Integer: the label for supervisory training.\npreprocessed::Bool=false: optional, flag if the data has already been complement coded or not.\n\nMethod List / Definition Locations\n\ntrain!(art, x, y; preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:227.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#index-types-docs","page":"Index","title":"Types","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:type]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.ART","page":"Index","title":"AdaptiveResonance.ART","text":"abstract type ART <: ARTModule\n\nSummary\n\nAbstract supertype for all default unsupervised ART modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTMAP","page":"Index","title":"AdaptiveResonance.ARTMAP","text":"abstract type ARTMAP <: ARTModule\n\nSummary\n\nAbstract supertype for all supervised ARTMAP modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTModule","page":"Index","title":"AdaptiveResonance.ARTModule","text":"abstract type ARTModule\n\nSummary\n\nAbstract supertype for both ART (unsupervised) and ARTMAP (supervised) modules.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.ARTOpts","page":"Index","title":"AdaptiveResonance.ARTOpts","text":"abstract type ARTOpts\n\nSummary\n\nAbstract supertype for all ART module options.\n\nFields\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DDVFA","page":"Index","title":"AdaptiveResonance.DDVFA","text":"mutable struct DDVFA <: ART\n\nSummary\n\nDistributed Dual Vigilance Fuzzy ARTMAP module struct.\n\nFor module options, see AdaptiveResonance.opts_DDVFA.\n\nReferences\n\nL. E. Brito da Silva, I. Elnabarawy, and D. C. Wunsch, 'Distributed dual vigilance fuzzy adaptive resonance theory learns online, retrieves arbitrarily-shaped clusters, and mitigates order dependence,' Neural Networks, vol. 121, pp. 208-228, 2020, doi: 10.1016/j.neunet.2019.08.033.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DDVFA: DDVFA options struct.\n\nsubopts::opts_FuzzyART: FuzzyART options struct used for all F2 nodes.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nF2::Vector{FuzzyART}: List of F2 nodes (themselves FuzzyART modules).\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of total categories.\n\nepoch::Int64: Current training epoch.\n\nT::Vector{Float64}: DDVFA activation values.\n\nM::Vector{Float64}: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DDVFA-Tuple{opts_DDVFA}","page":"Index","title":"AdaptiveResonance.DDVFA","text":"DDVFA(opts::opts_DDVFA) -> DDVFA\n\n\nSummary\n\nImplements a DDVFA learner with specified options.\n\nArguments\n\nopts::opts_DDVFA: the DDVFA options (see AdaptiveResonance.opts_DDVFA).\n\nExamples\n\njulia> my_opts = opts_DDVFA()\njulia> DDVFA(my_opts)\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nDDVFA(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:219.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DDVFA-Tuple{}","page":"Index","title":"AdaptiveResonance.DDVFA","text":"DDVFA(; kwargs...) -> DDVFA\n\n\nSummary\n\nImplements a DDVFA learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the DDVFA options struct (see AdaptiveResonance.opts_DDVFA.)\n\nExamples\n\nBy default:\n\njulia> DDVFA()\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nor with keyword arguments:\n\njulia> DDVFA(rho_lb=0.4, rho_ub = 0.75)\nDDVFA\n    opts: opts_DDVFA\n    subopts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nDDVFA(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/distributed/modules/DDVFA.jl:198.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DVFA","page":"Index","title":"AdaptiveResonance.DVFA","text":"mutable struct DVFA <: AdaptiveResonance.AbstractFuzzyART\n\nSummary\n\nDual Vigilance Fuzzy ARTMAP module struct.\n\nFor module options, see AdaptiveResonance.opts_DVFA.\n\nReferences:\n\nL. E. Brito da Silva, I. Elnabarawy and D. C. Wunsch II, 'Dual Vigilance Fuzzy ART,' Neural Networks Letters. To appear.\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_DVFA: DVFA options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold_ub::Float64: Operating upper bound module threshold value, a function of the upper bound vigilance parameter.\n\nthreshold_lb::Float64: Operating lower bound module threshold value, a function of the lower bound vigilance parameter.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nT::Vector{Float64}: Activation values for every weight for a given sample.\n\nM::Vector{Float64}: Match values for every weight for a given sample.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nn_clusters::Int64: Number of labeled clusters, may be lower than n_categories\n\nepoch::Int64: Current training epoch.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DVFA-Tuple{opts_DVFA}","page":"Index","title":"AdaptiveResonance.DVFA","text":"DVFA(opts::opts_DVFA) -> DVFA\n\n\nSummary\n\nImplements a DVFA learner with specified options.\n\nArguments\n\nopts::opts_DVFA: the DVFA options (see AdaptiveResonance.opts_DVFA).\n\nExamples\n\njulia> my_opts = opts_DVFA()\njulia> DVFA(my_opts)\nDVFA\n    opts: opts_DVFA\n    ...\n\nMethod List / Definition Locations\n\nDVFA(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:201.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DVFA-Tuple{}","page":"Index","title":"AdaptiveResonance.DVFA","text":"DVFA(; kwargs...) -> DVFA\n\n\nSummary\n\nImplements a DVFA learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the DVFA options struct (see AdaptiveResonance.opts_DVFA.)\n\nExamples\n\nBy default:\n\njulia> DVFA()\nDVFA\n    opts: opts_DVFA\n    ...\n\nor with keyword arguments:\n\njulia> DVFA(rho=0.7)\nDVFA\n    opts: opts_DVFA\n    ...\n\nMethod List / Definition Locations\n\nDVFA(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/DVFA.jl:181.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig","page":"Index","title":"AdaptiveResonance.DataConfig","text":"mutable struct DataConfig\n\nSummary\n\nContainer to standardize training/testing data configuration.\n\nThis container declares if a data configuration has been setup, what the original and complement coded dimensions are, and what the minimums and maximums of the values along each feature dimension are.\n\nFields\n\nsetup::Bool: Flag if data has been setup yet or not.\n\nmins::Vector{Float64}: List of minimum values for each feature.\n\nmaxs::Vector{Float64}: List of maximum values for each feature.\n\ndim::Int64: Dimensionality of the feature vectors (i.e., number of features).\n\ndim_comp::Int64: Complement coded feature dimensionality, twice the size of dim.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{AbstractMatrix{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(\n    data::AbstractMatrix{T} where T<:Real\n) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only the data matrix.\n\nArguments\n\ndata::RealMatrix: the 2-D batch of data to be used for inferring the data configuration.\n\nMethod List / Definition Locations\n\nDataConfig(data)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:120.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{AbstractVector{T} where T<:Real, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(\n    mins::AbstractVector{T} where T<:Real,\n    maxs::AbstractVector{T} where T<:Real\n) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only mins and maxs of the features.\n\nThis constructor is used when the mins and maxs differ across features. The dimension is inferred by the length of the mins and maxs.\n\nArguments\n\nmins::RealVector: a vector of minimum values for each feature dimension.\nmaxs::RealVector: a vector of maximum values for each feature dimension.\n\nMethod List / Definition Locations\n\nDataConfig(mins, maxs)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:79.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{Real, Real, Integer}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig(min::Real, max::Real, dim::Integer) -> DataConfig\n\n\nSummary\n\nConvenience constructor for DataConfig, requiring only a global min, max, and dim.\n\nThis constructor is used in the case that the feature mins and maxs are all the same respectively.\n\nArguments\n\nmin::Real: the minimum value across all features.\nmax::Real: the maximum value across all features.\ndim::Integer: the dimension of the features, which must be provided because it cannot be inferred from just the minimum or maximum values.\n\nMethod List / Definition Locations\n\nDataConfig(min, max, dim)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:104.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.DataConfig-Tuple{}","page":"Index","title":"AdaptiveResonance.DataConfig","text":"DataConfig() -> DataConfig\n\n\nSummary\n\nDefault constructor for a data configuration, not set up.\n\nMethod List / Definition Locations\n\nDataConfig()\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/lib/common.jl:60.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FAM","page":"Index","title":"AdaptiveResonance.FAM","text":"mutable struct FAM <: ARTMAP\n\nSummary\n\nFuzzy ARTMAP struct.\n\nFor module options, see AdaptiveResonance.opts_FAM.\n\nReferences\n\nG. A. Carpenter, S. Grossberg, N. Markuzon, J. H. Reynolds, and D. B. Rosen, “Fuzzy ARTMAP: A Neural Network Architecture for Incremental Supervised Learning of Analog Multidimensional Maps,” IEEE Trans. Neural Networks, vol. 3, no. 5, pp. 698-713, 1992, doi: 10.1109/72.159059.\n\nFields\n\nopts::opts_FAM: Fuzzy ARTMAP options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.FAM-Tuple{opts_FAM}","page":"Index","title":"AdaptiveResonance.FAM","text":"FAM(opts::opts_FAM) -> FAM\n\n\nSummary\n\nImplements a Fuzzy ARTMAP learner with specified options.\n\nExamples\n\njulia> opts = opts_FAM()\njulia> FAM(opts)\nFAM\n    opts: opts_FAM\n    ...\n\nMethod List / Definition Locations\n\nFAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/FAM.jl:138.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FAM-Tuple{}","page":"Index","title":"AdaptiveResonance.FAM","text":"FAM(; kwargs...) -> FAM\n\n\nSummary\n\nImplements a Fuzzy ARTMAP learner with optional keyword arguments.\n\nExamples\n\nBy default:\n\njulia> FAM()\nFAM\n    opts: opts_FAM\n    ...\n\nor with keyword arguments:\n\njulia> FAM(rho=0.7)\nFAM\n    opts: opts_FAM\n    ...\n\nMethod List / Definition Locations\n\nFAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/FAM.jl:121.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"mutable struct FuzzyART <: AdaptiveResonance.AbstractFuzzyART\n\nSummary\n\nGamma-Normalized Fuzzy ART learner struct\n\nFor module options, see AdaptiveResonance.opts_FuzzyART.\n\nReferences\n\nG. Carpenter, S. Grossberg, and D. Rosen, 'Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system,' Neural Networks, vol. 4, no. 6, pp. 759-771, 1991.\n\nFields\n\nopts::opts_FuzzyART: FuzzyART options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nthreshold::Float64: Operating module threshold value, a function of the vigilance parameter.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nT::Vector{Float64}: Activation values for every weight for a given sample.\n\nM::Vector{Float64}: Match values for every weight for a given sample.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nn_instance::Vector{Int64}: Number of weights associated with each category.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{opts_FuzzyART, AbstractVector{T} where T<:Real}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(\n    opts::opts_FuzzyART,\n    sample::AbstractVector{T} where T<:Real;\n    preprocessed\n) -> FuzzyART\n\n\nSummary\n\nCreate and initialize a FuzzyART with a single sample in one step.\n\nPrincipally used as a method for initialization within DDVFA.\n\nArguments\n\nopts::opts_FuzzyART: the FuzzyART options contains.\nsample::RealVector: the sample to use as a basis for setting up the FuzzyART.\npreprocessed::Bool=false: flag for if the sample is already complement coded and normalized.\n\nMethod List / Definition Locations\n\nFuzzyART(opts, sample; preprocessed)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:239.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{opts_FuzzyART}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(opts::opts_FuzzyART) -> FuzzyART\n\n\nSummary\n\nImplements a Fuzzy ART learner with specified options.\n\nArguments\n\nopts::opts_FuzzyART: the FuzzyART options struct with specified options (see AdaptiveResonance.opts_FuzzyART).\n\nExamples\n\njulia> FuzzyART(opts)\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nFuzzyART(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:206.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.FuzzyART-Tuple{}","page":"Index","title":"AdaptiveResonance.FuzzyART","text":"FuzzyART(; kwargs...) -> FuzzyART\n\n\nSummary\n\nImplements a Fuzzy ART learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments of FuzzyART options (see AdaptiveResonance.opts_FuzzyART).\n\nExamples\n\nBy default:\n\njulia> FuzzyART()\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nor with keyword arguments:\n\njulia> FuzzyART(rho=0.7)\nFuzzyART\n    opts: opts_FuzzyART\n    ...\n\nMethod List / Definition Locations\n\nFuzzyART(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ART/single/modules/FuzzyART.jl:184.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.SFAM","page":"Index","title":"AdaptiveResonance.SFAM","text":"mutable struct SFAM <: ARTMAP\n\nSummary\n\nSimple Fuzzy ARTMAP struct.\n\nFor module options, see AdaptiveResonance.opts_SFAM.\n\nReferences\n\nG. A. Carpenter, S. Grossberg, N. Markuzon, J. H. Reynolds, and D. B. Rosen, “Fuzzy ARTMAP: A Neural Network Architecture for Incremental Supervised Learning of Analog Multidimensional Maps,” IEEE Trans. Neural Networks, vol. 3, no. 5, pp. 698-713, 1992, doi: 10.1109/72.159059.\n\nFields\n\nopts::opts_SFAM: Simplified Fuzzy ARTMAP options struct.\n\nconfig::DataConfig: Data configuration struct.\n\nW::ElasticArrays.ElasticMatrix{Float64, V} where V<:DenseVector{Float64}: Category weight matrix.\n\nlabels::Vector{Int64}: Incremental list of labels corresponding to each F2 node, self-prescribed or supervised.\n\nn_categories::Int64: Number of category weights (F2 nodes).\n\nepoch::Int64: Current training epoch.\n\nT::Vector{Float64}: DDVFA activation values.\n\nM::Vector{Float64}: DDVFA match values.\n\nstats::Dict{String, Any}: Runtime statistics for the module, implemented as a dictionary containing entries at the end of each training iteration. These entries include the best-matching unit index and the activation and match values of the winning node.\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.SFAM-Tuple{opts_SFAM}","page":"Index","title":"AdaptiveResonance.SFAM","text":"SFAM(opts::opts_SFAM) -> SFAM\n\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner with specified options.\n\nArguments\n\nopts::opts_SFAM: the Simple Fuzzy ARTMAP options (see AdaptiveResonance.opts_SFAM).\n\nExamples\n\njulia> opts = opts_SFAM()\njulia> SFAM(opts)\nSFAM\n    opts: opts_SFAM\n    ...\n\nMethod List / Definition Locations\n\nSFAM(opts)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:178.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.SFAM-Tuple{}","page":"Index","title":"AdaptiveResonance.SFAM","text":"SFAM(; kwargs...) -> SFAM\n\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner with optional keyword arguments.\n\nArguments\n\nkwargs: keyword arguments to pass to the Simple Fuzzy ARTMAP options struct (see AdaptiveResonance.opts_SFAM.)\n\nExamples\n\nBy default:\n\njulia> SFAM()\nSFAM\n    opts: opts_SFAM\n    ...\n\nor with keyword arguments:\n\njulia> SFAM(rho=0.6)\nSFAM\n    opts: opts_SFAM\n    ...\n\nMethod List / Definition Locations\n\nSFAM(; kwargs...)\n\ndefined at /home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/src/ARTMAP/SFAM.jl:158.\n\n\n\n\n\n","category":"method"},{"location":"man/full-index/#AdaptiveResonance.opts_DDVFA","page":"Index","title":"AdaptiveResonance.opts_DDVFA","text":"mutable struct opts_DDVFA <: ARTOpts\n\nSummary\n\nDistributed Dual Vigilance Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.7\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.85\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nsimilarity::Symbol: Similarity method (activation and match): similarity ∈ [:single, :average, :complete, :median, :weighted, :centroid].  Default: :single\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.  Default: true\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :gamma_activation\nmatch::Symbol: Selected match function.  Default: :gamma_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_DVFA","page":"Index","title":"AdaptiveResonance.opts_DVFA","text":"mutable struct opts_DVFA <: ARTOpts\n\nSummary\n\nDual Vigilance Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho_lb::Float64: Lower-bound vigilance parameter: rho_lb ∈ [0, 1].  Default: 0.55\nrho_ub::Float64: Upper bound vigilance parameter: rho_ub ∈ [0, 1].  Default: 0.75\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training.  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nmatch::Symbol: Selected match function.  Default: :unnormalized_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_FAM","page":"Index","title":"AdaptiveResonance.opts_FAM","text":"mutable struct opts_FAM <: ARTOpts\n\nSummary\n\nImplements a Fuzzy ARTMAP learner's options.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.6\nalpha::Float64: Choice parameter: alpha > 0.  Default: 1.0e-7\nepsilon::Float64: Match tracking parameter: epsilon ∈ (0, 1).  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epochs::Int64: Maximum number of epochs during training: max_epochs ∈ [1, Inf)  Default: 1\nuncommitted::Bool: Uncommitted node flag.  Default: true\ndisplay::Bool: Display flag for progress bars.  Default: false\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_FuzzyART","page":"Index","title":"AdaptiveResonance.opts_FuzzyART","text":"mutable struct opts_FuzzyART <: ARTOpts\n\nSummary\n\nGamma-Normalized Fuzzy ART options struct.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.6\nalpha::Float64: Choice parameter: alpha > 0.  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\ngamma::Float64: Pseudo kernel width: gamma >= 1.  Default: 3.0\ngamma_ref::Float64: Reference gamma for normalization: 0 <= gamma_ref < gamma.  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training: max_epochs ∈ (1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\ngamma_normalization::Bool: Flag to normalize the threshold by the feature dimension.\nNOTE: this flag overwrites the activation and match settings here to their gamma-normalized equivalents along with adjusting the thresold.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nmatch::Symbol: Selected match function.  Default: :basic_match\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#AdaptiveResonance.opts_SFAM","page":"Index","title":"AdaptiveResonance.opts_SFAM","text":"mutable struct opts_SFAM <: ARTOpts\n\nSummary\n\nImplements a Simple Fuzzy ARTMAP learner's options.\n\nThese options are a Parameters.jl struct, taking custom options keyword arguments. Each field has a default value listed below.\n\nFields\n\nrho::Float64: Vigilance parameter: rho ∈ [0, 1].  Default: 0.75\nalpha::Float64: Choice parameter: alpha > 0.  Default: 1.0e-7\nepsilon::Float64: Match tracking parameter: epsilon ∈ (0, 1).  Default: 0.001\nbeta::Float64: Learning parameter: beta ∈ (0, 1].  Default: 1.0\nmax_epoch::Int64: Maximum number of epochs during training: max_epoch ∈ [1, Inf).  Default: 1\ndisplay::Bool: Display flag for progress bars.  Default: false\nuncommitted::Bool: Flag to use an uncommitted node when learning.\nIf true, new weights are created with ones(dim) and learn on the complement-coded sample. If false, fast-committing is used where the new weight is simply the complement-coded sample.  Default: false\nmatch::Symbol: Selected match function.  Default: :basic_match\nactivation::Symbol: Selected activation function.  Default: :basic_activation\nupdate::Symbol: Selected weight update function.  Default: :basic_update\n\n\n\n\n\n","category":"type"},{"location":"man/full-index/#index-constants-docs","page":"Index","title":"Constants","text":"","category":"section"},{"location":"man/full-index/","page":"Index","title":"Index","text":"Modules = [AdaptiveResonance]\nPrivate = false\nOrder = [:constant]","category":"page"},{"location":"man/full-index/#AdaptiveResonance.ACTIVATION_FUNCTIONS","page":"Index","title":"AdaptiveResonance.ACTIVATION_FUNCTIONS","text":"ACTIVATION_FUNCTIONS\n\nDescription\n\nEnumerates all of the activation functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ADAPTIVERESONANCE_MODULES","page":"Index","title":"AdaptiveResonance.ADAPTIVERESONANCE_MODULES","text":"ADAPTIVERESONANCE_MODULES\n\nDescription\n\nA combined list of all unsupervised ART and supervised ARTMAP modules from the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ADAPTIVERESONANCE_VERSION","page":"Index","title":"AdaptiveResonance.ADAPTIVERESONANCE_VERSION","text":"ADAPTIVERESONANCE_VERSION\n\nDescription\n\nA constant that contains the version of the installed AdaptiveResonance.jl package.\n\nThis value is computed at compile time, so it may be used to programmatically verify the version of AdaptiveResonance that is installed in case a compat entry in your Project.toml is missing or otherwise incorrect.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ARTMAP_MODULES","page":"Index","title":"AdaptiveResonance.ARTMAP_MODULES","text":"ARTMAP_MODULES\n\nDescription\n\nA list of supervised ARTMAP modules that are available in the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.ART_MODULES","page":"Index","title":"AdaptiveResonance.ART_MODULES","text":"ART_MODULES\n\nDescription\n\nA list of (default) unsupervised ART modules that are available in the AdaptiveResonance.jl package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.DDVFA_METHODS","page":"Index","title":"AdaptiveResonance.DDVFA_METHODS","text":"DDVFA_METHODS\n\nDescription\n\nA list of all DDVFA similarity linkage methods.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.MATCH_FUNCTIONS","page":"Index","title":"AdaptiveResonance.MATCH_FUNCTIONS","text":"MATCH_FUNCTIONS\n\nDescription\n\nEnumerates all of the match functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"man/full-index/#AdaptiveResonance.UPDATE_FUNCTIONS","page":"Index","title":"AdaptiveResonance.UPDATE_FUNCTIONS","text":"UPDATE_FUNCTIONS\n\nDescription\n\nEnumerates all of the update functions available in the package.\n\n\n\n\n\n","category":"constant"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"EditURL = \"/home/runner/work/AdaptiveResonance.jl/AdaptiveResonance.jl/docs/examples/adaptive_resonance/incremental-batch.jl\"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#incremental_batch","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(Image: Source code) (Image: notebook) (Image: compat) (Image: Author) (Image: Update time)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Overview","page":"Incremental vs. Batch Example","title":"Overview","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"All modules in AdaptiveResonance.jl are designed to handle incremental and batch training. In fact, ART modules are generally incremental in their implementation, so their batch methods wrap the incremental ones and handle preprocessing, etc. For example, DDVFA can be run incrementally (i.e. with one sample at a time) with custom algorithmic options and a predetermined data configuration.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"note: Note\nIn the incremental case, it is necessary to provide a data configuration if the model is not pretrained because the model has no knowledge of the boundaries and dimensionality of the data, which are necessary in the complement coding step. For more info, see the guide in the docs on incremental vs. batch.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Data-Setup","page":"Incremental vs. Batch Example","title":"Data Setup","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We begin with importing AdaptiveResonance for the ART modules and MLDatasets for some data utilities.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"using AdaptiveResonance # ART\nusing MLDatasets        # Iris dataset\nusing DataFrames        # DataFrames, necessary for MLDatasets.Iris()\nusing MLDataUtils       # Shuffling and splitting\nusing Printf            # Formatted number printing","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We will download the Iris dataset for its small size and benchmark use for clustering algorithms.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Get the iris dataset\niris = Iris(as_df=false)\n# Manipulate the features and labels into a matrix of features and a vector of labels\nfeatures, labels = iris.features, iris.targets","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"([5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 6.7 6.7 6.3 6.5 6.2 5.9; 3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2 3.3 3.0 2.5 3.0 3.4 3.0; 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1; 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 0.2 0.2 0.1 0.1 0.2 0.4 0.4 0.3 0.3 0.3 0.2 0.4 0.2 0.5 0.2 0.2 0.4 0.2 0.2 0.2 0.2 0.4 0.1 0.2 0.1 0.2 0.2 0.1 0.2 0.2 0.3 0.3 0.2 0.6 0.4 0.3 0.2 0.2 0.2 0.2 1.4 1.5 1.5 1.3 1.5 1.3 1.6 1.0 1.3 1.4 1.0 1.5 1.0 1.4 1.3 1.4 1.5 1.0 1.5 1.1 1.8 1.3 1.5 1.2 1.3 1.4 1.4 1.7 1.5 1.0 1.1 1.0 1.2 1.6 1.5 1.6 1.5 1.3 1.3 1.3 1.2 1.4 1.2 1.0 1.3 1.2 1.3 1.3 1.1 1.3 2.5 1.9 2.1 1.8 2.2 2.1 1.7 1.8 1.8 2.5 2.0 1.9 2.1 2.0 2.4 2.3 1.8 2.2 2.3 1.5 2.3 2.0 2.0 1.8 2.1 1.8 1.8 1.8 2.1 1.6 1.9 2.0 2.2 1.5 1.4 2.3 2.4 1.8 1.8 2.1 2.4 2.3 1.9 2.3 2.5 2.3 1.9 2.0 2.3 1.8], InlineStrings.String15[\"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-setosa\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-versicolor\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\" \"Iris-virginica\"])","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Because the MLDatasets package gives us Iris labels as strings, we will use the MLDataUtils.convertlabel method with the MLLabelUtils.LabelEnc.Indices type to get a list of integers representing each class:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"labels = convertlabel(LabelEnc.Indices{Int}, vec(labels))\nunique(labels)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"3-element Vector{Int64}:\n 1\n 2\n 3","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Next, we will create a train/test split with the MLDataUtils.stratifiedobs utility:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(X_train, y_train), (X_test, y_test) = stratifiedobs((features, labels))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"(([6.9 6.0 7.6 6.2 6.0 6.3 4.6 5.7 5.0 6.1 7.0 6.4 6.2 7.7 4.8 5.6 5.6 6.3 7.3 6.9 5.7 5.6 4.9 5.0 6.5 5.2 6.8 6.3 5.4 5.2 6.7 5.9 5.4 5.0 6.9 5.2 4.3 5.4 6.4 4.9 5.6 5.4 6.6 5.5 5.8 6.3 6.2 5.1 6.4 5.5 6.9 5.5 5.8 5.5 5.1 4.4 5.0 5.1 5.7 6.5 5.1 6.7 5.6 6.1 5.0 6.3 5.1 4.9 7.7 7.2 6.6 4.7 4.7 5.9 4.4 6.0 5.7 4.6 7.1 5.4 6.7 5.1 5.6 4.6 5.7 5.0 6.8 5.7 4.8 6.4 6.4 5.8 6.1 5.8 6.4 5.0 7.7 6.4 4.5 6.7 6.2 5.1 5.5 7.2 6.3; 3.1 2.2 3.0 2.8 2.9 2.9 3.4 2.8 3.0 3.0 3.2 2.9 3.4 3.0 3.1 2.7 2.8 2.8 2.9 3.1 2.8 3.0 2.5 3.4 3.0 2.7 3.0 3.4 3.4 4.1 2.5 3.0 3.7 3.5 3.2 3.5 3.0 3.9 2.8 3.0 2.5 3.4 3.0 3.5 2.7 2.7 2.9 3.5 3.1 2.5 3.1 2.4 4.0 2.3 2.5 2.9 3.2 3.4 3.0 3.0 3.8 3.0 2.9 3.0 2.3 3.3 3.7 3.1 2.8 3.2 2.9 3.2 3.2 3.2 3.2 2.2 2.5 3.2 3.0 3.9 3.1 3.8 3.0 3.1 3.8 3.6 3.2 2.6 3.0 2.8 2.7 2.8 2.8 2.6 3.2 3.3 2.6 3.2 2.3 3.1 2.2 3.3 2.4 3.0 3.3; 5.1 5.0 6.6 4.8 4.5 5.6 1.4 4.1 1.6 4.9 4.7 4.3 5.4 6.1 1.6 4.2 4.9 5.1 6.3 4.9 4.5 4.1 4.5 1.6 5.8 3.9 5.5 5.6 1.7 1.5 5.8 4.2 1.5 1.3 5.7 1.5 1.1 1.7 5.6 1.4 3.9 1.5 4.4 1.3 3.9 4.9 4.3 1.4 5.5 4.0 5.4 3.7 1.2 4.0 3.0 1.4 1.2 1.5 4.2 5.2 1.6 5.0 3.6 4.6 3.3 4.7 1.5 1.5 6.7 6.0 4.6 1.6 1.3 4.8 1.3 4.0 5.0 1.4 5.9 1.3 5.6 1.9 4.5 1.5 1.7 1.4 5.9 3.5 1.4 5.6 5.3 5.1 4.7 4.0 4.5 1.4 6.9 5.3 1.3 4.4 4.5 1.7 3.8 5.8 6.0; 2.3 1.5 2.1 1.8 1.5 1.8 0.3 1.3 0.2 1.8 1.4 1.3 2.3 2.3 0.2 1.3 2.0 1.5 1.8 1.5 1.3 1.3 1.7 0.4 2.2 1.4 2.1 2.4 0.2 0.1 1.8 1.5 0.2 0.3 2.3 0.2 0.1 0.4 2.2 0.2 1.1 0.4 1.4 0.2 1.2 1.8 1.3 0.3 1.8 1.3 2.1 1.0 0.2 1.3 1.1 0.2 0.2 0.2 1.2 2.0 0.2 1.7 1.3 1.4 1.0 1.6 0.4 0.1 2.0 1.8 1.3 0.2 0.2 1.8 0.2 1.0 2.0 0.2 2.1 0.4 2.4 0.4 1.5 0.2 0.3 0.2 2.3 1.0 0.3 2.1 1.9 2.4 1.2 1.2 1.5 0.2 2.3 2.3 0.3 1.4 1.5 0.5 1.1 1.6 2.5], [3, 3, 3, 3, 2, 3, 1, 2, 1, 3, 2, 2, 3, 3, 1, 2, 3, 3, 3, 2, 2, 2, 3, 1, 3, 2, 3, 3, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 1, 2, 3, 2, 1, 3, 2, 3, 2, 1, 2, 2, 1, 1, 1, 2, 3, 1, 2, 2, 2, 2, 2, 1, 1, 3, 3, 2, 1, 1, 2, 1, 2, 3, 1, 3, 1, 3, 1, 2, 1, 1, 1, 3, 2, 1, 3, 3, 3, 2, 2, 2, 1, 3, 3, 1, 2, 2, 1, 2, 3, 3]), ([4.8 6.8 5.1 6.0 5.0 6.3 6.5 7.2 5.2 5.4 4.8 6.5 6.7 5.1 6.7 4.6 5.7 6.0 6.3 5.0 6.7 5.5 6.7 5.7 5.8 6.1 4.9 6.0 5.8 5.0 4.9 7.4 6.3 5.3 7.9 5.5 5.8 6.1 6.1 7.7 5.9 4.9 4.8 4.4 6.5; 3.4 2.8 3.8 3.0 3.4 2.5 3.0 3.6 3.4 3.0 3.4 2.8 3.3 3.5 3.3 3.6 4.4 2.7 2.3 3.5 3.1 2.6 3.0 2.9 2.7 2.6 3.1 3.4 2.7 2.0 2.4 2.8 2.5 3.7 3.8 4.2 2.7 2.8 2.9 3.8 3.0 3.1 3.0 3.0 3.2; 1.6 4.8 1.5 4.8 1.5 5.0 5.5 6.1 1.4 4.5 1.9 4.6 5.7 1.4 5.7 1.0 1.5 5.1 4.4 1.6 4.7 4.4 5.2 4.2 4.1 5.6 1.5 4.5 5.1 3.5 3.3 6.1 4.9 1.5 6.4 1.4 5.1 4.0 4.7 6.7 5.1 1.5 1.4 1.3 5.1; 0.2 1.4 0.3 1.8 0.2 1.9 1.8 2.5 0.2 1.5 0.2 1.5 2.5 0.2 2.1 0.2 0.4 1.6 1.3 0.6 1.5 1.2 2.3 1.3 1.0 1.4 0.1 1.6 1.9 1.0 1.0 1.9 1.5 0.2 2.0 0.2 1.9 1.3 1.4 2.2 1.8 0.1 0.1 0.2 2.0], [1, 2, 1, 3, 1, 3, 3, 3, 1, 2, 1, 2, 3, 1, 3, 1, 1, 2, 2, 1, 2, 2, 3, 2, 2, 3, 1, 2, 3, 2, 2, 3, 2, 1, 3, 1, 3, 2, 2, 3, 3, 1, 1, 1, 3]))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Incremental-vs.-Batch","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/#Setup","page":"Incremental vs. Batch Example","title":"Setup","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Now, we can create several modules to illustrate training one in batch and one incrementaly.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Create several modules for batch and incremental training.\n# We can take advantage of the options instantiation method here to use the same options for both modules.\nopts = opts_DDVFA(rho_lb=0.6, rho_ub=0.75)\nart_batch = DDVFA(opts)\nart_incremental = DDVFA(opts)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"DDVFA(opts_DDVFA\n  rho_lb: Float64 0.6\n  rho_ub: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  similarity: Symbol single\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, opts_FuzzyART\n  rho: Float64 0.75\n  alpha: Float64 0.001\n  beta: Float64 1.0\n  gamma: Float64 3.0\n  gamma_ref: Float64 1.0\n  max_epoch: Int64 1\n  display: Bool false\n  gamma_normalization: Bool true\n  uncommitted: Bool false\n  activation: Symbol gamma_activation\n  match: Symbol gamma_match\n  update: Symbol basic_update\n, DataConfig(false, Float64[], Float64[], 0, 0), 0.0, FuzzyART[], Int64[], 0, 0, Float64[], Float64[], Dict{String, Any}(\"bmu\" => 0, \"mismatch\" => false, \"M\" => 0.0, \"T\" => 0.0))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"For the incremental version, we must setup the data configuration in advance. In batch mode, this is done automatically based upon the provided data, but the incremental variant has not way of knowing the bounds of the individual features. We could preprocess the data and set the data configuration with art.config = DataConfig(0, 1, 4), which translates to the data containing four features  that all range from 0 to 1. This would be done in scenarios where we have either done some preprocessing on the data or have prior knowledge about the bounds of individual features. However, in this example we will let the module determine the bounds with the convenience method data_setup!:","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Setup the data config on all of the features.\ndata_setup!(art_incremental.config, features)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Training","page":"Incremental vs. Batch Example","title":"Training","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can train in batch with a simple supervised mode by passing the labels as a keyword argument.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"y_hat_batch_train = train!(art_batch, X_train, y=y_train)\nprintln(\"Training labels: \",  size(y_hat_batch_train), \" \", typeof(y_hat_batch_train))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Training labels: (105,) Vector{Int64}\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can also train incrementally with the same method, being careful that we pass a vector features and a single integer as the labels","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Get the number of training samples\nn_train = length(y_train)\n# Create a container for the training output labels\ny_hat_incremental_train = zeros(Int, n_train)\n# Iterate over all training samples\nfor ix in eachindex(y_train)\n    sample = X_train[:, ix]\n    label = y_train[ix]\n    y_hat_incremental_train[ix] = train!(art_incremental, sample, y=label)\nend","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Testing","page":"Incremental vs. Batch Example","title":"Testing","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"We can then classify both networks and check that their performances are equivalent. For both, we will use the best-matching unit in the case of complete mismatch (see the docs on Mismatch vs. BMU)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Classify one model in batch mode\ny_hat_batch = AdaptiveResonance.classify(art_batch, X_test, get_bmu=true)\n\n# Classify one model incrementally\nn_test = length(y_test)\ny_hat_incremental = zeros(Int, n_test)\nfor ix = 1:n_test\n    y_hat_incremental[ix] = AdaptiveResonance.classify(art_incremental, X_test[:, ix], get_bmu=true)\nend\n\n# Check the shape and type of the output labels\nprintln(\"Batch testing labels: \",  size(y_hat_batch), \" \", typeof(y_hat_batch))\nprintln(\"Incremental testing labels: \",  size(y_hat_incremental), \" \", typeof(y_hat_incremental))","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Batch testing labels: (45,) Vector{Int64}\nIncremental testing labels: (45,) Vector{Int64}\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Finally, we check the performance (number of correct classifications over total number of test samples) for both models, verifying that they produce the same results.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Calculate performance on training data, testing data, and with get_bmu\nperf_train_batch = performance(y_hat_batch_train, y_train)\nperf_train_incremental = performance(y_hat_incremental_train, y_train)\nperf_test_batch = performance(y_hat_batch, y_test)\nperf_test_incremental = performance(y_hat_incremental, y_test)\n\n# Format each performance number for comparison\n@printf \"Batch training performance: %.4f\\n\" perf_train_batch\n@printf \"Incremental training performance: %.4f\\n\" perf_train_incremental\n@printf \"Batch testing performance: %.4f\\n\" perf_test_batch\n@printf \"Incremental testing performance: %.4f\\n\" perf_test_incremental","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Batch training performance: 1.0000\nIncremental training performance: 1.0000\nBatch testing performance: 0.9556\nIncremental testing performance: 0.9556\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/#Visualization","page":"Incremental vs. Batch Example","title":"Visualization","text":"","category":"section"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"So we showed that the performance and behavior of modules are identical in incremental and batch modes. Great! Sadly, illustrating this point doesn't lend itself to visualization in any meaningful way. Nonetheless, we would like a pretty picture at the end of the experiment to verify that these identical solutions work in the first place. Sanity checks are meaningful in their own right, right?","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"To do this, we will reduce the dimensionality of the dataset to two dimensions and show in a scatter plot how the modules classify the test data into groups. This will be done with principal component analysis (PCA) to cast the points into a 2-D space while trying to preserve the relative distances between points in the higher dimension. The process isn't perfect by any means, but it suffices for visualization.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Import visualization utilities\nusing Printf            # Formatted number printing\nusing MultivariateStats # Principal component analysis (PCA)\nusing Plots             # Plotting frontend\ngr()                    # Use the default GR backend explicitly\n\n# Train a PCA model\nM = fit(PCA, features; maxoutdim=2)\n\n# Apply the PCA model to the testing set\nX_test_pca = MultivariateStats.transform(M, X_test)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"2×45 Matrix{Float64}:\n 2.61314    -1.33104  2.58735   -1.16885   2.62648   -1.52566   -1.94925    -2.91813   2.63982  -0.587275   2.35617    -1.08713    -2.41939   2.68421   -2.27585   3.21586   2.38387  -1.37874   -0.812868  2.40551   -1.22043   -0.463031  -1.94402   -0.375238  -0.234541  -1.77964    2.67384   -0.807205  -1.41407    0.511086   0.751467  -2.84096   -1.29647   2.54269   -3.23234  2.59716  -1.41407   -0.356787   -0.984045  -3.48877  -1.38967    2.67384    2.78743   2.98184  -1.66193\n 0.0215206   0.24467  0.520474  -0.164502  0.170405  -0.375021   0.0407303   0.780381  0.31929  -0.483284  -0.0312096   0.0753904   0.303504  0.326607   0.333387  0.141616  1.34475  -0.421205  -0.370679  0.195917   0.408035  -0.669527   0.187415  -0.291622  -0.331922  -0.501465  -0.106692   0.195054  -0.574925  -1.26249   -1.00111    0.372743  -0.327562  0.586281   1.37052  1.10002  -0.574925  -0.0668238  -0.12436    1.17154  -0.282887  -0.106692  -0.22774  -0.48025   0.242038","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"Now that we have the test points cast into a 2-D set of points, we can create a scatter plot that shows how each point is categorized by the modules.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"# Create a scatterplot object from the data with some additional formatting options\nscatter(\n    X_test_pca[1, :],       # PCA dimension 1\n    X_test_pca[2, :],       # PCA dimension 2\n    group = y_hat_batch,    # labels belonging to each point\n    markersize = 8,         # size of scatter points\n    legend = false,         # no legend\n    xtickfontsize = 12,     # x-tick size\n    ytickfontsize = 12,     # y-tick size\n    dpi = 300,              # Set the dots-per-inch\n    xlims = :round,         # Round up the x-limits to the nearest whole number\n    xlabel = \"\\$PCA_1\\$\",   # x-label\n    ylabel = \"\\$PCA_2\\$\",   # y-label\n    title = (@sprintf \"DDVFA Iris Clusters\"),   # formatted title\n)","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n<defs>\n  <clipPath id=\"clip620\">\n    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip620)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip621\">\n    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n  </clipPath>\n</defs>\n<path clip-path=\"url(#clip620)\" d=\"M310.676 1405.9 L2352.76 1405.9 L2352.76 123.472 L310.676 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n<defs>\n  <clipPath id=\"clip622\">\n    <rect x=\"310\" y=\"123\" width=\"2043\" height=\"1283\"/>\n  </clipPath>\n</defs>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"821.196,1405.9 821.196,123.472 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1331.72,1405.9 1331.72,123.472 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1842.24,1405.9 1842.24,123.472 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2352.76,1405.9 2352.76,123.472 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 2352.76,1405.9 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,1387 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"821.196,1405.9 821.196,1387 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1331.72,1405.9 1331.72,1387 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1842.24,1405.9 1842.24,1387 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2352.76,1405.9 2352.76,1387 \"/>\n<path clip-path=\"url(#clip620)\" d=\"M264.027 1464.66 L308.541 1464.66 L308.541 1470.56 L264.027 1470.56 L264.027 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M342.95 1444.17 L325.242 1471.84 L342.95 1471.84 L342.95 1444.17 M341.11 1438.06 L349.929 1438.06 L349.929 1471.84 L357.325 1471.84 L357.325 1477.68 L349.929 1477.68 L349.929 1489.9 L342.95 1489.9 L342.95 1477.68 L319.547 1477.68 L319.547 1470.91 L341.11 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M776.109 1464.66 L820.623 1464.66 L820.623 1470.56 L776.109 1470.56 L776.109 1464.66 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M841.803 1484 L866.283 1484 L866.283 1489.9 L833.366 1489.9 L833.366 1484 Q837.359 1479.87 844.234 1472.92 Q851.144 1465.94 852.915 1463.93 Q856.283 1460.14 857.602 1457.54 Q858.956 1454.9 858.956 1452.37 Q858.956 1448.23 856.04 1445.63 Q853.158 1443.03 848.505 1443.03 Q845.206 1443.03 841.526 1444.17 Q837.88 1445.32 833.713 1447.64 L833.713 1440.56 Q837.949 1438.86 841.63 1437.99 Q845.31 1437.12 848.366 1437.12 Q856.421 1437.12 861.213 1441.15 Q866.005 1445.18 866.005 1451.91 Q866.005 1455.11 864.789 1457.99 Q863.609 1460.84 860.449 1464.73 Q859.581 1465.73 854.928 1470.56 Q850.276 1475.35 841.803 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1331.72 1442.68 Q1326.3 1442.68 1323.56 1448.03 Q1320.85 1453.34 1320.85 1464.03 Q1320.85 1474.69 1323.56 1480.04 Q1326.3 1485.35 1331.72 1485.35 Q1337.17 1485.35 1339.88 1480.04 Q1342.62 1474.69 1342.62 1464.03 Q1342.62 1453.34 1339.88 1448.03 Q1337.17 1442.68 1331.72 1442.68 M1331.72 1437.12 Q1340.43 1437.12 1345.01 1444.03 Q1349.63 1450.91 1349.63 1464.03 Q1349.63 1477.12 1345.01 1484.03 Q1340.43 1490.91 1331.72 1490.91 Q1323 1490.91 1318.38 1484.03 Q1313.8 1477.12 1313.8 1464.03 Q1313.8 1450.91 1318.38 1444.03 Q1323 1437.12 1331.72 1437.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1834.22 1484 L1858.69 1484 L1858.69 1489.9 L1825.78 1489.9 L1825.78 1484 Q1829.77 1479.87 1836.65 1472.92 Q1843.56 1465.94 1845.33 1463.93 Q1848.69 1460.14 1850.01 1457.54 Q1851.37 1454.9 1851.37 1452.37 Q1851.37 1448.23 1848.45 1445.63 Q1845.57 1443.03 1840.92 1443.03 Q1837.62 1443.03 1833.94 1444.17 Q1830.29 1445.32 1826.12 1447.64 L1826.12 1440.56 Q1830.36 1438.86 1834.04 1437.99 Q1837.72 1437.12 1840.78 1437.12 Q1848.83 1437.12 1853.62 1441.15 Q1858.42 1445.18 1858.42 1451.91 Q1858.42 1455.11 1857.2 1457.99 Q1856.02 1460.84 1852.86 1464.73 Q1851.99 1465.73 1847.34 1470.56 Q1842.69 1475.35 1834.22 1484 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M2357.27 1444.17 L2339.56 1471.84 L2357.27 1471.84 L2357.27 1444.17 M2355.43 1438.06 L2364.25 1438.06 L2364.25 1471.84 L2371.64 1471.84 L2371.64 1477.68 L2364.25 1477.68 L2364.25 1489.9 L2357.27 1489.9 L2357.27 1477.68 L2333.87 1477.68 L2333.87 1470.91 L2355.43 1438.06 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1293.14 1527.31 Q1293.14 1530.92 1290.47 1534.24 Q1287.83 1537.55 1283.52 1539.58 Q1279.23 1541.58 1274.63 1541.58 L1263.42 1541.58 L1259.33 1558.07 Q1259.3 1558.17 1259.2 1558.58 Q1259.1 1558.97 1259.1 1559.2 Q1259.1 1560 1260.1 1560.19 Q1261.13 1560.39 1263.42 1560.39 Q1264.9 1560.39 1265.13 1560.65 Q1265.25 1560.81 1265.25 1561.1 Q1265.25 1561.55 1265.13 1561.87 Q1265 1562.16 1264.74 1562.26 Q1264.51 1562.35 1264.35 1562.38 Q1264.19 1562.42 1263.93 1562.42 Q1263.26 1562.42 1261.81 1562.35 Q1260.39 1562.29 1259.65 1562.29 L1255.43 1562.22 L1247.06 1562.42 Q1246.06 1562.42 1246.06 1561.61 Q1246.06 1561 1246.32 1560.74 Q1246.58 1560.45 1246.86 1560.42 Q1247.15 1560.39 1247.9 1560.39 Q1249.51 1560.39 1250.47 1560.29 Q1251.44 1560.19 1252.05 1560.07 Q1252.69 1559.9 1253.02 1559.45 Q1253.37 1559 1253.53 1558.62 Q1253.69 1558.2 1253.92 1557.26 L1262.74 1521.84 Q1263 1520.77 1263 1520.61 Q1263 1520.07 1262.68 1519.87 Q1262.39 1519.65 1261.55 1519.55 Q1259.94 1519.42 1258.72 1519.42 Q1257.91 1519.42 1257.59 1519.39 Q1257.3 1519.36 1257.04 1519.2 Q1256.82 1519 1256.82 1518.62 Q1256.82 1518 1257.07 1517.75 Q1257.36 1517.46 1257.69 1517.42 Q1258.01 1517.36 1258.78 1517.36 L1280.17 1517.36 Q1286.32 1517.36 1289.73 1520.29 Q1293.14 1523.22 1293.14 1527.31 M1287.03 1525.73 Q1287.03 1519.42 1278.04 1519.42 L1271.73 1519.42 Q1269.63 1519.42 1269.12 1519.81 Q1268.6 1520.16 1268.15 1521.93 L1263.68 1539.87 L1272.98 1539.87 Q1279.23 1539.87 1283.13 1536.36 Q1284.9 1534.75 1285.96 1531.4 Q1287.03 1528.05 1287.03 1525.73 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1343.51 1516.59 L1339.36 1533.4 Q1339.07 1534.46 1338.88 1534.59 Q1338.72 1534.72 1338.2 1534.72 Q1337.2 1534.72 1337.2 1534.04 Q1337.2 1533.98 1337.3 1533.14 Q1337.39 1532.27 1337.39 1530.69 Q1337.39 1524.86 1334.56 1521.42 Q1331.76 1517.97 1326.77 1517.97 Q1322.45 1517.97 1318.1 1520.16 Q1313.79 1522.35 1310.7 1525.93 Q1308.38 1528.63 1306.67 1532.05 Q1305 1535.46 1304.19 1538.58 Q1303.42 1541.71 1303.06 1544.06 Q1302.71 1546.41 1302.71 1548.12 Q1302.71 1550.6 1303.22 1552.69 Q1303.77 1554.78 1304.74 1556.27 Q1305.7 1557.71 1306.93 1558.84 Q1308.18 1559.94 1309.63 1560.58 Q1311.11 1561.22 1312.6 1561.55 Q1314.08 1561.84 1315.62 1561.84 Q1321.84 1561.84 1327.77 1557.01 Q1332.47 1553.04 1334.43 1546.57 Q1334.59 1545.93 1335.27 1545.93 Q1336.07 1545.93 1336.07 1546.57 Q1336.07 1546.7 1335.91 1547.34 Q1335.75 1547.96 1335.27 1549.21 Q1334.79 1550.44 1334.05 1551.82 Q1333.3 1553.21 1331.92 1554.94 Q1330.53 1556.68 1328.83 1558.2 Q1325.93 1560.71 1322.26 1562.29 Q1318.59 1563.87 1314.56 1563.87 Q1309.54 1563.87 1305.48 1561.64 Q1301.42 1559.42 1299.04 1555.27 Q1296.69 1551.11 1296.69 1545.8 Q1296.69 1540.19 1299.26 1534.69 Q1301.84 1529.18 1305.93 1525.09 Q1310.02 1521 1315.43 1518.46 Q1320.84 1515.91 1326.25 1515.91 Q1328.31 1515.91 1330.15 1516.46 Q1331.98 1517.01 1333.08 1517.68 Q1334.21 1518.36 1335.2 1519.36 Q1336.2 1520.32 1336.53 1520.77 Q1336.88 1521.23 1337.2 1521.77 L1341.81 1516.72 Q1342.61 1515.91 1342.81 1515.91 Q1343.19 1515.91 1343.35 1516.14 Q1343.51 1516.36 1343.51 1516.59 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1388.64 1561.1 Q1388.64 1561.71 1388.38 1562.03 Q1388.15 1562.32 1387.93 1562.38 Q1387.73 1562.42 1387.44 1562.42 Q1386.61 1562.42 1383.71 1562.32 Q1380.81 1562.22 1379.97 1562.22 Q1378.62 1562.22 1375.85 1562.32 Q1373.08 1562.42 1371.73 1562.42 Q1370.83 1562.42 1370.83 1561.68 Q1370.83 1561.19 1370.92 1560.93 Q1371.02 1560.65 1371.28 1560.55 Q1371.57 1560.42 1371.73 1560.42 Q1371.92 1560.39 1372.4 1560.39 Q1373.05 1560.39 1373.72 1560.32 Q1374.4 1560.23 1375.24 1560.03 Q1376.07 1559.84 1376.59 1559.36 Q1377.14 1558.87 1377.14 1558.2 Q1377.14 1557.91 1376.91 1555.52 Q1376.69 1553.14 1376.4 1550.37 Q1376.11 1547.57 1376.07 1547.18 L1359.52 1547.18 Q1358.01 1549.79 1356.94 1551.6 Q1355.88 1553.4 1355.5 1554.01 Q1355.11 1554.62 1354.88 1555.01 Q1354.66 1555.4 1354.53 1555.62 Q1353.6 1557.33 1353.6 1558.07 Q1353.6 1560.13 1356.69 1560.39 Q1357.75 1560.39 1357.75 1561.16 Q1357.75 1561.74 1357.49 1562.06 Q1357.23 1562.35 1357.01 1562.38 Q1356.82 1562.42 1356.49 1562.42 Q1355.43 1562.42 1353.21 1562.32 Q1350.99 1562.22 1349.89 1562.22 Q1348.96 1562.22 1347.03 1562.32 Q1345.09 1562.42 1344.22 1562.42 Q1343.84 1562.42 1343.61 1562.19 Q1343.39 1561.97 1343.39 1561.68 Q1343.39 1561.22 1343.45 1560.97 Q1343.55 1560.71 1343.8 1560.58 Q1344.06 1560.45 1344.19 1560.45 Q1344.32 1560.42 1344.77 1560.39 Q1347.22 1560.23 1349.12 1559.07 Q1351.05 1557.88 1352.89 1554.82 L1375.82 1516.3 Q1376.04 1515.91 1376.2 1515.72 Q1376.36 1515.52 1376.69 1515.36 Q1377.04 1515.2 1377.56 1515.2 Q1378.36 1515.2 1378.52 1515.46 Q1378.68 1515.69 1378.78 1516.78 L1382.81 1558 Q1382.9 1558.87 1382.97 1559.23 Q1383.06 1559.55 1383.48 1559.9 Q1383.93 1560.23 1384.74 1560.32 Q1385.58 1560.39 1387.12 1560.39 Q1387.7 1560.39 1387.93 1560.42 Q1388.15 1560.42 1388.38 1560.58 Q1388.64 1560.74 1388.64 1561.1 M1375.88 1545.12 L1373.79 1523.38 L1360.78 1545.12 L1375.88 1545.12 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1395.24 1554.34 L1395.24 1552.9 Q1400.78 1552.9 1403.65 1549.94 Q1404.44 1549.94 1404.57 1550.12 Q1404.71 1550.3 1404.71 1551.14 L1404.71 1577.04 Q1404.71 1578.42 1405.38 1578.84 Q1406.06 1579.27 1409.01 1579.27 L1410.48 1579.27 L1410.48 1580.69 Q1408.85 1580.56 1402.99 1580.56 Q1397.13 1580.56 1395.53 1580.69 L1395.53 1579.27 L1397 1579.27 Q1399.9 1579.27 1400.6 1578.87 Q1401.3 1578.44 1401.3 1577.04 L1401.3 1553.12 Q1398.89 1554.34 1395.24 1554.34 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1248.99 2352.76,1248.99 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,1019.25 2352.76,1019.25 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,789.506 2352.76,789.506 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,559.762 2352.76,559.762 \"/>\n<polyline clip-path=\"url(#clip622)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"310.676,330.018 2352.76,330.018 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1405.9 310.676,123.472 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1248.99 329.574,1248.99 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,1019.25 329.574,1019.25 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,789.506 329.574,789.506 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,559.762 329.574,559.762 \"/>\n<polyline clip-path=\"url(#clip620)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"310.676,330.018 329.574,330.018 \"/>\n<path clip-path=\"url(#clip620)\" d=\"M114.26 1249.67 L158.774 1249.67 L158.774 1255.57 L114.26 1255.57 L114.26 1249.67 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M175.128 1269.01 L186.586 1269.01 L186.586 1229.46 L174.121 1231.96 L174.121 1225.57 L186.517 1223.07 L193.531 1223.07 L193.531 1269.01 L204.989 1269.01 L204.989 1274.91 L175.128 1274.91 L175.128 1269.01 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M219.155 1266.09 L226.482 1266.09 L226.482 1274.91 L219.155 1274.91 L219.155 1266.09 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M256.759 1227.69 Q251.343 1227.69 248.6 1233.04 Q245.891 1238.35 245.891 1249.05 Q245.891 1259.7 248.6 1265.05 Q251.343 1270.36 256.759 1270.36 Q262.211 1270.36 264.919 1265.05 Q267.662 1259.7 267.662 1249.05 Q267.662 1238.35 264.919 1233.04 Q262.211 1227.69 256.759 1227.69 M256.759 1222.14 Q265.475 1222.14 270.058 1229.05 Q274.676 1235.92 274.676 1249.05 Q274.676 1262.14 270.058 1269.04 Q265.475 1275.92 256.759 1275.92 Q248.044 1275.92 243.426 1269.04 Q238.843 1262.14 238.843 1249.05 Q238.843 1235.92 243.426 1229.05 Q248.044 1222.14 256.759 1222.14 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M115.753 1019.93 L160.267 1019.93 L160.267 1025.83 L115.753 1025.83 L115.753 1019.93 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M190.406 997.947 Q184.989 997.947 182.246 1003.29 Q179.538 1008.61 179.538 1019.3 Q179.538 1029.96 182.246 1035.31 Q184.989 1040.62 190.406 1040.62 Q195.857 1040.62 198.565 1035.31 Q201.308 1029.96 201.308 1019.3 Q201.308 1008.61 198.565 1003.29 Q195.857 997.947 190.406 997.947 M190.406 992.392 Q199.121 992.392 203.704 999.302 Q208.322 1006.18 208.322 1019.3 Q208.322 1032.39 203.704 1039.3 Q199.121 1046.18 190.406 1046.18 Q181.69 1046.18 177.072 1039.3 Q172.489 1032.39 172.489 1019.3 Q172.489 1006.18 177.072 999.302 Q181.69 992.392 190.406 992.392 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M220.648 1036.35 L227.975 1036.35 L227.975 1045.17 L220.648 1045.17 L220.648 1036.35 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M243.322 993.329 L270.857 993.329 L270.857 999.232 L249.746 999.232 L249.746 1011.94 Q251.273 1011.42 252.801 1011.18 Q254.329 1010.9 255.857 1010.9 Q264.537 1010.9 269.607 1015.66 Q274.676 1020.41 274.676 1028.54 Q274.676 1036.91 269.468 1041.56 Q264.259 1046.18 254.78 1046.18 Q251.516 1046.18 248.114 1045.62 Q244.746 1045.07 241.134 1043.95 L241.134 1036.91 Q244.259 1038.61 247.593 1039.44 Q250.926 1040.27 254.641 1040.27 Q260.648 1040.27 264.155 1037.11 Q267.662 1033.95 267.662 1028.54 Q267.662 1023.12 264.155 1019.96 Q260.648 1016.8 254.641 1016.8 Q251.829 1016.8 249.016 1017.43 Q246.239 1018.05 243.322 1019.37 L243.322 993.329 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M188.913 768.204 Q183.496 768.204 180.753 773.551 Q178.045 778.863 178.045 789.558 Q178.045 800.217 180.753 805.565 Q183.496 810.877 188.913 810.877 Q194.364 810.877 197.072 805.565 Q199.815 800.217 199.815 789.558 Q199.815 778.863 197.072 773.551 Q194.364 768.204 188.913 768.204 M188.913 762.648 Q197.628 762.648 202.211 769.558 Q206.829 776.433 206.829 789.558 Q206.829 802.648 202.211 809.558 Q197.628 816.433 188.913 816.433 Q180.197 816.433 175.579 809.558 Q170.996 802.648 170.996 789.558 Q170.996 776.433 175.579 769.558 Q180.197 762.648 188.913 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M219.155 806.606 L226.482 806.606 L226.482 815.426 L219.155 815.426 L219.155 806.606 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M256.759 768.204 Q251.343 768.204 248.6 773.551 Q245.891 778.863 245.891 789.558 Q245.891 800.217 248.6 805.565 Q251.343 810.877 256.759 810.877 Q262.211 810.877 264.919 805.565 Q267.662 800.217 267.662 789.558 Q267.662 778.863 264.919 773.551 Q262.211 768.204 256.759 768.204 M256.759 762.648 Q265.475 762.648 270.058 769.558 Q274.676 776.433 274.676 789.558 Q274.676 802.648 270.058 809.558 Q265.475 816.433 256.759 816.433 Q248.044 816.433 243.426 809.558 Q238.843 802.648 238.843 789.558 Q238.843 776.433 243.426 769.558 Q248.044 762.648 256.759 762.648 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M190.406 538.46 Q184.989 538.46 182.246 543.807 Q179.538 549.12 179.538 559.814 Q179.538 570.474 182.246 575.821 Q184.989 581.133 190.406 581.133 Q195.857 581.133 198.565 575.821 Q201.308 570.474 201.308 559.814 Q201.308 549.12 198.565 543.807 Q195.857 538.46 190.406 538.46 M190.406 532.905 Q199.121 532.905 203.704 539.814 Q208.322 546.689 208.322 559.814 Q208.322 572.904 203.704 579.814 Q199.121 586.689 190.406 586.689 Q181.69 586.689 177.072 579.814 Q172.489 572.904 172.489 559.814 Q172.489 546.689 177.072 539.814 Q181.69 532.905 190.406 532.905 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M220.648 576.863 L227.975 576.863 L227.975 585.682 L220.648 585.682 L220.648 576.863 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M243.322 533.842 L270.857 533.842 L270.857 539.745 L249.746 539.745 L249.746 552.453 Q251.273 551.932 252.801 551.689 Q254.329 551.411 255.857 551.411 Q264.537 551.411 269.607 556.168 Q274.676 560.925 274.676 569.05 Q274.676 577.418 269.468 582.071 Q264.259 586.689 254.78 586.689 Q251.516 586.689 248.114 586.133 Q244.746 585.578 241.134 584.467 L241.134 577.418 Q244.259 579.12 247.593 579.953 Q250.926 580.786 254.641 580.786 Q260.648 580.786 264.155 577.626 Q267.662 574.467 267.662 569.05 Q267.662 563.634 264.155 560.474 Q260.648 557.314 254.641 557.314 Q251.829 557.314 249.016 557.939 Q246.239 558.564 243.322 559.884 L243.322 533.842 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M175.128 350.036 L186.586 350.036 L186.586 310.487 L174.121 312.987 L174.121 306.598 L186.517 304.098 L193.531 304.098 L193.531 350.036 L204.989 350.036 L204.989 355.938 L175.128 355.938 L175.128 350.036 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M219.155 347.119 L226.482 347.119 L226.482 355.938 L219.155 355.938 L219.155 347.119 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M256.759 308.716 Q251.343 308.716 248.6 314.064 Q245.891 319.376 245.891 330.07 Q245.891 340.73 248.6 346.077 Q251.343 351.39 256.759 351.39 Q262.211 351.39 264.919 346.077 Q267.662 340.73 267.662 330.07 Q267.662 319.376 264.919 314.064 Q262.211 308.716 256.759 308.716 M256.759 303.161 Q265.475 303.161 270.058 310.071 Q274.676 316.946 274.676 330.07 Q274.676 343.161 270.058 350.07 Q265.475 356.945 256.759 356.945 Q248.044 356.945 243.426 350.07 Q238.843 343.161 238.843 330.07 Q238.843 316.946 243.426 310.071 Q248.044 303.161 256.759 303.161 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M28.8883 804.838 Q32.4954 804.838 35.8126 807.511 Q39.1298 810.152 41.1587 814.467 Q43.1555 818.751 43.1555 823.356 L43.1555 834.564 L59.6449 838.654 Q59.7415 838.686 60.1602 838.783 Q60.5467 838.879 60.7721 838.879 Q61.5772 838.879 61.7705 837.881 Q61.9637 836.85 61.9637 834.564 Q61.9637 833.082 62.2214 832.857 Q62.3824 832.728 62.6722 832.728 Q63.1231 832.728 63.4452 832.857 Q63.735 832.986 63.8317 833.243 Q63.9283 833.469 63.9605 833.63 Q63.9927 833.791 63.9927 834.048 Q63.9927 834.725 63.9283 836.174 Q63.8639 837.591 63.8639 838.332 L63.7995 842.551 L63.9927 850.924 Q63.9927 851.923 63.1875 851.923 Q62.5756 851.923 62.318 851.665 Q62.0281 851.407 61.9959 851.117 Q61.9637 850.828 61.9637 850.087 Q61.9637 848.477 61.8671 847.51 Q61.7705 846.544 61.6417 845.932 Q61.4806 845.288 61.0297 844.966 Q60.5789 844.612 60.1924 844.451 Q59.7737 844.29 58.8398 844.064 L23.4133 835.24 Q22.3505 834.982 22.1895 834.982 Q21.642 834.982 21.4487 835.304 Q21.2233 835.594 21.1267 836.432 Q20.9979 838.042 20.9979 839.266 Q20.9979 840.071 20.9657 840.393 Q20.9335 840.683 20.7724 840.94 Q20.5792 841.166 20.1927 841.166 Q19.5808 841.166 19.3232 840.908 Q19.0333 840.618 19.0011 840.296 Q18.9367 839.974 18.9367 839.201 L18.9367 817.817 Q18.9367 811.665 21.8674 808.251 Q24.7982 804.838 28.8883 804.838 M27.3102 810.957 Q20.9979 810.957 20.9979 819.942 L20.9979 826.255 Q20.9979 828.348 21.3843 828.863 Q21.7386 829.378 23.5099 829.829 L41.4486 834.306 L41.4486 824.998 Q41.4486 818.751 37.9381 814.854 Q36.3279 813.082 32.9784 812.02 Q29.629 810.957 27.3102 810.957 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M18.1637 754.469 L34.9752 758.623 Q36.038 758.913 36.1668 759.106 Q36.2956 759.267 36.2956 759.783 Q36.2956 760.781 35.6193 760.781 Q35.5549 760.781 34.7176 760.684 Q33.848 760.588 32.2699 760.588 Q26.4407 760.588 22.9946 763.422 Q19.5486 766.224 19.5486 771.216 Q19.5486 775.531 21.7386 779.879 Q23.9286 784.195 27.5034 787.286 Q30.2087 789.605 33.6226 791.312 Q37.0364 792.987 40.1604 793.792 Q43.2843 794.565 45.6353 794.919 Q47.9864 795.273 49.6933 795.273 Q52.1731 795.273 54.2665 794.758 Q56.3599 794.211 57.8414 793.244 Q59.2906 792.278 60.4178 791.055 Q61.5128 789.798 62.157 788.349 Q62.8011 786.868 63.1231 785.386 Q63.413 783.905 63.413 782.359 Q63.413 776.143 58.5821 770.217 Q54.6208 765.515 48.1474 763.551 Q47.5033 763.39 47.5033 762.713 Q47.5033 761.908 48.1474 761.908 Q48.2762 761.908 48.9203 762.069 Q49.5323 762.23 50.7883 762.713 Q52.0121 763.196 53.397 763.937 Q54.7818 764.678 56.5209 766.063 Q58.26 767.448 59.7737 769.155 Q62.2858 772.053 63.8639 775.725 Q65.442 779.396 65.442 783.422 Q65.442 788.446 63.2197 792.504 Q60.9975 796.562 56.843 798.945 Q52.6884 801.296 47.3745 801.296 Q41.7706 801.296 36.2634 798.719 Q30.7562 796.143 26.6661 792.053 Q22.576 787.963 20.0317 782.552 Q17.4874 777.142 17.4874 771.731 Q17.4874 769.67 18.0349 767.834 Q18.5824 765.998 19.2587 764.903 Q19.9351 763.776 20.9335 762.778 Q21.8996 761.779 22.3505 761.457 Q22.8014 761.103 23.3489 760.781 L18.2926 756.176 Q17.4874 755.37 17.4874 755.177 Q17.4874 754.791 17.7129 754.63 Q17.9383 754.469 18.1637 754.469 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M62.6722 709.347 Q63.2842 709.347 63.6062 709.605 Q63.8961 709.83 63.9605 710.056 Q63.9927 710.249 63.9927 710.539 Q63.9927 711.376 63.8961 714.275 Q63.7995 717.173 63.7995 718.011 Q63.7995 719.363 63.8961 722.133 Q63.9927 724.903 63.9927 726.255 Q63.9927 727.157 63.252 727.157 Q62.7689 727.157 62.5112 727.061 Q62.2214 726.964 62.1247 726.706 Q61.9959 726.416 61.9959 726.255 Q61.9637 726.062 61.9637 725.579 Q61.9637 724.935 61.8993 724.259 Q61.8027 723.582 61.6095 722.745 Q61.4162 721.908 60.9331 721.392 Q60.45 720.845 59.7737 720.845 Q59.4839 720.845 57.1006 721.07 Q54.7174 721.296 51.9477 721.586 Q49.1458 721.875 48.7593 721.908 L48.7593 738.461 Q51.368 739.975 53.1715 741.038 Q54.975 742.101 55.587 742.487 Q56.1989 742.874 56.5853 743.099 Q56.9718 743.325 57.1973 743.453 Q58.9042 744.387 59.6449 744.387 Q61.7061 744.387 61.9637 741.296 Q61.9637 740.233 62.7367 740.233 Q63.3164 740.233 63.6384 740.49 Q63.9283 740.748 63.9605 740.973 Q63.9927 741.167 63.9927 741.489 Q63.9927 742.552 63.8961 744.774 Q63.7995 746.996 63.7995 748.091 Q63.7995 749.025 63.8961 750.957 Q63.9927 752.89 63.9927 753.759 Q63.9927 754.146 63.7672 754.371 Q63.5418 754.597 63.252 754.597 Q62.8011 754.597 62.5434 754.532 Q62.2858 754.436 62.157 754.178 Q62.0281 753.92 62.0281 753.791 Q61.9959 753.663 61.9637 753.212 Q61.8027 750.764 60.6433 748.864 Q59.4517 746.932 56.3921 745.096 L17.8739 722.165 Q17.4874 721.94 17.2942 721.779 Q17.101 721.618 16.9399 721.296 Q16.7789 720.941 16.7789 720.426 Q16.7789 719.621 17.0365 719.46 Q17.262 719.299 18.357 719.202 L59.5805 715.177 Q60.45 715.08 60.8043 715.016 Q61.1264 714.919 61.4806 714.5 Q61.8027 714.049 61.8993 713.244 Q61.9637 712.407 61.9637 710.861 Q61.9637 710.281 61.9959 710.056 Q61.9959 709.83 62.157 709.605 Q62.318 709.347 62.6722 709.347 M46.6981 722.101 L24.9592 724.194 L46.6981 737.205 L46.6981 722.101 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M82.2693 702.744 Q81.4351 702.744 81.1871 702.676 Q80.9391 702.586 80.5559 702.226 L70.6816 693.366 Q65.2259 688.519 60.4691 688.519 Q57.3806 688.519 55.1712 690.142 Q52.9619 691.743 52.9619 694.696 Q52.9619 696.725 54.2018 698.438 Q55.4418 700.151 57.6511 700.941 Q57.606 700.805 57.606 700.332 Q57.606 699.182 58.3274 698.551 Q59.0488 697.897 60.0182 697.897 Q61.2581 697.897 61.8668 698.709 Q62.453 699.498 62.453 700.287 Q62.453 700.602 62.3854 701.031 Q62.3177 701.437 61.6865 702.09 Q61.0327 702.744 59.883 702.744 Q56.6592 702.744 54.0891 700.309 Q51.5191 697.852 51.5191 694.11 Q51.5191 689.871 54.044 687.098 Q56.5464 684.303 60.4691 684.303 Q61.8443 684.303 63.1068 684.731 Q64.3467 685.137 65.3161 685.701 Q66.2855 686.242 67.841 687.73 Q69.3966 689.218 70.5012 690.412 Q71.6059 691.607 73.9505 694.29 L78.7073 699.182 L78.7073 690.863 Q78.7073 686.805 78.3466 686.49 Q77.6928 686.039 74.2436 685.475 L74.2436 684.303 L82.2693 685.611 L82.2693 702.744 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M948.399 18.8205 L948.399 65.8515 L958.283 65.8515 Q970.801 65.8515 976.593 60.1802 Q982.427 54.509 982.427 42.2752 Q982.427 30.1225 976.593 24.4918 Q970.801 18.8205 958.283 18.8205 L948.399 18.8205 M940.216 12.096 L957.028 12.096 Q974.608 12.096 982.832 19.4281 Q991.055 26.7198 991.055 42.2752 Q991.055 57.9117 982.791 65.2439 Q974.527 72.576 957.028 72.576 L940.216 72.576 L940.216 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1012.28 18.8205 L1012.28 65.8515 L1022.17 65.8515 Q1034.68 65.8515 1040.48 60.1802 Q1046.31 54.509 1046.31 42.2752 Q1046.31 30.1225 1040.48 24.4918 Q1034.68 18.8205 1022.17 18.8205 L1012.28 18.8205 M1004.1 12.096 L1020.91 12.096 Q1038.49 12.096 1046.71 19.4281 Q1054.94 26.7198 1054.94 42.2752 Q1054.94 57.9117 1046.67 65.2439 Q1038.41 72.576 1020.91 72.576 L1004.1 72.576 L1004.1 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1082.12 72.576 L1059.03 12.096 L1067.58 12.096 L1086.74 63.0159 L1105.94 12.096 L1114.45 12.096 L1091.4 72.576 L1082.12 72.576 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1123.28 12.096 L1158.03 12.096 L1158.03 18.9825 L1131.46 18.9825 L1131.46 36.8065 L1155.44 36.8065 L1155.44 43.6931 L1131.46 43.6931 L1131.46 72.576 L1123.28 72.576 L1123.28 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1183.59 20.1573 L1172.5 50.2555 L1194.73 50.2555 L1183.59 20.1573 M1178.98 12.096 L1188.25 12.096 L1211.3 72.576 L1202.8 72.576 L1197.29 57.061 L1170.02 57.061 L1164.51 72.576 L1155.89 72.576 L1178.98 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1246.51 12.096 L1254.69 12.096 L1254.69 72.576 L1246.51 72.576 L1246.51 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1296.94 34.1734 Q1295.68 33.4443 1294.18 33.1202 Q1292.73 32.7556 1290.94 32.7556 Q1284.62 32.7556 1281.22 36.8875 Q1277.86 40.9789 1277.86 48.6757 L1277.86 72.576 L1270.36 72.576 L1270.36 27.2059 L1277.86 27.2059 L1277.86 34.2544 Q1280.21 30.1225 1283.98 28.1376 Q1287.74 26.1121 1293.13 26.1121 Q1293.9 26.1121 1294.83 26.2337 Q1295.76 26.3147 1296.9 26.5172 L1296.94 34.1734 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1304.76 27.2059 L1312.21 27.2059 L1312.21 72.576 L1304.76 72.576 L1304.76 27.2059 M1304.76 9.54393 L1312.21 9.54393 L1312.21 18.9825 L1304.76 18.9825 L1304.76 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1356.73 28.5427 L1356.73 35.5912 Q1353.57 33.9709 1350.17 33.1607 Q1346.77 32.3505 1343.12 32.3505 Q1337.57 32.3505 1334.77 34.0519 Q1332.02 35.7533 1332.02 39.156 Q1332.02 41.7486 1334 43.2475 Q1335.99 44.7058 1341.98 46.0426 L1344.54 46.6097 Q1352.48 48.3111 1355.8 51.4303 Q1359.16 54.509 1359.16 60.0587 Q1359.16 66.3781 1354.14 70.0644 Q1349.16 73.7508 1340.41 73.7508 Q1336.76 73.7508 1332.79 73.0216 Q1328.86 72.3329 1324.49 70.9151 L1324.49 63.2184 Q1328.62 65.3654 1332.63 66.4591 Q1336.64 67.5124 1340.57 67.5124 Q1345.83 67.5124 1348.67 65.73 Q1351.5 63.9071 1351.5 60.6258 Q1351.5 57.5877 1349.44 55.9673 Q1347.41 54.3469 1340.49 52.8481 L1337.89 52.2405 Q1330.97 50.7821 1327.89 47.7845 Q1324.81 44.7463 1324.81 39.4801 Q1324.81 33.0797 1329.35 29.5959 Q1333.88 26.1121 1342.23 26.1121 Q1346.36 26.1121 1350.01 26.7198 Q1353.65 27.3274 1356.73 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1443.01 16.7545 L1443.01 25.383 Q1438.88 21.5346 1434.18 19.6307 Q1429.53 17.7268 1424.26 17.7268 Q1413.89 17.7268 1408.38 24.0867 Q1402.87 30.4061 1402.87 42.3968 Q1402.87 54.3469 1408.38 60.7069 Q1413.89 67.0263 1424.26 67.0263 Q1429.53 67.0263 1434.18 65.1223 Q1438.88 63.2184 1443.01 59.3701 L1443.01 67.9175 Q1438.72 70.8341 1433.9 72.2924 Q1429.12 73.7508 1423.77 73.7508 Q1410.04 73.7508 1402.14 65.3654 Q1394.24 56.9395 1394.24 42.3968 Q1394.24 27.8135 1402.14 19.4281 Q1410.04 11.0023 1423.77 11.0023 Q1429.2 11.0023 1433.98 12.4606 Q1438.8 13.8784 1443.01 16.7545 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1455.33 9.54393 L1462.78 9.54393 L1462.78 72.576 L1455.33 72.576 L1455.33 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1477.61 54.671 L1477.61 27.2059 L1485.06 27.2059 L1485.06 54.3874 Q1485.06 60.8284 1487.57 64.0691 Q1490.09 67.2693 1495.11 67.2693 Q1501.15 67.2693 1504.63 63.421 Q1508.15 59.5726 1508.15 52.9291 L1508.15 27.2059 L1515.61 27.2059 L1515.61 72.576 L1508.15 72.576 L1508.15 65.6084 Q1505.44 69.7404 1501.83 71.7658 Q1498.27 73.7508 1493.53 73.7508 Q1485.71 73.7508 1481.66 68.8897 Q1477.61 64.0286 1477.61 54.671 M1496.36 26.1121 L1496.36 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1559.88 28.5427 L1559.88 35.5912 Q1556.72 33.9709 1553.32 33.1607 Q1549.92 32.3505 1546.27 32.3505 Q1540.72 32.3505 1537.93 34.0519 Q1535.17 35.7533 1535.17 39.156 Q1535.17 41.7486 1537.16 43.2475 Q1539.14 44.7058 1545.14 46.0426 L1547.69 46.6097 Q1555.63 48.3111 1558.95 51.4303 Q1562.31 54.509 1562.31 60.0587 Q1562.31 66.3781 1557.29 70.0644 Q1552.31 73.7508 1543.56 73.7508 Q1539.91 73.7508 1535.94 73.0216 Q1532.01 72.3329 1527.64 70.9151 L1527.64 63.2184 Q1531.77 65.3654 1535.78 66.4591 Q1539.79 67.5124 1543.72 67.5124 Q1548.99 67.5124 1551.82 65.73 Q1554.66 63.9071 1554.66 60.6258 Q1554.66 57.5877 1552.59 55.9673 Q1550.57 54.3469 1543.64 52.8481 L1541.05 52.2405 Q1534.12 50.7821 1531.04 47.7845 Q1527.96 44.7463 1527.96 39.4801 Q1527.96 33.0797 1532.5 29.5959 Q1537.04 26.1121 1545.38 26.1121 Q1549.51 26.1121 1553.16 26.7198 Q1556.8 27.3274 1559.88 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1581.56 14.324 L1581.56 27.2059 L1596.91 27.2059 L1596.91 32.9987 L1581.56 32.9987 L1581.56 57.6282 Q1581.56 63.1779 1583.05 64.7578 Q1584.59 66.3376 1589.25 66.3376 L1596.91 66.3376 L1596.91 72.576 L1589.25 72.576 Q1580.62 72.576 1577.34 69.3758 Q1574.06 66.1351 1574.06 57.6282 L1574.06 32.9987 L1568.59 32.9987 L1568.59 27.2059 L1574.06 27.2059 L1574.06 14.324 L1581.56 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1645.52 48.0275 L1645.52 51.6733 L1611.25 51.6733 Q1611.73 59.3701 1615.87 63.421 Q1620.04 67.4314 1627.45 67.4314 Q1631.75 67.4314 1635.76 66.3781 Q1639.81 65.3249 1643.78 63.2184 L1643.78 70.267 Q1639.77 71.9684 1635.55 72.8596 Q1631.34 73.7508 1627.01 73.7508 Q1616.15 73.7508 1609.79 67.4314 Q1603.47 61.1119 1603.47 50.3365 Q1603.47 39.1965 1609.47 32.6746 Q1615.5 26.1121 1625.71 26.1121 Q1634.87 26.1121 1640.17 32.0264 Q1645.52 37.9003 1645.52 48.0275 M1638.07 45.84 Q1637.98 39.7232 1634.62 36.0774 Q1631.3 32.4315 1625.79 32.4315 Q1619.55 32.4315 1615.79 35.9558 Q1612.06 39.4801 1611.49 45.8805 L1638.07 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1684.04 34.1734 Q1682.79 33.4443 1681.29 33.1202 Q1679.83 32.7556 1678.05 32.7556 Q1671.73 32.7556 1668.33 36.8875 Q1664.96 40.9789 1664.96 48.6757 L1664.96 72.576 L1657.47 72.576 L1657.47 27.2059 L1664.96 27.2059 L1664.96 34.2544 Q1667.31 30.1225 1671.08 28.1376 Q1674.85 26.1121 1680.24 26.1121 Q1681.01 26.1121 1681.94 26.2337 Q1682.87 26.3147 1684 26.5172 L1684.04 34.1734 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip620)\" d=\"M1720.79 28.5427 L1720.79 35.5912 Q1717.63 33.9709 1714.22 33.1607 Q1710.82 32.3505 1707.17 32.3505 Q1701.62 32.3505 1698.83 34.0519 Q1696.07 35.7533 1696.07 39.156 Q1696.07 41.7486 1698.06 43.2475 Q1700.04 44.7058 1706.04 46.0426 L1708.59 46.6097 Q1716.53 48.3111 1719.85 51.4303 Q1723.22 54.509 1723.22 60.0587 Q1723.22 66.3781 1718.19 70.0644 Q1713.21 73.7508 1704.46 73.7508 Q1700.81 73.7508 1696.84 73.0216 Q1692.91 72.3329 1688.54 70.9151 L1688.54 63.2184 Q1692.67 65.3654 1696.68 66.4591 Q1700.69 67.5124 1704.62 67.5124 Q1709.89 67.5124 1712.72 65.73 Q1715.56 63.9071 1715.56 60.6258 Q1715.56 57.5877 1713.49 55.9673 Q1711.47 54.3469 1704.54 52.8481 L1701.95 52.2405 Q1695.02 50.7821 1691.94 47.7845 Q1688.86 44.7463 1688.86 39.4801 Q1688.86 33.0797 1693.4 29.5959 Q1697.94 26.1121 1706.28 26.1121 Q1710.41 26.1121 1714.06 26.7198 Q1717.71 27.3274 1720.79 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip622)\" cx=\"1998.75\" cy=\"779.617\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1992.16\" cy=\"550.355\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2002.15\" cy=\"711.207\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2005.56\" cy=\"642.796\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1933.15\" cy=\"803.846\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2016.89\" cy=\"639.434\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2152.6\" cy=\"724.435\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1940.22\" cy=\"171.608\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1945.75\" cy=\"699.484\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2014.24\" cy=\"838.529\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1980.76\" cy=\"520.117\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1994.67\" cy=\"284.06\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2014.24\" cy=\"838.529\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2043.24\" cy=\"894.149\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"2092.86\" cy=\"1010.17\" r=\"28.8\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"991.954\" cy=\"677.083\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1181.81\" cy=\"1011.57\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1054.21\" cy=\"754.865\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1124.22\" cy=\"959.828\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1020.19\" cy=\"602.019\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1213.52\" cy=\"1097.14\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1235.93\" cy=\"923.502\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1271.85\" cy=\"942.02\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"877.445\" cy=\"1019.92\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1125.67\" cy=\"699.881\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1462.18\" cy=\"1369.6\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1523.54\" cy=\"1249.5\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1000.78\" cy=\"940.016\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1240.64\" cy=\"820.21\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1080.53\" cy=\"846.648\" r=\"28.8\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"1033.35\" cy=\"865.092\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"942.275\" cy=\"961.823\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"834.151\" cy=\"770.791\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"586.833\" cy=\"430.931\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"714.142\" cy=\"650.049\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"750.782\" cy=\"636.319\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"979.78\" cy=\"983.044\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"835.486\" cy=\"703.391\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"970.76\" cy=\"1053.68\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"606.532\" cy=\"618.235\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"506.628\" cy=\"159.767\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"970.76\" cy=\"1053.68\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"441.174\" cy=\"251.196\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"976.99\" cy=\"919.489\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n<circle clip-path=\"url(#clip622)\" cx=\"907.49\" cy=\"678.292\" r=\"28.8\" fill=\"#3da44d\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n</svg>\n","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"This plot shows that the DDVFA modules do well at identifying the structure of the three clusters despite not achieving 100% test performance.","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"\"assets/incremental-batch-cover.png\"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"","category":"page"},{"location":"examples/adaptive_resonance/incremental-batch/","page":"Incremental vs. Batch Example","title":"Incremental vs. Batch Example","text":"This page was generated using DemoCards.jl and Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"DocTestSetup = quote\n    using AdaptiveResonance, Dates\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: header)","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"These pages serve as the official documentation for the AdaptiveResonance.jl Julia package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Adaptive Resonance Theory (ART) began as a neurocognitive theory of how fields of cells can continuously learn stable representations, and it has been utilized as the basis for a myriad of practical machine learning algorithms. Pioneered by Stephen Grossberg and Gail Carpenter, the field has had contributions across many years and from many disciplines, resulting in a plethora of engineering applications and theoretical advancements that have enabled ART-based algorithms to compete with many other modern learning and clustering algorithms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The purpose of this package is to provide a home for the development and use of these ART-based machine learning algorithms in the Julia programming language.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See the Index for the complete list of documented functions and types.","category":"page"},{"location":"#Manual-Outline","page":"Home","title":"Manual Outline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation is split into the following sections:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pages = [\n    \"man/guide.md\",\n    \"../examples/index.md\",\n    \"man/modules.md\",\n    \"man/contributing.md\",\n    \"man/full-index.md\",\n    \"man/dev-index.md\",\n]\nDepth = 1","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Package Guide provides a tutorial to the full usage of the package, while Examples gives sample workflows using a variety of ART modules. A list of the implemented ART modules is included in Modules, where different options are also listed for creating variants of these modules that exist in the literature.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Instructions on how to contribute to the package are found in Contributing, and docstrings for every element of the package is listed in the Index. Names internal to the package are also listed under the Developer Index.","category":"page"},{"location":"#Documentation-Build","page":"Home","title":"Documentation Build","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation was built using Documenter.jl with the following version and OS:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using AdaptiveResonance, Dates # hide\nprintln(\"AdaptiveResonance v$(ADAPTIVERESONANCE_VERSION) docs built $(Dates.now()) with Julia $(VERSION) on $(Sys.KERNEL)\") # hide","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you make use of this project, please generate your citation with the CITATION.cff file of the repository. Alternatively, you may use the following BibTeX entry for the JOSS paper associated with the repository:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{Petrenko2022,\n  doi = {10.21105/joss.03671},\n  url = {https://doi.org/10.21105/joss.03671},\n  year = {2022},\n  publisher = {The Open Journal},\n  volume = {7},\n  number = {73},\n  pages = {3671},\n  author = {Sasha Petrenko and Donald C. Wunsch},\n  title = {AdaptiveResonance.jl: A Julia Implementation of Adaptive Resonance Theory (ART) Algorithms},\n  journal = {Journal of Open Source Software}\n}","category":"page"}]
}
